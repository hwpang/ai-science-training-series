{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J1tOS7oWba4s"
   },
   "source": [
    "# Large language models (LLMs): Part II\n",
    "\n",
    "Author: Archit Vasan , including materials on LLMs by Varuni Sastri, and discussion/editorial work by Taylor Childers, Carlo Graziani, Bethany Lusch, and Venkat Vishwanath (Argonne)\n",
    "\n",
    "Inspiration from the blog posts \"The Illustrated Transformer\" and \"The Illustrated GPT2\" by Jay Alammar, highly recommended reading.\n",
    "\n",
    "Before you begin, make sure that you have your environment set up and your repo refreshed, as described in previous lessons, and reviewed in the accompanying 'Readme.md' file. Make sure that you select the kernel 'datascience/conda-2023-01-10' at the top-left of the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "1. Training and inference using Hugging Face\n",
    "2. Elements of an LLM\n",
    "3. Attention mechanisms\n",
    "4. Positional encoding\n",
    "5. Output layers\n",
    "6. Training loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"HTTP_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"HTTPS_PROXY\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"http_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"https_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\"\n",
    "# os.environ[\"ftp_proxy\"]=\"http://proxy-01.pub.alcf.anl.gov:3128\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM training and inference using HuggingFace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/hf-logo-with-title.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "HuggingFace is a platform and community that provides open-source library tools and resources like pre-trained models and datasets.\n",
    "Refer to the following links for more information :\n",
    "\n",
    "https://huggingface.co/docs/hub/index\n",
    "\n",
    "https://huggingface.co/docs/transformers/en/index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: _Large Language Models are only as good as their training data. They have no ethics, no judgement, or editing ability. We will be using some pretrained models from Hugging Face which used wide samples of internet hosted text. The datasets have not been strictly filtered to restrict all malign content so the generated text may be surprisingly dark or questionable. They do not reflect our core values and are only used for demonstration purposes._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "We can use the Huggingface pipeline with a pretrained GPT2 model to generate text given a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My dog really wanted to spend his days outside, he has taken him a lot of hours each day'},\n",
       " {'generated_text': \"My dog really wanted to have fun with I'm going to take him to the zoo. He was\"},\n",
       " {'generated_text': 'My dog really wanted to hug me when I was about 4 or 5 years old.\"\\n\\n\\nA'},\n",
       " {'generated_text': 'My dog really wanted to get her paws involved.\\n\\n\"I was just trying to make sure'},\n",
       " {'generated_text': \"My dog really wanted to be with me and I wanted her to know you wouldn't hurt her when\"}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM, AutoConfig\n",
    "input_text = \"My dog really wanted to\"\n",
    "from transformers import pipeline\n",
    "generator = pipeline(\"text-generation\", model=\"openai-community/gpt2\")\n",
    "generator(input_text, max_length=20, num_return_sequences=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover  evaluation metrics,as well as safe and responsibilities practices when using LLMs in **Session 8**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also load in our own dataset and train a model with this data as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (0.28.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from accelerate) (0.4.2)\n",
      "Requirement already satisfied: filelock in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: requests in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from huggingface-hub->accelerate) (4.66.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install accelerate -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextDataset,DataCollatorForLanguageModeling\n",
    "\n",
    "def load_dataset(train_path,test_path,tokenizer):\n",
    "    train_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=train_path,\n",
    "          block_size=128) \n",
    "    test_dataset = TextDataset(\n",
    "          tokenizer=tokenizer,\n",
    "          file_path=test_path,\n",
    "          block_size=128)   \n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, mlm=False,\n",
    "    )\n",
    "    return train_dataset,test_dataset,data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ü§ó Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n",
      "/home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\")\n",
    "\n",
    "train_dataset,test_dataset,data_collator = load_dataset('dataset/train_input.txt','dataset/test_input.txt', tokenizer)\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./gpt2\", #The output directory\n",
    "    overwrite_output_dir=True, #overwrite the content of the output directory\n",
    "    num_train_epochs=3, # number of training epochs\n",
    "    per_device_train_batch_size=32, # batch size for training\n",
    "    per_device_eval_batch_size=64,  # batch size for evaluation\n",
    "    eval_steps = 40, # Number of update steps between two evaluations.\n",
    "    save_steps=80, # after # steps model is saved \n",
    "    warmup_steps=50,# number of warmup steps for learning rate scheduler\n",
    "    prediction_loss_only=True,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is going on below the hood?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two components that are \"black-boxes\" here:\n",
    "1. The method for tokenization\n",
    "2. The model that generates novel text.\n",
    "\n",
    "Carlo Graziani already gave a great explanation of tokenization last week and how this affects embeddings (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today we will take a closer look at how the model is designed to deal with language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look inside GPT2! GPT2 incorporates the `GPT2LMHeadModel` architecture so let's inspect this more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "# model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General elements of an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-2 is an example of the popular Transformer architecture. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cig2mvfguetQ"
   },
   "source": [
    "<img src=\"images/decoder_only_block.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "Image credit: https://arxiv.org/pdf/1706.03762.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gray section in this figure is the Transfomer Decoder and it is the main mechanism GPT2 uses to encode context of language into its predictions.\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Transformer-Decoder is composed of Decoder blocks stacked ontop of each other where each contains two types of layers: \n",
    "1. Masked Self-Attention and \n",
    "2. Feed Forward Neural Networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already discussed Feed Forward Neural Networks in detail in the other lectures in this series. To review this, please look at https://github.com/argonne-lcf/ai-science-training-series/blob/main/02_intro_neural_networks/01_introduction_mnist.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lecture, we will \n",
    "* First, discuss attention mechanisms at length as this is arguably the greatest contribution by Transformers.\n",
    "* Second, extend the discussion from last week (https://github.com/argonne-lcf/ai-science-training-series/blob/main/04_intro_to_llms/Sequential_Data_Models.ipynb) on embedding input data while taking into account position.\n",
    "* Third, discuss outputting real text/sequences from the models.\n",
    "* Fourth, build a training loop for a mini-LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's set up all the imports we will need**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f902af9f090>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## IMPORTS\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------\n",
    "\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BowLYFlCrDrr"
   },
   "source": [
    "## Attention mechanisms\n",
    "\n",
    "Suppose the following sentence is an input sentence we want to translate using an LLM:\n",
    "\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "\n",
    "Last week, Carlo mentioned that the Transformer learns an embedding of all words allowing interpretation of meanings of words.\n",
    "\n",
    "<img src=\"images/viz-bert-voc-verbs.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "So, if the model did a good job in token embedding, it will \"know\" what all the words in this sentence mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But to understand a full sentence, the model also need to understand what each word means in relation to other words.\n",
    "\n",
    "For example, when we read the sentence:\n",
    "`‚ÄùThe animal didn't cross the street because it was too tired‚Äù`\n",
    "we know intuitively that the word `\"it\"` refers to `\"animal\"`, the state for `\"it\"` is `\"tired\"`, and the associated action is `\"didn't cross\"`.\n",
    "\n",
    "However, the model needs a way to learn all of this information in a simple yet generalizable way.\n",
    "What makes Transformers particularly powerful compared to earlier sequential architectures is how it encodes context with the **self-attention mechanism**.\n",
    "\n",
    "As the model processes each word in the input sequence, attention looks at other positions in the input sequence for clues to a better understanding for this word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_self-attention_visualization.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UGbAi0cJ7x3a"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention mechanisms use 3 vectors to encode the context of a word in a sequence with another word:\n",
    "1. Query: the word representation we score other words against using the other word's keys\n",
    "2. Key: labels for the words in a sequence that we match against the query\n",
    "3. Value: actual word representation. We will use the queries and keys to score the word's relevance to the query, and multiply this by the value. \n",
    "\n",
    "An analogy provided by Jay Alammar is thinking about attention as choosing a file from a file cabinet according to information on a post-it note. You can use the post-it note (query) to identify the folder (key) that most matches the topic you are looking up. Then you access the contents of the file (value) according to its relevance to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-example-folders-3.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://jalammar.github.io/illustrated-gpt2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our models, we can encode queries, keys, and values using simple linear layers with the same size (`sequence length, head_size`). During the training process, these layers will be updated to best encode context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 32 # channels\n",
    "head_size = 16\n",
    "\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jzf9VE_AqWeR"
   },
   "source": [
    "The algorithm for self-attention is as follows:\n",
    "\n",
    "1. Generate query, key and value vectors for each word\n",
    "2. Calculate a score for each word in the input sentence against each other.\n",
    "3. Divide the scores by the square root of the dimension of the key vectors to stabilize the gradients. This is then passed through a softmax operation.\n",
    "4. Multiply each value vector by the softmax score.\n",
    "5. Sum up the weighted value vectors to produce the output.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/self-attention-output.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOwm-NkXA8U3"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how attention is performed in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "B,T,C = 4,8,32 # batch, time, channels\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "# Here we want the wei to be data dependent - ie gather info from the past but in a data dependant way\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "k = key(x)   # (B, T, 16) # each token here (totally B*T) produce a key and query in parallel and independently\n",
    "q = query(x) # (B, T, 16)\n",
    "v = value(x)\n",
    "\n",
    "wei =  q @ k.transpose(-2, -1) * head_size**-0.5 # (B, T, 16) @ (B, 16, T) ---> (B, T, T). #\n",
    "wei = F.softmax(wei, dim=-1) # exponentiate and normalize giving a nice distibution that sums to 1 and\n",
    "                             # now it tells us that in a data dependent manner how much of info to aggregate from\n",
    "\n",
    "out = wei @ v # aggregate the attention scores and value vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0618, -0.0091, -0.3488,  0.3208,  0.2971, -0.1573, -0.0561,  0.1068,\n",
      "          0.0368,  0.0139, -0.0017,  0.3110,  0.1404, -0.0158,  0.1853,  0.4290],\n",
      "        [ 0.1578, -0.0971, -0.4256,  0.3538,  0.3621, -0.2392, -0.0536,  0.1759,\n",
      "          0.1115,  0.0282, -0.0649,  0.3641,  0.1928,  0.0261,  0.2162,  0.3758],\n",
      "        [ 0.1293,  0.0759, -0.2946,  0.2292,  0.2215, -0.0710, -0.0107,  0.1616,\n",
      "         -0.0930, -0.0877,  0.0567,  0.1899,  0.0311, -0.0894,  0.0309,  0.5471],\n",
      "        [ 0.1247,  0.1400, -0.2436,  0.1819,  0.1976,  0.0338, -0.0028,  0.1124,\n",
      "         -0.1477, -0.0748,  0.0650,  0.1392, -0.0314, -0.0989,  0.0613,  0.5433],\n",
      "        [ 0.0667,  0.1845, -0.2135,  0.2813,  0.2064,  0.0873,  0.0084,  0.2055,\n",
      "         -0.1130, -0.1466,  0.0459,  0.1923, -0.0275, -0.1107,  0.0065,  0.4674],\n",
      "        [ 0.1924,  0.1693, -0.1568,  0.2284,  0.1620,  0.0737,  0.0443,  0.2519,\n",
      "         -0.1912, -0.1979,  0.0832,  0.0713, -0.0826, -0.0848, -0.1047,  0.6089],\n",
      "        [ 0.1184,  0.0884, -0.2652,  0.2560,  0.1840,  0.0284, -0.0621,  0.1181,\n",
      "         -0.0880,  0.0104,  0.1123,  0.1850,  0.0369, -0.0730,  0.0663,  0.5242],\n",
      "        [ 0.1243,  0.0453, -0.3412,  0.2709,  0.2335, -0.0948, -0.0421,  0.2143,\n",
      "         -0.0330, -0.0313,  0.0520,  0.2378,  0.1084, -0.0959,  0.0300,  0.4707]],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4lwyFlxKW6oA"
   },
   "source": [
    "### Multi-head attention\n",
    "\n",
    "In practice, multiple attention heads are used which\n",
    "1. Expands the model‚Äôs ability to focus on different positions and prevent the attention to be dominated by the word itself.\n",
    "2. Have multiple ‚Äúrepresentation subspaces‚Äù. Have multiple sets of Query/Key/Value weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_multi-headed_self-attention-recap.png\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6oHsezdVBIaf"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see attention mechanisms in action!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the powerful visualization tool bertviz, which allows an interactive experience of the attention mechanisms. Normally these mechanisms are abstracted away but this will allow us to inspect our model in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bertviz in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (1.4.0)\n",
      "Requirement already satisfied: transformers>=2.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (4.38.2)\n",
      "Requirement already satisfied: torch>=1.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (2.2.1)\n",
      "Requirement already satisfied: tqdm in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (4.66.2)\n",
      "Requirement already satisfied: boto3 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (1.34.60)\n",
      "Requirement already satisfied: requests in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (2.31.0)\n",
      "Requirement already satisfied: regex in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (2023.12.25)\n",
      "Requirement already satisfied: sentencepiece in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from bertviz) (0.2.0)\n",
      "Requirement already satisfied: filelock in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.0->bertviz) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.0->bertviz) (4.10.0)\n",
      "Requirement already satisfied: sympy in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.0->bertviz) (1.12)\n",
      "Requirement already satisfied: networkx in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.0->bertviz) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.0->bertviz) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from torch>=1.0->bertviz) (2024.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from transformers>=2.0->bertviz) (0.21.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from transformers>=2.0->bertviz) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from transformers>=2.0->bertviz) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from transformers>=2.0->bertviz) (6.0.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from transformers>=2.0->bertviz) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from transformers>=2.0->bertviz) (0.4.2)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.60 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from boto3->bertviz) (1.34.60)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from boto3->bertviz) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from boto3->bertviz) (0.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->bertviz) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->bertviz) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->bertviz) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from requests->bertviz) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from botocore<1.35.0,>=1.34.60->boto3->bertviz) (2.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from jinja2->torch>=1.0->bertviz) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/hwpang/miniforge3/envs/alcf_training/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.60->boto3->bertviz) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install bertviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the model, GPT2 and look at the attention mechanisms. \n",
    "\n",
    "**Hint... click on the different blocks in the visualization to see the attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\"></script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "      \n",
       "        <div id=\"bertviz-43e94066d0a34bdbbbf570b94f4258a7\" style=\"font-family:'Helvetica Neue', Helvetica, Arial, sans-serif;\">\n",
       "            <span style=\"user-select:none\">\n",
       "                \n",
       "            </span>\n",
       "            <div id='vis'></div>\n",
       "        </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "/**\n * @fileoverview Transformer Visualization D3 javascript code.\n *\n * Based on: https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/visualization/attention.js\n *\n * Change log:\n *\n * 02/01/19  Jesse Vig   Initial implementation\n * 12/31/20  Jesse Vig   Support multiple visualizations in single notebook.\n * 01/19/21  Jesse Vig   Support light/dark modes\n * 02/06/21  Jesse Vig   Move require config from separate jupyter notebook step\n * 05/03/21  Jesse Vig   Adjust visualization height dynamically\n * 03/23/22  Daniel SC   Update requirement URLs for d3 and jQuery (source of bug not allowing end result to be displayed on browsers)\n **/\n\nrequire.config({\n  paths: {\n      d3: 'https://cdnjs.cloudflare.com/ajax/libs/d3/5.7.0/d3.min',\n    jquery: 'https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.0/jquery.min',\n  }\n});\n\nrequirejs(['jquery', 'd3'], function($, d3) {\n\n        const params = {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780126720666885, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792066276073456, 0.2121374011039734, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301144361496, 0.1275128275156021, 0.08361561596393585, 0.04182284325361252, 0.0], [0.27288734912872314, 0.11203355342149734, 0.1663985401391983, 0.08467110991477966, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448002859950066, 0.9890841841697693, 0.0, 0.0, 0.0], [0.00012328459706623107, 0.0018733164761215448, 0.013126970268785954, 0.9848763942718506, 0.0, 0.0], [0.00106695550493896, 0.001136626466177404, 0.0030349940061569214, 0.0015735073247924447, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437359688803554, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578442096710205, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906046032905579, 0.2486610859632492, 0.1607343554496765, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457565546035767, 0.11392831057310104, 0.0, 0.0], [0.45094069838523865, 0.16486799716949463, 0.17318037152290344, 0.11748009920120239, 0.0935307964682579, 0.0], [0.425724595785141, 0.17328649759292603, 0.15651948750019073, 0.07022647559642792, 0.08087009936571121, 0.09337282925844193]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133622527122498, 0.38663774728775024, 0.0, 0.0, 0.0, 0.0], [0.06098512187600136, 0.0325346402823925, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717088632285595, 0.00040128850378096104, 0.7572957873344421, 0.23558583855628967, 0.0, 0.0], [0.03722767159342766, 0.002948855282738805, 0.1008109450340271, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.002419827738776803, 0.003433502744883299, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.05104445293545723, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.13952414691448212, 0.17833498120307922, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399299949407578, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440174341202, 0.07926186174154282, 0.17836196720600128, 0.3331669867038727, 0.0], [0.09464019536972046, 0.007428212556988001, 0.006983975879848003, 0.0071843755431473255, 0.018724266439676285, 0.8650389313697815]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834612369537354, 0.6616538763046265, 0.0, 0.0, 0.0, 0.0], [0.07855997234582901, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.016775991767644882, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.02760043926537037, 0.00044415253796614707, 0.0006541680195368826, 0.00022661880939267576, 0.971074640750885, 0.0], [0.01024820376187563, 3.70155721611809e-05, 0.00016064057126641273, 2.7341844543116167e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496658489108086, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467936769127846, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248183369636536, 0.0, 0.0], [0.6015855669975281, 0.09881887584924698, 0.07070109248161316, 0.16652536392211914, 0.062369026243686676, 0.0], [0.3232504427433014, 0.12567414343357086, 0.04432179406285286, 0.07076980918645859, 0.06606650352478027, 0.3699173331260681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986407995224, 0.39703118801116943, 0.14310474693775177, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181743383407593, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963918089866638, 0.1376371681690216, 0.20173481106758118, 0.23632165789604187, 0.23466715216636658, 0.0], [0.15410438179969788, 0.09489505738019943, 0.11902564018964767, 0.10277966409921646, 0.431721955537796, 0.09747330099344254]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36500000953674316, 0.6349999904632568, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.202127605676651, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738624334335327, 0.25186213850975037, 0.06861571967601776, 0.0, 0.0], [0.10242554545402527, 0.16683614253997803, 0.5248050093650818, 0.054454635828733444, 0.15147866308689117, 0.0], [0.25029510259628296, 0.22198131680488586, 0.18899966776371002, 0.10677117109298706, 0.13032673299312592, 0.10162606835365295]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.300949364900589, 0.0, 0.0, 0.0, 0.0], [0.5107942223548889, 0.2948642075061798, 0.1943414956331253, 0.0, 0.0, 0.0], [0.4604707360267639, 0.28051912784576416, 0.1917480230331421, 0.06726215034723282, 0.0, 0.0], [0.376484215259552, 0.21120665967464447, 0.20214541256427765, 0.10207021981477737, 0.10809355229139328, 0.0], [0.30138447880744934, 0.20456178486347198, 0.1825033575296402, 0.11019384860992432, 0.16291266679763794, 0.03844384476542473]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131581902503967, 0.28684180974960327, 0.0, 0.0, 0.0, 0.0], [0.40588000416755676, 0.18063294887542725, 0.4134870171546936, 0.0, 0.0, 0.0], [0.2655460834503174, 0.16985861957073212, 0.3358592689037323, 0.22873596847057343, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928361773490906, 0.053776707500219345, 0.29991865158081055, 0.0], [0.20466557145118713, 0.18731121718883514, 0.15959152579307556, 0.06381776928901672, 0.03642302379012108, 0.34819096326828003]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776823043823, 0.3160034418106079, 0.09221882373094559, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586949706077576, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.09920340776443481, 0.13881628215312958, 0.0], [0.32743728160858154, 0.19600817561149597, 0.06805712729692459, 0.0892510786652565, 0.11618079245090485, 0.20306554436683655]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448371924459934, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906113028526306, 0.07145344465970993, 0.0, 0.0, 0.0], [0.3800053596496582, 0.04127565026283264, 0.5496611595153809, 0.029057765379548073, 0.0, 0.0], [0.2144523561000824, 0.05088743939995766, 0.43174391984939575, 0.2586929202079773, 0.04422333091497421, 0.0], [0.11175251752138138, 0.017593061551451683, 0.027507437393069267, 0.04086765646934509, 0.7754672169685364, 0.02681213989853859]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285966753959656, 0.07140327990055084, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012863248586655, 0.0, 0.0, 0.0], [0.49429091811180115, 0.28503692150115967, 0.1184932291507721, 0.10217896103858948, 0.0, 0.0], [0.41838788986206055, 0.23117896914482117, 0.08340625464916229, 0.11365951597690582, 0.1533673107624054, 0.0], [0.4221589267253876, 0.12917141616344452, 0.08740925043821335, 0.10163748264312744, 0.21230244636535645, 0.0473204143345356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786477088928223, 0.021352343261241913, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.0651036724448204, 0.15998412668704987, 0.0, 0.0, 0.0], [0.6484924554824829, 0.0748312845826149, 0.14751607179641724, 0.12916018068790436, 0.0, 0.0], [0.5224639773368835, 0.06921806186437607, 0.13823406398296356, 0.11106578260660172, 0.15901808440685272, 0.0], [0.39645180106163025, 0.07325819134712219, 0.12938153743743896, 0.10642421990633011, 0.14864003658294678, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525904297828674, 0.4474095404148102, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259160041809, 0.22387316823005676, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964673459529877, 0.15491966903209686, 0.17112070322036743, 0.0, 0.0], [0.5039963126182556, 0.11401881277561188, 0.11974023282527924, 0.1255258023738861, 0.13671885430812836, 0.0], [0.5061841011047363, 0.08567393571138382, 0.0890302062034607, 0.09759815782308578, 0.10275726765394211, 0.1187562420964241]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257424831390381, 0.07932532578706741, 0.0949321985244751, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320429503917694, 0.0, 0.0], [0.6383237838745117, 0.0788639485836029, 0.07815034687519073, 0.08758100867271423, 0.11708094924688339, 0.0], [0.5552157163619995, 0.07409123331308365, 0.06834892928600311, 0.07778594642877579, 0.09999319165945053, 0.1245650053024292]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578914999961853, 0.1421085000038147, 0.0, 0.0, 0.0, 0.0], [0.6423038840293884, 0.1662902981042862, 0.19140584766864777, 0.0, 0.0, 0.0], [0.553097665309906, 0.10609276592731476, 0.07821261882781982, 0.26259690523147583, 0.0, 0.0], [0.40121686458587646, 0.12223610281944275, 0.19347301125526428, 0.1416463404893875, 0.141427680850029, 0.0], [0.4021257758140564, 0.18450741469860077, 0.07516802847385406, 0.05849042534828186, 0.1444634199142456, 0.13524499535560608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233254820108414, 0.05468339845538139, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.030065858736634254, 0.0, 0.0], [0.6819812059402466, 0.049908217042684555, 0.08296556770801544, 0.08369525521993637, 0.10144972801208496, 0.0], [0.40566906332969666, 0.0733766257762909, 0.08601399511098862, 0.061709318310022354, 0.13226418197155, 0.24096690118312836]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670192003250122, 0.032980870455503464, 0.0, 0.0, 0.0, 0.0], [0.8449063301086426, 0.0851450189948082, 0.06994856148958206, 0.0, 0.0, 0.0], [0.712357223033905, 0.07896044850349426, 0.05541076511144638, 0.15327154099941254, 0.0, 0.0], [0.6402612924575806, 0.0739755630493164, 0.044393084943294525, 0.14322125911712646, 0.09814874082803726, 0.0], [0.5073903799057007, 0.07523056864738464, 0.07754651457071304, 0.11362487822771072, 0.13947953283786774, 0.0867280513048172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487567901611328, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107235193252563, 0.037362754344940186, 0.0, 0.0, 0.0], [0.750551700592041, 0.11348950117826462, 0.061799634248018265, 0.0741591602563858, 0.0, 0.0], [0.6614720225334167, 0.10242638736963272, 0.052934251725673676, 0.0752970427274704, 0.10787028074264526, 0.0], [0.6014200448989868, 0.1134038195014, 0.05631931126117706, 0.07096722722053528, 0.10906289517879486, 0.04882662743330002]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.944548487663269, 0.05545153468847275, 0.0, 0.0, 0.0, 0.0], [0.8874567747116089, 0.054742176085710526, 0.05780100077390671, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895003467798233, 0.05903465300798416, 0.043826356530189514, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629696935415268, 0.05417948588728905, 0.11905863881111145, 0.0], [0.7367821931838989, 0.05611901357769966, 0.06857296824455261, 0.03421955928206444, 0.07875380665063858, 0.025552431121468544]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913392090704292, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981205708347261, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648472674190998, 0.34519824385643005, 0.30852681398391724, 0.3455100953578949, 0.0, 0.0], [0.0010283150477334857, 0.24135905504226685, 0.23320144414901733, 0.2555713355541229, 0.26883992552757263, 0.0], [0.0009746805299073458, 0.17789693176746368, 0.16743157804012299, 0.18587595224380493, 0.1873445361852646, 0.28047627210617065]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8244929313659668, 0.1755070984363556, 0.0, 0.0, 0.0, 0.0], [0.123868927359581, 0.0444999635219574, 0.8316311240196228, 0.0, 0.0, 0.0], [0.079243503510952, 0.01296587847173214, 0.0015277144266292453, 0.9062629342079163, 0.0, 0.0], [0.0880640298128128, 0.02134104259312153, 0.0028886180371046066, 0.0028453818522393703, 0.8848609328269958, 0.0], [0.09983208775520325, 0.03363381698727608, 0.005499974358826876, 0.0024330471642315388, 0.0015082373283803463, 0.8570928573608398]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531069681048393, 0.0, 0.0, 0.0, 0.0], [0.7529155611991882, 0.08733483403921127, 0.1597496122121811, 0.0, 0.0, 0.0], [0.42022812366485596, 0.0919511616230011, 0.23549865186214447, 0.25232207775115967, 0.0, 0.0], [0.3084891736507416, 0.059081461280584335, 0.38391315937042236, 0.15659154951572418, 0.09192463755607605, 0.0], [0.4479040205478668, 0.04329320415854454, 0.07969193160533905, 0.11081938445568085, 0.22124597430229187, 0.09704560786485672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904012851417065, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.02608449012041092, 0.004147926811128855, 0.0, 0.0, 0.0], [0.9082902073860168, 0.03320598229765892, 0.009421163238584995, 0.049082621932029724, 0.0, 0.0], [0.8949132561683655, 0.055445630103349686, 0.0055776298977434635, 0.031506892293691635, 0.012556551024317741, 0.0], [0.8497739434242249, 0.028890099376440048, 0.003664793213829398, 0.037519875913858414, 0.03842782601714134, 0.04172348231077194]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947787284851074, 0.4812198877334595, 0.02930225431919098, 0.0, 0.0, 0.0], [0.11772128194570541, 0.1312120407819748, 0.6702316999435425, 0.08083496987819672, 0.0, 0.0], [0.13043686747550964, 0.04068691283464432, 0.2652047574520111, 0.41143539547920227, 0.1522361934185028, 0.0], [0.1266181319952011, 0.03275136649608612, 0.03567884862422943, 0.06039205193519592, 0.6021828055381775, 0.14237675070762634]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.01948235183954239, 0.0, 0.0, 0.0, 0.0], [0.7948846220970154, 0.12061934918165207, 0.08449608087539673, 0.0, 0.0, 0.0], [0.561235249042511, 0.15743158757686615, 0.20339740812778473, 0.07793577015399933, 0.0, 0.0], [0.4258372187614441, 0.1074204370379448, 0.151236891746521, 0.08755026012659073, 0.227955162525177, 0.0], [0.24752575159072876, 0.024188309907913208, 0.03039529360830784, 0.08586953580379486, 0.5714344382286072, 0.040586717426776886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572690844535828, 0.22317378222942352, 0.01955713890492916, 0.0, 0.0, 0.0], [0.5341876745223999, 0.22107593715190887, 0.1762186586856842, 0.06851772964000702, 0.0, 0.0], [0.17095263302326202, 0.08229422569274902, 0.5760225057601929, 0.11097591370344162, 0.05975468084216118, 0.0], [0.24871118366718292, 0.08880820125341415, 0.08980222791433334, 0.0972934141755104, 0.44130849838256836, 0.03407648205757141]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.84221351146698, 0.1577865183353424, 0.0, 0.0, 0.0, 0.0], [0.46841272711753845, 0.4610536992549896, 0.07053355872631073, 0.0, 0.0, 0.0], [0.2588139772415161, 0.4635891318321228, 0.18503500521183014, 0.09256189316511154, 0.0, 0.0], [0.18399538099765778, 0.2915422320365906, 0.17031094431877136, 0.27172988653182983, 0.08242153376340866, 0.0], [0.16469836235046387, 0.24726982414722443, 0.08770570158958435, 0.22575023770332336, 0.17745378613471985, 0.09712209552526474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005395531654358, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.04406510293483734, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582223057746887, 0.05534825101494789, 0.04041941091418266, 0.04601002112030983, 0.0, 0.0], [0.7855252027511597, 0.04124240577220917, 0.0836929976940155, 0.04887611046433449, 0.04066324606537819, 0.0], [0.7856316566467285, 0.05014647915959358, 0.047512687742710114, 0.027365945279598236, 0.056147508323192596, 0.03319566696882248]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041034579277039, 0.09589657187461853, 0.0, 0.0, 0.0, 0.0], [0.5862313508987427, 0.0719982385635376, 0.3417704105377197, 0.0, 0.0, 0.0], [0.3878958523273468, 0.046608101576566696, 0.20279009640216827, 0.3627060055732727, 0.0, 0.0], [0.26652413606643677, 0.02453301101922989, 0.12211944907903671, 0.20041222870349884, 0.386411190032959, 0.0], [0.2335742861032486, 0.020537355914711952, 0.09610342979431152, 0.13062255084514618, 0.22990457713603973, 0.2892577648162842]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008838564157486, 0.0, 0.0, 0.0, 0.0], [0.7075549364089966, 0.25427794456481934, 0.03816715627908707, 0.0, 0.0, 0.0], [0.2566525936126709, 0.20589333772659302, 0.0166566651314497, 0.5207974314689636, 0.0, 0.0], [0.10379378497600555, 0.04639103636145592, 0.008698646910488605, 0.7866851687431335, 0.05443137139081955, 0.0], [0.22143368422985077, 0.03379754349589348, 0.02902398630976677, 0.5412925481796265, 0.15286068618297577, 0.021591559052467346]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829629376530647, 0.0, 0.0, 0.0, 0.0], [0.791315495967865, 0.12309640645980835, 0.08558814227581024, 0.0, 0.0, 0.0], [0.2954595983028412, 0.15808328986167908, 0.421724408864975, 0.12473269551992416, 0.0, 0.0], [0.2344098538160324, 0.09886544197797775, 0.3316018581390381, 0.19713956117630005, 0.1379833221435547, 0.0], [0.19728359580039978, 0.05741845443844795, 0.06909029930830002, 0.1646983027458191, 0.2797278165817261, 0.23178145289421082]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.06408719718456268, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673479408025742, 0.12440250813961029, 0.0, 0.0, 0.0], [0.6535120010375977, 0.07573550939559937, 0.09732569009065628, 0.1734268069267273, 0.0, 0.0], [0.5222766399383545, 0.05827883630990982, 0.09920477867126465, 0.17020843923091888, 0.15003135800361633, 0.0], [0.41088414192199707, 0.047306060791015625, 0.07265680283308029, 0.10560746490955353, 0.10550005733966827, 0.2580455541610718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.896539568901062, 0.03887060284614563, 0.0645897388458252, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213467076420784, 0.05196719989180565, 0.08940290659666061, 0.0, 0.0], [0.7718175053596497, 0.030402889475226402, 0.04582744464278221, 0.07118470221757889, 0.08076753467321396, 0.0], [0.7292330265045166, 0.021699870005249977, 0.033074770122766495, 0.047200947999954224, 0.06474558264017105, 0.10404574126005173]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.002043285872787237, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802532583475113, 0.03668050840497017, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755579072982073, 0.0020629873033612967, 0.06971046328544617, 0.0, 0.0], [0.8660573363304138, 0.003888371866196394, 0.0006785969599150121, 0.0006981453043408692, 0.12867748737335205, 0.0], [0.8455931544303894, 0.0037804031744599342, 0.0002534222148824483, 6.027047857060097e-05, 0.00011820740473922342, 0.15019452571868896]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262452721595764, 0.0737547054886818, 0.0, 0.0, 0.0, 0.0], [0.7717155814170837, 0.16241982579231262, 0.06586461514234543, 0.0, 0.0, 0.0], [0.8167634010314941, 0.07807183265686035, 0.06324050575494766, 0.04192419722676277, 0.0, 0.0], [0.6867184042930603, 0.07755175232887268, 0.10056906193494797, 0.059550799429416656, 0.07560998201370239, 0.0], [0.6421160101890564, 0.11014913767576218, 0.0768820121884346, 0.054033394902944565, 0.10333629697561264, 0.013483160175383091]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395952820777893, 0.0604046992957592, 0.0, 0.0, 0.0, 0.0], [0.23004570603370667, 0.6617382168769836, 0.10821598768234253, 0.0, 0.0, 0.0], [0.2670212686061859, 0.36079588532447815, 0.32496336102485657, 0.04721950367093086, 0.0, 0.0], [0.595202624797821, 0.12269263714551926, 0.0630204826593399, 0.08916771411895752, 0.12991654872894287, 0.0], [0.10284564644098282, 0.02938022091984749, 0.013739144429564476, 0.045860543847084045, 0.7698503136634827, 0.03832409530878067]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040981531143188, 0.09590183943510056, 0.0, 0.0, 0.0, 0.0], [0.3572389781475067, 0.6274600625038147, 0.015300886705517769, 0.0, 0.0, 0.0], [0.5917983055114746, 0.27640461921691895, 0.10476133972406387, 0.02703571505844593, 0.0, 0.0], [0.7254412770271301, 0.049831323325634, 0.014982974156737328, 0.1778138279914856, 0.03193071112036705, 0.0], [0.7612766623497009, 0.061589207500219345, 0.005942226853221655, 0.016426678746938705, 0.12677942216396332, 0.02798573672771454]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.0052412403747439384, 0.0, 0.0, 0.0, 0.0], [0.963241457939148, 0.017816441133618355, 0.018942032009363174, 0.0, 0.0, 0.0], [0.9671075940132141, 0.008509601466357708, 0.008562229573726654, 0.01582048460841179, 0.0, 0.0], [0.9340997338294983, 0.011952393688261509, 0.02018018066883087, 0.026750795543193817, 0.007016893941909075, 0.0], [0.9587237238883972, 0.004657106939703226, 0.0033267769031226635, 0.006545298267155886, 0.010182461701333523, 0.01656450144946575]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000916466116905, 0.0, 0.0, 0.0, 0.0], [0.7917606830596924, 0.1753322035074234, 0.03290712088346481, 0.0, 0.0, 0.0], [0.7949190735816956, 0.10531847923994064, 0.04021858796477318, 0.05954387038946152, 0.0, 0.0], [0.7097724080085754, 0.10552516579627991, 0.0659755989909172, 0.05765584483742714, 0.061070967465639114, 0.0], [0.7506605386734009, 0.026514414697885513, 0.021575985476374626, 0.03429659456014633, 0.08494436740875244, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248326748609543, 0.0, 0.0, 0.0, 0.0], [0.5615501403808594, 0.08956822007894516, 0.34888166189193726, 0.0, 0.0, 0.0], [0.3292894661426544, 0.024114856496453285, 0.5428069829940796, 0.10378868877887726, 0.0, 0.0], [0.3433028757572174, 0.013086398132145405, 0.5121980905532837, 0.11146178841590881, 0.019950786605477333, 0.0], [0.479281485080719, 0.01733359508216381, 0.11805380880832672, 0.061302732676267624, 0.20071853697299957, 0.12330985069274902]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115325286984444, 0.0, 0.0, 0.0, 0.0], [0.5282702445983887, 0.32922643423080444, 0.14250332117080688, 0.0, 0.0, 0.0], [0.48788580298423767, 0.2336864322423935, 0.1757809817790985, 0.10264680534601212, 0.0, 0.0], [0.314447283744812, 0.18065206706523895, 0.16871440410614014, 0.09506572037935257, 0.24112050235271454, 0.0], [0.5168745517730713, 0.03589726984500885, 0.026188218966126442, 0.04039734974503517, 0.18791824579238892, 0.19272442162036896]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750303387641907, 0.12496966868638992, 0.0, 0.0, 0.0, 0.0], [0.4550611078739166, 0.4900429844856262, 0.05489587038755417, 0.0, 0.0, 0.0], [0.29337161779403687, 0.5449912548065186, 0.09444315731525421, 0.06719394773244858, 0.0, 0.0], [0.48970794677734375, 0.27210018038749695, 0.06861996650695801, 0.1469479650259018, 0.022623907774686813, 0.0], [0.4729057848453522, 0.08103127777576447, 0.016052212566137314, 0.30672261118888855, 0.10120765119791031, 0.02208036370575428]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697787597775459, 0.0, 0.0, 0.0, 0.0], [0.7557193040847778, 0.164363831281662, 0.0799168273806572, 0.0, 0.0, 0.0], [0.6947702169418335, 0.08409861475229263, 0.06382618844509125, 0.15730492770671844, 0.0, 0.0], [0.5821161866188049, 0.03297793120145798, 0.07936564832925797, 0.1944134384393692, 0.11112679541110992, 0.0], [0.5974540710449219, 0.04261098429560661, 0.06919704377651215, 0.1456344574689865, 0.12481749057769775, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815646052360535, 0.0, 0.0, 0.0], [0.8435326218605042, 0.01569502428174019, 0.04575122147798538, 0.09502112865447998, 0.0, 0.0], [0.7724100351333618, 0.01198125071823597, 0.03504614159464836, 0.038767702877521515, 0.1417948305606842, 0.0], [0.7642909288406372, 0.009868795052170753, 0.008122756145894527, 0.013314363546669483, 0.04824389889836311, 0.15615925192832947]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988227643072605, 0.0, 0.0, 0.0, 0.0], [0.656400740146637, 0.22506137192249298, 0.11853783577680588, 0.0, 0.0, 0.0], [0.6958051919937134, 0.14701884984970093, 0.0714603066444397, 0.08571569621562958, 0.0, 0.0], [0.6353278756141663, 0.13460659980773926, 0.030994264408946037, 0.05691635236144066, 0.14215490221977234, 0.0], [0.6779390573501587, 0.05365435406565666, 0.018006397411227226, 0.06284541636705399, 0.11038216948509216, 0.07717254012823105]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.01776665635406971, 0.0, 0.0, 0.0, 0.0], [0.9037665128707886, 0.06541507691144943, 0.030818404629826546, 0.0, 0.0, 0.0], [0.8119190335273743, 0.03679019585251808, 0.06056112423539162, 0.09072960913181305, 0.0, 0.0], [0.4054649770259857, 0.10383855551481247, 0.10211297124624252, 0.35434144735336304, 0.03424210846424103, 0.0], [0.22824402153491974, 0.01727871596813202, 0.05055490508675575, 0.60157310962677, 0.09411770850419998, 0.008231508545577526]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445892810821533, 0.5317586660385132, 0.11378246545791626, 0.0, 0.0, 0.0], [0.07823362201452255, 0.7221351265907288, 0.10936681926250458, 0.09026447683572769, 0.0, 0.0], [0.21967922151088715, 0.4048427939414978, 0.12358146905899048, 0.20018842816352844, 0.0517081543803215, 0.0], [0.3608972728252411, 0.10459017753601074, 0.06983830779790878, 0.29764848947525024, 0.13869914412498474, 0.02832675352692604]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.026783782988786697, 0.0, 0.0, 0.0, 0.0], [0.9167556166648865, 0.061452481895685196, 0.02179187908768654, 0.0, 0.0, 0.0], [0.8543080687522888, 0.08049603551626205, 0.030334968119859695, 0.034860968589782715, 0.0, 0.0], [0.8919214606285095, 0.04280785843729973, 0.022045092657208443, 0.023470696061849594, 0.019754959270358086, 0.0], [0.8116771578788757, 0.03413521125912666, 0.0356765016913414, 0.047485724091529846, 0.02539709210395813, 0.04562826454639435]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761363983154, 0.049723830074071884, 0.0, 0.0, 0.0, 0.0], [0.7637463212013245, 0.20073527097702026, 0.035518381744623184, 0.0, 0.0, 0.0], [0.6279093027114868, 0.03768132999539375, 0.19945405423641205, 0.13495533168315887, 0.0, 0.0], [0.6397068500518799, 0.027007201686501503, 0.09082008898258209, 0.2065378874540329, 0.03592789173126221, 0.0], [0.4559430480003357, 0.02164110541343689, 0.12939560413360596, 0.2180090695619583, 0.10379841923713684, 0.07121271640062332]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.949840784072876, 0.05015929415822029, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.08722192794084549, 0.04390566796064377, 0.0, 0.0, 0.0], [0.6937949657440186, 0.06359197199344635, 0.09179069846868515, 0.1508224457502365, 0.0, 0.0], [0.7266592979431152, 0.0438988097012043, 0.04683993384242058, 0.09851823002099991, 0.084083691239357, 0.0], [0.7848989963531494, 0.03714786469936371, 0.012907862663269043, 0.01053939014673233, 0.12079212069511414, 0.03371364623308182]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.010894596576690674, 0.0, 0.0, 0.0, 0.0], [0.8929520845413208, 0.08700034022331238, 0.020047562196850777, 0.0, 0.0, 0.0], [0.7891120910644531, 0.0979725793004036, 0.08633225411176682, 0.026582974940538406, 0.0, 0.0], [0.8850637078285217, 0.036449968814849854, 0.053954605013132095, 0.012377229519188404, 0.012154524214565754, 0.0], [0.6861334443092346, 0.05720369145274162, 0.011636318638920784, 0.021660534664988518, 0.17487967014312744, 0.04848628118634224]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396193027496338, 0.06038069725036621, 0.0, 0.0, 0.0, 0.0], [0.7851802110671997, 0.19751375913619995, 0.01730608195066452, 0.0, 0.0, 0.0], [0.7660508155822754, 0.1544468104839325, 0.03188299760222435, 0.04761935770511627, 0.0, 0.0], [0.7035229206085205, 0.0517142117023468, 0.07761009782552719, 0.1533903032541275, 0.013762438669800758, 0.0], [0.7121880650520325, 0.04994235187768936, 0.03772565349936485, 0.08649145811796188, 0.06541427969932556, 0.048238206654787064]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927728042006493, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.011715562082827091, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106766819953918, 0.007296766620129347, 0.03961999714374542, 0.4424065053462982, 0.0, 0.0], [0.5862478017807007, 0.012099698185920715, 0.024585217237472534, 0.06737837195396423, 0.3096889853477478, 0.0], [0.3019629716873169, 0.007724009454250336, 0.011518126353621483, 0.04694725573062897, 0.22146691381931305, 0.41038069128990173]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.025544624775648117, 0.0, 0.0, 0.0, 0.0], [0.9769196510314941, 0.015048498287796974, 0.008031906560063362, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875406339764595, 0.0259548369795084, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665185675025, 0.005828304681926966, 0.031757812947034836, 0.01684906892478466, 0.0], [0.9105739593505859, 0.00197521666996181, 0.008646715432405472, 0.013360830023884773, 0.03543954715132713, 0.030003638938069344]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444867730140686, 0.1350778490304947, 0.02043532207608223, 0.0, 0.0, 0.0], [0.79030841588974, 0.145591601729393, 0.03753012418746948, 0.026569755747914314, 0.0, 0.0], [0.7298934459686279, 0.05649610608816147, 0.03273553401231766, 0.10400418937206268, 0.07687069475650787, 0.0], [0.5684201121330261, 0.0438881553709507, 0.026293382048606873, 0.08117102831602097, 0.24314747750759125, 0.0370798297226429]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001312494277954, 0.0, 0.0, 0.0, 0.0], [0.9336171746253967, 0.05848865583539009, 0.007894255220890045, 0.0, 0.0, 0.0], [0.7897833585739136, 0.11071822792291641, 0.05360185354948044, 0.045896612107753754, 0.0, 0.0], [0.885930061340332, 0.05752985551953316, 0.013743252493441105, 0.0033877433743327856, 0.03940894454717636, 0.0], [0.9337607622146606, 0.026470622047781944, 0.004523388110101223, 0.006190470885485411, 0.014132914133369923, 0.014921694993972778]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521260081172386e-09, 0.0, 0.0, 0.0, 0.0], [6.675903478026157e-06, 0.9999804496765137, 1.2841342140745837e-05, 0.0, 0.0, 0.0], [2.2193603399500716e-08, 2.6684225939987982e-09, 0.9999971389770508, 2.8136612399976e-06, 0.0, 0.0], [1.0145256510440959e-06, 4.46400640896627e-08, 0.0003535630239639431, 0.9993677735328674, 0.00027762516401708126, 0.0], [9.43658595708996e-10, 1.3820626067195807e-11, 5.017902204862423e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8643494260904845e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.00513676879927516, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832391880452633, 0.054254528135061264, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143425729125738, 0.004314453341066837, 0.02364284358918667, 0.0, 0.0], [0.8999071717262268, 0.0014671594835817814, 0.0002913369389716536, 0.002585020614787936, 0.09574926644563675, 0.0], [0.9386116862297058, 0.00022248283494263887, 0.0006146674859337509, 0.001549566863104701, 0.030689409002661705, 0.02831234037876129]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042728050990263e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613893381494563e-06, 0.0017206610646098852, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376221790560521e-07, 0.00011847093992400914, 0.0, 0.0], [0.9996154308319092, 3.4731661457954033e-07, 3.892111877235038e-08, 4.4684205136036326e-07, 0.0003836941614281386, 0.0], [0.9994840621948242, 1.6550078640875654e-08, 2.8715612998553297e-08, 1.0638264029694255e-06, 0.0002126663748640567, 0.00030211807461455464]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.04858642816543579, 0.0, 0.0, 0.0, 0.0], [0.5749937295913696, 0.39028200507164, 0.03472421318292618, 0.0, 0.0, 0.0], [0.744231641292572, 0.17524123191833496, 0.0756477639079094, 0.004879268351942301, 0.0, 0.0], [0.5232070088386536, 0.0942932739853859, 0.11381909251213074, 0.199792742729187, 0.06888788938522339, 0.0], [0.47472670674324036, 0.05636586248874664, 0.04530372843146324, 0.06967273354530334, 0.3098013997077942, 0.044129498302936554]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734647035598755, 0.12653528153896332, 0.0, 0.0, 0.0, 0.0], [0.6097909212112427, 0.3541729152202606, 0.036036167293787, 0.0, 0.0, 0.0], [0.45984145998954773, 0.3869791030883789, 0.09960132837295532, 0.0535782128572464, 0.0, 0.0], [0.5722206234931946, 0.23636245727539062, 0.08344567567110062, 0.06921914219856262, 0.03875211626291275, 0.0], [0.5143572092056274, 0.16723047196865082, 0.0901939794421196, 0.0765446126461029, 0.1057807207107544, 0.045892927795648575]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771260976791382, 0.0, 0.0, 0.0, 0.0], [0.6142943501472473, 0.3503974974155426, 0.03530814126133919, 0.0, 0.0, 0.0], [0.5770685076713562, 0.32858479022979736, 0.055082615464925766, 0.039264190942049026, 0.0, 0.0], [0.1718820184469223, 0.011042507365345955, 0.05457884445786476, 0.7326582670211792, 0.02983839437365532, 0.0], [0.3783011734485626, 0.017070064321160316, 0.021754175424575806, 0.44096899032592773, 0.06093829870223999, 0.0809672474861145]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688738871365786, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.01670977473258972, 0.033411506563425064, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787282276898623, 0.0006868182099424303, 0.002304845955222845, 0.0, 0.0], [0.9935757517814636, 0.0032635012175887823, 0.0009993863059207797, 0.0002793227322399616, 0.0018820592667907476, 0.0], [0.9907532930374146, 0.00021344238484743983, 0.00045952422078698874, 0.0007905613165348768, 0.004424726124852896, 0.0033583571203052998]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.964773952960968, 0.03522602468729019, 0.0, 0.0, 0.0, 0.0], [0.8194128274917603, 0.1365438550710678, 0.04404330253601074, 0.0, 0.0, 0.0], [0.7584255337715149, 0.006878912448883057, 0.20653310418128967, 0.028162462636828423, 0.0, 0.0], [0.5298123359680176, 0.002678809454664588, 0.07857999205589294, 0.3598378598690033, 0.029091043397784233, 0.0], [0.754441499710083, 0.0003678227076306939, 0.001971352146938443, 0.0032400530762970448, 0.19423414766788483, 0.04574509337544441]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749132394790649, 0.02508675493299961, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705658718943596, 0.01229624543339014, 0.0, 0.0, 0.0], [0.9305250644683838, 0.05277106165885925, 0.011119479313492775, 0.005584415048360825, 0.0, 0.0], [0.8863321542739868, 0.012924151495099068, 0.017724741250276566, 0.06150190532207489, 0.02151712030172348, 0.0], [0.7916855216026306, 0.015036052092909813, 0.03174784779548645, 0.033921852707862854, 0.0370795801281929, 0.0905291959643364]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608500599861145, 0.039149921387434006, 0.0, 0.0, 0.0, 0.0], [0.9121274352073669, 0.022576449438929558, 0.06529611349105835, 0.0, 0.0, 0.0], [0.9364107251167297, 0.015584415756165981, 0.0245449710637331, 0.0234599057585001, 0.0, 0.0], [0.9454621076583862, 0.006762259639799595, 0.022026216611266136, 0.009137730114161968, 0.016611695289611816, 0.0], [0.8346174955368042, 0.001881692442111671, 0.005609028972685337, 0.018873492255806923, 0.12449129670858383, 0.014527009800076485]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.003577282652258873, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154070280492306, 0.0, 0.0, 0.0], [0.9735792279243469, 0.01900338940322399, 0.003664416028186679, 0.0037529077380895615, 0.0, 0.0], [0.9586312174797058, 0.0071162013337016106, 0.009218445979058743, 0.02272566594183445, 0.002308481838554144, 0.0], [0.973607063293457, 0.008490566164255142, 0.003251248737797141, 0.0036064349114894867, 0.004877458792179823, 0.006167220883071423]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011967703700066, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211372509598732, 0.01182244811207056, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293111711740494, 0.05218198522925377, 0.0602056086063385, 0.0, 0.0], [0.9378372430801392, 0.03354859724640846, 0.008826459757983685, 0.002879226813092828, 0.016908442601561546, 0.0], [0.8124936819076538, 0.02696746587753296, 0.05999191105365753, 0.034457143396139145, 0.011011820286512375, 0.0550779327750206]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001204967498779, 0.09987951070070267, 0.0, 0.0, 0.0, 0.0], [0.6271927952766418, 0.07988713681697845, 0.2929201126098633, 0.0, 0.0, 0.0], [0.7624075412750244, 0.027344312518835068, 0.03867955133318901, 0.17156852781772614, 0.0, 0.0], [0.7995960116386414, 0.014336294494569302, 0.014375682920217514, 0.02543851174414158, 0.14625348150730133, 0.0], [0.7851974964141846, 0.0420403778553009, 0.02525358647108078, 0.029083862900733948, 0.029306240379810333, 0.08911842852830887]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.004553199280053377, 0.0, 0.0, 0.0, 0.0], [0.9356003999710083, 0.04476733133196831, 0.019632287323474884, 0.0, 0.0, 0.0], [0.5605555772781372, 0.09861976653337479, 0.29983237385749817, 0.040992334485054016, 0.0, 0.0], [0.5893721580505371, 0.11000939458608627, 0.08033614605665207, 0.16753984987735748, 0.05274246260523796, 0.0], [0.22306011617183685, 0.056808121502399445, 0.05467968434095383, 0.24733951687812805, 0.31112346053123474, 0.1069890707731247]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985487043857574, 0.0, 0.0, 0.0, 0.0], [0.8936480283737183, 0.08535702526569366, 0.020994946360588074, 0.0, 0.0, 0.0], [0.8404536247253418, 0.1061922013759613, 0.023636743426322937, 0.029717376455664635, 0.0, 0.0], [0.8927384614944458, 0.024784700945019722, 0.008319015614688396, 0.05165454372763634, 0.022503262385725975, 0.0], [0.8646613359451294, 0.009503137320280075, 0.0024329768493771553, 0.04796736314892769, 0.04273197054862976, 0.03270314633846283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037388376891613, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.016807029023766518, 0.012989150360226631, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064437106251717, 0.013456246815621853, 0.018002305179834366, 0.0, 0.0], [0.9332926869392395, 0.018972063437104225, 0.02014695107936859, 0.01702381670475006, 0.010564573109149933, 0.0], [0.9113592505455017, 0.012528608553111553, 0.022096263244748116, 0.017518579959869385, 0.01851789280772209, 0.017979402095079422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096419215202332, 0.07916685938835144, 0.01119125634431839, 0.0, 0.0, 0.0], [0.8379933834075928, 0.13078252971172333, 0.012140998616814613, 0.019083015620708466, 0.0, 0.0], [0.9116523265838623, 0.054519619792699814, 0.00949938502162695, 0.007465861737728119, 0.016862777993083, 0.0], [0.851029098033905, 0.07338204979896545, 0.008022509515285492, 0.009083150885999203, 0.04260997846722603, 0.015873290598392487]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.02906331978738308, 0.015062525868415833, 0.0, 0.0, 0.0], [0.7943134903907776, 0.06074090674519539, 0.06907660514116287, 0.07586902379989624, 0.0, 0.0], [0.5494317412376404, 0.03154715523123741, 0.054820265620946884, 0.057880859822034836, 0.3063200116157532, 0.0], [0.6453989744186401, 0.010770932771265507, 0.017528090626001358, 0.021579807624220848, 0.24958215653896332, 0.05514010041952133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506810307502747, 0.04931899905204773, 0.0, 0.0, 0.0, 0.0], [0.8553216457366943, 0.0925624817609787, 0.05211583897471428, 0.0, 0.0, 0.0], [0.8508524298667908, 0.047345925122499466, 0.04417736455798149, 0.057624299079179764, 0.0, 0.0], [0.7697127461433411, 0.027885807678103447, 0.031017374247312546, 0.06842515617609024, 0.10295884311199188, 0.0], [0.7931904792785645, 0.04052181541919708, 0.02924203872680664, 0.04478130862116814, 0.04894694313406944, 0.04331747815012932]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296891249716282, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.01732144132256508, 0.03969675302505493, 0.0, 0.0, 0.0], [0.9144347310066223, 0.00858356710523367, 0.013035789132118225, 0.06394591182470322, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740282729268074, 0.010410360060632229, 0.05996229872107506, 0.0], [0.9198877215385437, 0.00308226328343153, 0.0034827536437660456, 0.004206801764667034, 0.021254312247037888, 0.0480860210955143]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541867569088936, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475461065769196, 0.03231288120150566, 0.0, 0.0, 0.0], [0.8423514366149902, 0.05980268120765686, 0.03740082308650017, 0.06044512242078781, 0.0, 0.0], [0.767462968826294, 0.035363391041755676, 0.042155198752880096, 0.06658652424812317, 0.08843202888965607, 0.0], [0.6182615160942078, 0.016110582277178764, 0.020167652517557144, 0.038688965141773224, 0.23146964609622955, 0.07530171424150467]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634855389595032, 0.03651442751288414, 0.0, 0.0, 0.0, 0.0], [0.4363935589790344, 0.5226373672485352, 0.040969084948301315, 0.0, 0.0, 0.0], [0.36086100339889526, 0.35129719972610474, 0.265510618686676, 0.022331176325678825, 0.0, 0.0], [0.39429211616516113, 0.02170465514063835, 0.07794343680143356, 0.3716889023780823, 0.13437090814113617, 0.0], [0.6310721635818481, 0.01698395051062107, 0.025942014530301094, 0.08615919947624207, 0.21831989288330078, 0.021522851660847664]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750215198844671, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.000482639909023419, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.7051579309045337e-05, 0.00011307407839922234, 0.001738940947689116, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199954704148695, 6.028387360856868e-05, 0.001545313629321754, 0.0], [0.9982888102531433, 1.0552178082434693e-06, 3.278099757153541e-05, 0.00013039002078585327, 0.000660590420011431, 0.0008863671682775021]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328931078314781, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561385804787278, 0.02537504769861698, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586130511015654, 0.0111924447119236, 0.014418884180486202, 0.0, 0.0], [0.9782042503356934, 0.0009589148685336113, 0.0018706441624090075, 0.006326551549136639, 0.012639685533940792, 0.0], [0.9592596888542175, 0.0024555183481425047, 0.0016124190296977758, 0.005019677337259054, 0.006687132176011801, 0.024965709075331688]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.037099964916706085, 0.0, 0.0, 0.0, 0.0], [0.3680204749107361, 0.6152247786521912, 0.016754787415266037, 0.0, 0.0, 0.0], [0.31735146045684814, 0.6140009760856628, 0.053751520812511444, 0.014896061271429062, 0.0, 0.0], [0.48987242579460144, 0.21071438491344452, 0.04693024978041649, 0.20700497925281525, 0.045477937906980515, 0.0], [0.48774248361587524, 0.17695219814777374, 0.06915215402841568, 0.09849291294813156, 0.12091444432735443, 0.04674571007490158]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.02055801823735237, 0.0, 0.0, 0.0, 0.0], [0.6677901148796082, 0.3103237748146057, 0.021886024624109268, 0.0, 0.0, 0.0], [0.7118752002716064, 0.11108573526144028, 0.14187400043010712, 0.03516511619091034, 0.0, 0.0], [0.45014554262161255, 0.04036048427224159, 0.040458329021930695, 0.3885704278945923, 0.08046524226665497, 0.0], [0.49346134066581726, 0.013696961104869843, 0.008126801811158657, 0.1307452917098999, 0.30861467123031616, 0.04535486549139023]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394557267427444, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.00771379517391324, 0.011612341739237309, 0.0, 0.0, 0.0], [0.932663083076477, 0.019578365609049797, 0.024103496223688126, 0.023654954507946968, 0.0, 0.0], [0.9422017931938171, 0.0009538942249491811, 0.0010898011969402432, 0.0031933740247040987, 0.052561141550540924, 0.0], [0.9352928400039673, 0.0010279340203851461, 0.00444443104788661, 0.0016371429665014148, 0.010590991005301476, 0.047006651759147644]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216711279004812, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178896529600024, 0.009547151625156403, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997019565664232e-05, 0.00013218825915828347, 0.0017900315579026937, 0.0, 0.0], [0.9986976385116577, 4.104396066395566e-05, 3.86835108656669e-06, 2.3676237105973996e-05, 0.0012337120715528727, 0.0], [0.9971562623977661, 1.8522248865338042e-05, 1.8826665382221108e-06, 2.7900308850803412e-05, 0.0006533503765240312, 0.0021419888362288475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768234491348267, 0.023176616057753563, 0.0, 0.0, 0.0, 0.0], [0.9194678664207458, 0.05088184028863907, 0.02965029887855053, 0.0, 0.0, 0.0], [0.8474552631378174, 0.0610017366707325, 0.043723780661821365, 0.04781918227672577, 0.0, 0.0], [0.8011623620986938, 0.04186701774597168, 0.04375810548663139, 0.04189479723572731, 0.07131779938936234, 0.0], [0.8031870126724243, 0.024504972621798515, 0.017323583364486694, 0.047443993389606476, 0.061099253594875336, 0.04644118249416351]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.017057159915566444, 0.0, 0.0, 0.0, 0.0], [0.8863736391067505, 0.09492656588554382, 0.01869977079331875, 0.0, 0.0, 0.0], [0.9231083989143372, 0.03696353733539581, 0.03219838812947273, 0.00772966630756855, 0.0, 0.0], [0.9068527221679688, 0.016046592965722084, 0.014310522936284542, 0.04543788731098175, 0.017352281138300896, 0.0], [0.6555968523025513, 0.05091021955013275, 0.028384927660226822, 0.1256553679704666, 0.10546855628490448, 0.03398403897881508]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502320885658264, 0.049767933785915375, 0.0, 0.0, 0.0, 0.0], [0.882986843585968, 0.10009609907865524, 0.01691715605556965, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463543891906738, 0.030189240351319313, 0.019429462030529976, 0.0, 0.0], [0.8706230521202087, 0.03244059532880783, 0.026951614767313004, 0.04410304129123688, 0.02588159590959549, 0.0], [0.6883643269538879, 0.00968147162348032, 0.016449356451630592, 0.09871123731136322, 0.08971188217401505, 0.09708172082901001]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683720588684, 0.020731639117002487, 0.0, 0.0, 0.0, 0.0], [0.9523285627365112, 0.025933803990483284, 0.02173773944377899, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358544170856476, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386075634509325, 0.03263096883893013, 0.009686199016869068, 0.0], [0.9347904920578003, 0.007862492464482784, 0.00778817106038332, 0.021432826295495033, 0.008491143584251404, 0.019634811207652092]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.01662970893085003, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229961782693863, 0.027658678591251373, 0.0, 0.0, 0.0], [0.9706627130508423, 0.0041494122706353664, 0.006813110783696175, 0.018374666571617126, 0.0, 0.0], [0.987951934337616, 0.0021658826153725386, 0.0003490109520498663, 0.0015838148538023233, 0.007949409075081348, 0.0], [0.9457950592041016, 0.014583510346710682, 0.0003652951563708484, 0.0009569510584697127, 0.01362155843526125, 0.02467748336493969]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.012194057926535606, 0.0, 0.0, 0.0, 0.0], [0.8710368275642395, 0.09448162466287613, 0.03448151424527168, 0.0, 0.0, 0.0], [0.6309778094291687, 0.11090415716171265, 0.19230234622955322, 0.06581573933362961, 0.0, 0.0], [0.5360508561134338, 0.04618927836418152, 0.1360524743795395, 0.26455411314964294, 0.01715322956442833, 0.0], [0.8287523984909058, 0.023732686415314674, 0.0200803205370903, 0.07245255261659622, 0.030431007966399193, 0.024550918489694595]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995687365531921, 0.10043126344680786, 0.0, 0.0, 0.0, 0.0], [0.27034348249435425, 0.6504330039024353, 0.07922350615262985, 0.0, 0.0, 0.0], [0.20541679859161377, 0.5892513394355774, 0.18085838854312897, 0.024473492056131363, 0.0, 0.0], [0.557386577129364, 0.17741332948207855, 0.08806800842285156, 0.09881839901208878, 0.07831361889839172, 0.0], [0.592290997505188, 0.08700643479824066, 0.05643286183476448, 0.056858956813812256, 0.12181514501571655, 0.08559554815292358]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836196035146713, 0.0, 0.0, 0.0, 0.0], [0.9572947025299072, 0.026243478059768677, 0.01646178960800171, 0.0, 0.0, 0.0], [0.9880544543266296, 0.004273314960300922, 0.0029545787256211042, 0.004717642907053232, 0.0, 0.0], [0.99403977394104, 0.000941342965234071, 0.00047398428432643414, 0.0001164695349871181, 0.004428449086844921, 0.0], [0.9806035161018372, 2.5468691092100926e-05, 0.0001623934949748218, 0.00014764114166609943, 0.001344241201877594, 0.017716819420456886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821834947913885, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.013184119947254658, 0.011163449846208096, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721749108284712, 0.0023818123154342175, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.002284808550029993, 6.19848069618456e-05, 0.0005984465242363513, 0.0065506696701049805, 0.0], [0.9697662591934204, 0.000887882721144706, 0.0002346669789403677, 0.001704077236354351, 0.004128350876271725, 0.023278873413801193]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.028376810252666473, 0.0, 0.0, 0.0, 0.0], [0.9223620295524597, 0.028907237574458122, 0.048730701208114624, 0.0, 0.0, 0.0], [0.8426316380500793, 0.023872135207057, 0.047481343150138855, 0.08601481467485428, 0.0, 0.0], [0.8521119952201843, 0.020744245499372482, 0.04494619369506836, 0.0576501302421093, 0.024547411128878593, 0.0], [0.8800727725028992, 0.022448495030403137, 0.018235674127936363, 0.01925477385520935, 0.01585422269999981, 0.04413408041000366]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727655559778214, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.026094043627381325, 0.0, 0.0, 0.0], [0.8392420411109924, 0.0576905757188797, 0.013829050585627556, 0.089238241314888, 0.0, 0.0], [0.8987160325050354, 0.013477892614901066, 0.0003456464037299156, 0.003298763185739517, 0.08416159451007843, 0.0], [0.8701689839363098, 0.002700863406062126, 0.0014349977718666196, 0.005666180979460478, 0.08874324709177017, 0.031285710632801056]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.034327439963817596, 0.0, 0.0, 0.0, 0.0], [0.9178615212440491, 0.062257975339889526, 0.019880497828125954, 0.0, 0.0, 0.0], [0.8233147859573364, 0.06282391399145126, 0.03670433908700943, 0.07715694606304169, 0.0, 0.0], [0.850174605846405, 0.038169246166944504, 0.03196500986814499, 0.051601458340883255, 0.028089668601751328, 0.0], [0.6572404503822327, 0.058773960918188095, 0.04336008429527283, 0.09013216942548752, 0.08146587014198303, 0.06902747601270676]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.08379381895065308, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099279269576073, 0.013829839415848255, 0.0, 0.0, 0.0], [0.8928354978561401, 0.05368681252002716, 0.017597004771232605, 0.03588074818253517, 0.0, 0.0], [0.8337052464485168, 0.047996122390031815, 0.03351327404379845, 0.04680858924984932, 0.03797685727477074, 0.0], [0.8167197704315186, 0.06337116658687592, 0.013286247849464417, 0.020469708368182182, 0.02529226988554001, 0.06086098402738571]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525134563446045, 0.04748653620481491, 0.0, 0.0, 0.0, 0.0], [0.30198657512664795, 0.6520941257476807, 0.04591922089457512, 0.0, 0.0, 0.0], [0.28558313846588135, 0.5569522976875305, 0.1444740742444992, 0.012990488670766354, 0.0, 0.0], [0.8438040614128113, 0.0322512723505497, 0.03954298049211502, 0.06848165392875671, 0.01592007651925087, 0.0], [0.6664938926696777, 0.06095923110842705, 0.04064349830150604, 0.06804486364126205, 0.0918637365102768, 0.0719948261976242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.03173447400331497, 0.0, 0.0, 0.0, 0.0], [0.7385219931602478, 0.22856836020946503, 0.03290965035557747, 0.0, 0.0, 0.0], [0.5946674346923828, 0.23033154010772705, 0.14867639541625977, 0.026324590668082237, 0.0, 0.0], [0.6339258551597595, 0.05813023820519447, 0.09654311835765839, 0.14291933178901672, 0.06848140805959702, 0.0], [0.40375664830207825, 0.08945391327142715, 0.0763508751988411, 0.2558707892894745, 0.14330387115478516, 0.03126382827758789]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020600192248821, 0.0, 0.0, 0.0, 0.0], [0.8631383180618286, 0.11056677997112274, 0.02629486285150051, 0.0, 0.0, 0.0], [0.9488077759742737, 0.028615085408091545, 0.006535575725138187, 0.016041584312915802, 0.0, 0.0], [0.9672170877456665, 0.006604996509850025, 0.0004517149063758552, 0.004844421520829201, 0.020881768316030502, 0.0], [0.9354620575904846, 0.02047811448574066, 0.0011700240429490805, 0.007056952454149723, 0.01631820760667324, 0.0195146631449461]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332731418311596, 0.0, 0.0, 0.0, 0.0], [0.9052743315696716, 0.08373638242483139, 0.010989279486238956, 0.0, 0.0, 0.0], [0.8145939707756042, 0.04283738136291504, 0.10568298399448395, 0.036885667592287064, 0.0, 0.0], [0.23519864678382874, 0.012018423527479172, 0.052801016718149185, 0.6516178250312805, 0.0483640655875206, 0.0], [0.31818586587905884, 0.01863238587975502, 0.03948180750012398, 0.37555408477783203, 0.2078733742237091, 0.04027256369590759]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826698884367943, 0.0, 0.0, 0.0, 0.0], [0.861893892288208, 0.06479166448116302, 0.07331448048353195, 0.0, 0.0, 0.0], [0.7664541006088257, 0.0733041912317276, 0.10353526473045349, 0.05670643597841263, 0.0, 0.0], [0.8128494024276733, 0.032154932618141174, 0.05900587886571884, 0.05416533723473549, 0.041824545711278915, 0.0], [0.8687860369682312, 0.026987731456756592, 0.02046993561089039, 0.016297340393066406, 0.03218373283743858, 0.03527515381574631]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354163378477097, 0.0, 0.0, 0.0, 0.0], [0.840353786945343, 0.06373763829469681, 0.09590858221054077, 0.0, 0.0, 0.0], [0.7330995202064514, 0.06451121717691422, 0.10380081832408905, 0.09858846664428711, 0.0, 0.0], [0.9143611788749695, 0.008257775567471981, 0.0073203882202506065, 0.0179662574082613, 0.052094392478466034, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019446697086096, 0.014860529452562332, 0.03399762138724327, 0.038375258445739746]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196521550416946, 0.0, 0.0, 0.0, 0.0], [0.8328665494918823, 0.12199021875858307, 0.04514317587018013, 0.0, 0.0, 0.0], [0.7994157075881958, 0.08744136989116669, 0.03605782240629196, 0.07708513736724854, 0.0, 0.0], [0.8809850215911865, 0.02074962854385376, 0.020554590970277786, 0.017120812088251114, 0.06058994680643082, 0.0], [0.7453036904335022, 0.04433394968509674, 0.022549200803041458, 0.03315267711877823, 0.0335705541074276, 0.12108993530273438]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293919153511524, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414149008691311, 0.005408118944615126, 0.0, 0.0, 0.0], [0.96304851770401, 0.015290765091776848, 0.010345702059566975, 0.011314956471323967, 0.0, 0.0], [0.921357274055481, 0.014132414944469929, 0.01763911545276642, 0.016567610204219818, 0.03030361607670784, 0.0], [0.9373326301574707, 0.009064320474863052, 0.007548372261226177, 0.006576449144631624, 0.011827622540295124, 0.027650468051433563]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.004899625666439533, 0.0, 0.0, 0.0, 0.0], [0.9476008415222168, 0.04140792787075043, 0.01099128182977438, 0.0, 0.0, 0.0], [0.914217472076416, 0.023523781448602676, 0.0391450896859169, 0.023113636299967766, 0.0, 0.0], [0.9534734487533569, 0.008932958357036114, 0.01527285948395729, 0.007908289320766926, 0.01441233605146408, 0.0], [0.9427102208137512, 0.008233072236180305, 0.004650996532291174, 0.004178107716143131, 0.005463524721562862, 0.034764114767313004]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543375372886658, 0.045662399381399155, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954764500260353, 0.010848326608538628, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425409629940987, 0.008068899624049664, 0.008460735902190208, 0.0, 0.0], [0.9726192951202393, 0.0026976661756634712, 0.0004483147931750864, 0.0013814790872856975, 0.022853214293718338, 0.0], [0.9675467610359192, 0.00961342453956604, 0.0032030234578996897, 0.004248827695846558, 0.007442236877977848, 0.007945860736072063]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204237088561058, 0.019694417715072632, 0.0, 0.0, 0.0], [0.8351995348930359, 0.03487849235534668, 0.05134478211402893, 0.0785771831870079, 0.0, 0.0], [0.9042682647705078, 0.010541536845266819, 0.01642668806016445, 0.025921892374753952, 0.04284176975488663, 0.0], [0.8913140296936035, 0.00891267228871584, 0.005010711494833231, 0.008175631985068321, 0.01351472269743681, 0.07307225465774536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693917393684387, 0.13060827553272247, 0.0, 0.0, 0.0, 0.0], [0.3507991135120392, 0.6063516139984131, 0.042849257588386536, 0.0, 0.0, 0.0], [0.35475584864616394, 0.3502020537853241, 0.24722479283809662, 0.04781736060976982, 0.0, 0.0], [0.3537052869796753, 0.03527728095650673, 0.09567125141620636, 0.44979700446128845, 0.06554915010929108, 0.0], [0.4132605493068695, 0.09055498242378235, 0.05286572501063347, 0.1746796816587448, 0.17384834587574005, 0.09479069709777832]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.0370243638753891, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.019658580422401428, 0.00469872634857893, 0.0, 0.0, 0.0], [0.9775736331939697, 0.013286291621625423, 0.002559040440246463, 0.006581087596714497, 0.0, 0.0], [0.9870141744613647, 0.007388267666101456, 0.0009579190518707037, 0.0018318271031603217, 0.002807757118716836, 0.0], [0.9409245848655701, 0.01663369871675968, 0.0022979089990258217, 0.005890654865652323, 0.0055129146203398705, 0.028740227222442627]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.03717280924320221, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641839787364006, 0.01713441126048565, 0.0, 0.0, 0.0], [0.9351300001144409, 0.01533155981451273, 0.014810988679528236, 0.034727487713098526, 0.0, 0.0], [0.9225171208381653, 0.010528765618801117, 0.011010175570845604, 0.019440075382590294, 0.03650391846895218, 0.0], [0.8420167565345764, 0.043571941554546356, 0.007488266099244356, 0.01496152114123106, 0.023852868005633354, 0.06810871511697769]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.007361340336501598, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.003346986835822463, 0.0009136911830864847, 0.0, 0.0, 0.0], [0.9869900345802307, 0.0019747884944081306, 0.0015245546819642186, 0.009510713629424572, 0.0, 0.0], [0.9933527708053589, 0.0010203253477811813, 0.00034337257966399193, 0.0010291127255186439, 0.004254375584423542, 0.0], [0.9749016761779785, 0.0004348014772403985, 0.00043065508361905813, 0.0012364371214061975, 0.0015347691951319575, 0.0214616060256958]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252452455461025, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.016509056091308594, 0.004427103791385889, 0.0, 0.0, 0.0], [0.9521437287330627, 0.02943229302763939, 0.008943171240389347, 0.009480933658778667, 0.0, 0.0], [0.9395941495895386, 0.02151092328131199, 0.010278573259711266, 0.004555240273475647, 0.02406112663447857, 0.0], [0.9205076098442078, 0.016153624281287193, 0.010818622075021267, 0.016644427552819252, 0.014566363766789436, 0.021309377625584602]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149775072932243, 0.0, 0.0, 0.0, 0.0], [0.9820908904075623, 0.006907526403665543, 0.011001539416611195, 0.0, 0.0, 0.0], [0.9684997200965881, 0.00898759812116623, 0.015342569909989834, 0.0071700941771268845, 0.0, 0.0], [0.9274121522903442, 0.009485254064202309, 0.02206612005829811, 0.03222893923521042, 0.008807620964944363, 0.0], [0.9006659388542175, 0.021623753011226654, 0.013808260671794415, 0.009843838401138783, 0.00852135755121708, 0.04553692787885666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555594641715288, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.0022854891140013933, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072294104844332, 0.0081663578748703, 0.0, 0.0], [0.9889963865280151, 0.0012260436778888106, 0.000799637520685792, 0.0006774249486625195, 0.008300581946969032, 0.0], [0.9865202903747559, 0.0003942708426620811, 0.0009571776608936489, 0.0004954370087943971, 0.0009604979422874749, 0.010672301054000854]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870450392365456, 0.0, 0.0, 0.0, 0.0], [0.7489441633224487, 0.2200266420841217, 0.03102918341755867, 0.0, 0.0, 0.0], [0.2854781150817871, 0.2112564593553543, 0.47871625423431396, 0.024549271911382675, 0.0, 0.0], [0.8056638836860657, 0.026974665001034737, 0.04302823543548584, 0.06993737071752548, 0.054395824670791626, 0.0], [0.33072203397750854, 0.022326543927192688, 0.016627110540866852, 0.08019448071718216, 0.41574740409851074, 0.13438241183757782]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225304886698723, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.01501889992505312, 0.004924531560391188, 0.0, 0.0, 0.0], [0.9237860441207886, 0.052764855325222015, 0.0063024042174220085, 0.017146749421954155, 0.0, 0.0], [0.9451844096183777, 0.036180444061756134, 0.0019892072305083275, 0.003958722576498985, 0.012687275186181068, 0.0], [0.9633328318595886, 0.018662936985492706, 0.0030418310780078173, 0.007070897612720728, 0.0050094048492610455, 0.0028820550069212914]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.01267546508461237, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.005541936494410038, 0.004001116845756769, 0.0, 0.0, 0.0], [0.9814971685409546, 0.00465345149859786, 0.00372528238222003, 0.010124064981937408, 0.0, 0.0], [0.9744364619255066, 0.004632250871509314, 0.0023799948394298553, 0.006518092937767506, 0.012033039703965187, 0.0], [0.9624499678611755, 0.003374351654201746, 0.0013198566157370806, 0.0017274974379688501, 0.002944669686257839, 0.02818365767598152]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.019232602789998055, 0.0, 0.0, 0.0, 0.0], [0.9664247035980225, 0.0154139194637537, 0.01816144958138466, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.0029253941029310226, 0.02926820144057274, 0.0, 0.0], [0.9562349319458008, 0.0012223614612594247, 0.0005304082878865302, 0.008671483024954796, 0.033340904861688614, 0.0], [0.9657101035118103, 0.0009808274917304516, 0.0016686276067048311, 0.002634831238538027, 0.005866364110261202, 0.02313927561044693]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639714956283569, 0.03602852299809456, 0.0, 0.0, 0.0, 0.0], [0.9562799334526062, 0.03373318165540695, 0.009986845776438713, 0.0, 0.0, 0.0], [0.853999674320221, 0.08073031902313232, 0.03334449231624603, 0.031925544142723083, 0.0, 0.0], [0.9547491073608398, 0.009605043567717075, 0.004146157298237085, 0.002013318007811904, 0.029486333951354027, 0.0], [0.933113694190979, 0.02869970165193081, 0.005477478262037039, 0.006368077825754881, 0.012613045983016491, 0.013728044927120209]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070062145590782, 0.0, 0.0, 0.0, 0.0], [0.929839015007019, 0.061895474791526794, 0.00826549157500267, 0.0, 0.0, 0.0], [0.8471820950508118, 0.09035061299800873, 0.017636112868785858, 0.044831179082393646, 0.0, 0.0], [0.885770320892334, 0.03918180614709854, 0.007867700420320034, 0.02276584692299366, 0.04441431537270546, 0.0], [0.8563282489776611, 0.10088985413312912, 0.0065314252860844135, 0.008485888130962849, 0.0073684146627783775, 0.020396165549755096]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353267908096313, 0.16467322409152985, 0.0, 0.0, 0.0, 0.0], [0.6160862445831299, 0.3137644827365875, 0.0701492428779602, 0.0, 0.0, 0.0], [0.3431633710861206, 0.2758488953113556, 0.11966050416231155, 0.26132717728614807, 0.0, 0.0], [0.590817391872406, 0.050290681421756744, 0.041665878146886826, 0.21994929015636444, 0.09727674722671509, 0.0], [0.8481413125991821, 0.0631808266043663, 0.014733714051544666, 0.055267464369535446, 0.00901501253247261, 0.009661633521318436]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627320766448975, 0.03726797550916672, 0.0, 0.0, 0.0, 0.0], [0.7757524847984314, 0.17996257543563843, 0.04428499937057495, 0.0, 0.0, 0.0], [0.6317061185836792, 0.2438071072101593, 0.1092565506696701, 0.015230262652039528, 0.0, 0.0], [0.9539909958839417, 0.01818224973976612, 0.011601795442402363, 0.012299071066081524, 0.00392577052116394, 0.0], [0.40356963872909546, 0.14237530529499054, 0.05661213770508766, 0.19757381081581116, 0.09299228340387344, 0.10687696188688278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.98739093542099, 0.007800445891916752, 0.0048086862079799175, 0.0, 0.0, 0.0], [0.9283919334411621, 0.008301216177642345, 0.01330563984811306, 0.05000118911266327, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.01017758622765541, 0.039987027645111084, 0.036138664931058884, 0.0], [0.975350022315979, 0.00035432918230071664, 0.000586602371186018, 0.0011877480428665876, 0.0010750865330919623, 0.021446339786052704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046696543693542, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116684943437576, 0.022682495415210724, 0.0, 0.0, 0.0], [0.848682165145874, 0.05802804231643677, 0.02485615573823452, 0.06843367964029312, 0.0, 0.0], [0.8661179542541504, 0.022324690595269203, 0.010369129478931427, 0.026001954451203346, 0.07518625259399414, 0.0], [0.8074424862861633, 0.04438251629471779, 0.018497074022889137, 0.03357783704996109, 0.018561221659183502, 0.07753884047269821]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194639831781387, 0.0, 0.0, 0.0, 0.0], [0.9693688750267029, 0.02568497136235237, 0.0049460818991065025, 0.0, 0.0, 0.0], [0.9620568156242371, 0.02255242131650448, 0.0054713222198188305, 0.009919441305100918, 0.0, 0.0], [0.9727528095245361, 0.010137123987078667, 0.0007573263137601316, 0.002882888540625572, 0.013469807803630829, 0.0], [0.9624636769294739, 0.0031108937691897154, 0.001000758376903832, 0.0019475924782454967, 0.00826621986925602, 0.02321087382733822]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542504906654358, 0.14574958384037018, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116308651864529, 0.013286862522363663, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257258981466293, 0.014612091705203056, 0.02705303207039833, 0.0, 0.0], [0.7923433780670166, 0.02730492874979973, 0.018806710839271545, 0.13854092359542847, 0.023004023358225822, 0.0], [0.6152045130729675, 0.026655228808522224, 0.029353102669119835, 0.05590905621647835, 0.11611326038837433, 0.15676474571228027]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534548744559288, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509480696171522, 0.004245338030159473, 0.0, 0.0, 0.0], [0.9584206342697144, 0.010963553562760353, 0.010456074960529804, 0.02015972137451172, 0.0, 0.0], [0.9604811668395996, 0.007182620465755463, 0.003072339342907071, 0.006898906547576189, 0.02236505039036274, 0.0], [0.966888964176178, 0.0032812796998769045, 0.005500525701791048, 0.004234071355313063, 0.005038019735366106, 0.015057139098644257]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430053859949112, 0.00543356966227293, 0.0, 0.0, 0.0], [0.8618696928024292, 0.036093570291996, 0.07555556297302246, 0.02648119255900383, 0.0, 0.0], [0.5449843406677246, 0.015411121770739555, 0.02351648546755314, 0.2574354410171509, 0.15865254402160645, 0.0], [0.9571872353553772, 0.0030803862027823925, 0.001444687251932919, 0.006861583329737186, 0.014818801544606686, 0.01660725846886635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156562566757202, 0.3843437135219574, 0.0, 0.0, 0.0, 0.0], [0.3676063120365143, 0.42816364765167236, 0.20423007011413574, 0.0, 0.0, 0.0], [0.1647152304649353, 0.413679301738739, 0.25092387199401855, 0.1706816405057907, 0.0, 0.0], [0.41844576597213745, 0.1524762064218521, 0.10305406898260117, 0.11071507632732391, 0.21530888974666595, 0.0], [0.19686941802501678, 0.20146216452121735, 0.12827251851558685, 0.09203242510557175, 0.09167557209730148, 0.2896879017353058]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726356714963913, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504457473754883, 0.05690572038292885, 0.0320608913898468, 0.06058766320347786, 0.0, 0.0], [0.7661209106445312, 0.03530395030975342, 0.03433046489953995, 0.09675205498933792, 0.0674925372004509, 0.0], [0.8650377988815308, 0.02008521929383278, 0.011498049832880497, 0.018558336421847343, 0.018430253490805626, 0.06639043241739273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.034691739827394485, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176078140735626, 0.004191520158201456, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737217351794243, 0.01152826938778162, 0.013573980890214443, 0.0, 0.0], [0.9293117523193359, 0.025833290070295334, 0.0072271134704351425, 0.014300605282187462, 0.023327283561229706, 0.0], [0.8895065188407898, 0.04689610004425049, 0.00471709668636322, 0.0062865810468792915, 0.006090124603360891, 0.04650355875492096]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619732737541199, 0.0, 0.0, 0.0, 0.0], [0.8221707344055176, 0.06304483860731125, 0.11478452384471893, 0.0, 0.0, 0.0], [0.5047376751899719, 0.15375745296478271, 0.22770409286022186, 0.11380089074373245, 0.0, 0.0], [0.4082075357437134, 0.09066350013017654, 0.11696871370077133, 0.2455318123102188, 0.13862836360931396, 0.0], [0.7291043996810913, 0.06638871133327484, 0.023112772032618523, 0.031103022396564484, 0.05714310333132744, 0.09314798563718796]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247532486915588, 0.07524675130844116, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989560276269913, 0.034366827458143234, 0.0, 0.0, 0.0], [0.7924937605857849, 0.09601148217916489, 0.05509118735790253, 0.0564035139977932, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840159252285957, 0.05396983399987221, 0.03967498242855072, 0.0], [0.7807857990264893, 0.07993530482053757, 0.042531732469797134, 0.032342106103897095, 0.0178169347345829, 0.046588048338890076]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191132426261902, 0.0, 0.0, 0.0, 0.0], [0.8636947870254517, 0.047562118619680405, 0.08874309808015823, 0.0, 0.0, 0.0], [0.9341371059417725, 0.02222410961985588, 0.02262447215616703, 0.021014327183365822, 0.0, 0.0], [0.9588143229484558, 0.008020920678973198, 0.004490080755203962, 0.005862290970981121, 0.02281239815056324, 0.0], [0.9385918378829956, 0.021227702498435974, 0.004872457589954138, 0.01094016246497631, 0.009524572640657425, 0.01484342198818922]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.02362659201025963, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189403425902128, 0.006330382544547319, 0.0, 0.0, 0.0], [0.9477092027664185, 0.01798516884446144, 0.010156619362533092, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552826147526503, 0.0033227908425033092, 0.005563332699239254, 0.01736840419471264, 0.0], [0.9584562182426453, 0.007502953987568617, 0.005136328749358654, 0.008071633987128735, 0.005997116211801767, 0.014835822395980358]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8840709328651428, 0.11592909693717957, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070808809250593, 0.001803802908398211, 0.0, 0.0, 0.0], [0.9534159302711487, 0.023829061537981033, 0.007748984266072512, 0.01500609703361988, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190969824790955, 0.011050427332520485, 0.04975659400224686, 0.0], [0.8769674301147461, 0.03385210409760475, 0.008486478589475155, 0.009969150647521019, 0.03468582406640053, 0.036039091646671295]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709525044541806, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525040225824341e-05, 0.37378236651420593, 0.6261524558067322, 0.0, 0.0, 0.0], [4.6060264139669016e-05, 0.21050874888896942, 0.41159680485725403, 0.377848356962204, 0.0, 0.0], [4.753069515572861e-05, 0.11616948246955872, 0.23264294862747192, 0.3985331058502197, 0.25260692834854126, 0.0], [1.2476385791160283e-06, 0.14819687604904175, 0.15813174843788147, 0.3007437586784363, 0.11939030885696411, 0.2735360264778137]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444180265069008, 0.0, 0.0, 0.0, 0.0], [0.9529063701629639, 0.03233079984784126, 0.014762787148356438, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351296693086624, 0.020498057827353477, 0.021676253527402878, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.0043593235313892365, 0.008064544759690762, 0.02605690062046051, 0.0], [0.9653594493865967, 0.008487643674015999, 0.0034992804285138845, 0.0027215764857828617, 0.0032828792463988066, 0.016649337485432625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.1369219273328781, 0.0, 0.0, 0.0, 0.0], [0.7696154117584229, 0.08513347804546356, 0.14525112509727478, 0.0, 0.0, 0.0], [0.7133336663246155, 0.10170901566743851, 0.11931274831295013, 0.06564459204673767, 0.0, 0.0], [0.7186222672462463, 0.05444291979074478, 0.013868155889213085, 0.07808026671409607, 0.13498631119728088, 0.0], [0.7990154027938843, 0.0580558106303215, 0.009446999058127403, 0.01777041330933571, 0.021138500422239304, 0.09457293897867203]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.04810110479593277, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944575622677803, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577736139297485, 0.08513452857732773, 0.12613102793693542, 0.1309608370065689, 0.0, 0.0], [0.8087372183799744, 0.03230157867074013, 0.018418142572045326, 0.06856127083301544, 0.07198181748390198, 0.0], [0.6683297157287598, 0.13281385600566864, 0.021880634129047394, 0.02787742204964161, 0.049234047532081604, 0.09986431896686554]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-43e94066d0a34bdbbbf570b94f4258a7\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12}; // HACK: {\"attention\": [{\"name\": null, \"attn\": [[[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.961219847202301, 0.038780126720666885, 0.0, 0.0, 0.0, 0.0], [0.7466979026794434, 0.11987314373254776, 0.1334289014339447, 0.0, 0.0, 0.0], [0.5885030031204224, 0.13792066276073456, 0.2121374011039734, 0.06143897399306297, 0.0, 0.0], [0.6570857763290405, 0.08996301144361496, 0.1275128275156021, 0.08361561596393585, 0.04182284325361252, 0.0], [0.27288734912872314, 0.11203355342149734, 0.1663985401391983, 0.08467110991477966, 0.16952736675739288, 0.19448210299015045]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010616563260555267, 0.9893833994865417, 0.0, 0.0, 0.0, 0.0], [0.0024677535984665155, 0.008448002859950066, 0.9890841841697693, 0.0, 0.0, 0.0], [0.00012328459706623107, 0.0018733164761215448, 0.013126970268785954, 0.9848763942718506, 0.0, 0.0], [0.00106695550493896, 0.001136626466177404, 0.0030349940061569214, 0.0015735073247924447, 0.9931879043579102, 0.0], [0.00019791982776951045, 0.0010528112761676311, 0.0015437359688803554, 0.0009642760851420462, 3.4924432839034125e-05, 0.9962062835693359]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.47578442096710205, 0.524215579032898, 0.0, 0.0, 0.0, 0.0], [0.5906046032905579, 0.2486610859632492, 0.1607343554496765, 0.0, 0.0, 0.0], [0.5529289841651917, 0.18856702744960785, 0.14457565546035767, 0.11392831057310104, 0.0, 0.0], [0.45094069838523865, 0.16486799716949463, 0.17318037152290344, 0.11748009920120239, 0.0935307964682579, 0.0], [0.425724595785141, 0.17328649759292603, 0.15651948750019073, 0.07022647559642792, 0.08087009936571121, 0.09337282925844193]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6133622527122498, 0.38663774728775024, 0.0, 0.0, 0.0, 0.0], [0.06098512187600136, 0.0325346402823925, 0.9064802527427673, 0.0, 0.0, 0.0], [0.006717088632285595, 0.00040128850378096104, 0.7572957873344421, 0.23558583855628967, 0.0, 0.0], [0.03722767159342766, 0.002948855282738805, 0.1008109450340271, 0.04142269119620323, 0.8175898790359497, 0.0], [0.04989781975746155, 0.00030758307548239827, 0.002419827738776803, 0.003433502744883299, 0.0006823898293077946, 0.9432588815689087]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9489555954933167, 0.05104445293545723, 0.0, 0.0, 0.0, 0.0], [0.6821408867835999, 0.13952414691448212, 0.17833498120307922, 0.0, 0.0, 0.0], [0.20366324484348297, 0.05641487240791321, 0.06399299949407578, 0.6759288311004639, 0.0, 0.0], [0.3419547975063324, 0.06725440174341202, 0.07926186174154282, 0.17836196720600128, 0.3331669867038727, 0.0], [0.09464019536972046, 0.007428212556988001, 0.006983975879848003, 0.0071843755431473255, 0.018724266439676285, 0.8650389313697815]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.33834612369537354, 0.6616538763046265, 0.0, 0.0, 0.0, 0.0], [0.07855997234582901, 0.006165449041873217, 0.9152746200561523, 0.0, 0.0, 0.0], [0.016775991767644882, 0.0004037705948576331, 0.003340460592880845, 0.9794798493385315, 0.0, 0.0], [0.02760043926537037, 0.00044415253796614707, 0.0006541680195368826, 0.00022661880939267576, 0.971074640750885, 0.0], [0.01024820376187563, 3.70155721611809e-05, 0.00016064057126641273, 2.7341844543116167e-05, 1.0187304724240676e-05, 0.98951655626297]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.982503354549408, 0.017496658489108086, 0.0, 0.0, 0.0, 0.0], [0.8874197006225586, 0.05467936769127846, 0.05790085718035698, 0.0, 0.0, 0.0], [0.6849910616874695, 0.1228068619966507, 0.04972026124596596, 0.14248183369636536, 0.0, 0.0], [0.6015855669975281, 0.09881887584924698, 0.07070109248161316, 0.16652536392211914, 0.062369026243686676, 0.0], [0.3232504427433014, 0.12567414343357086, 0.04432179406285286, 0.07076980918645859, 0.06606650352478027, 0.3699173331260681]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9191647171974182, 0.0808352455496788, 0.0, 0.0, 0.0, 0.0], [0.45986407995224, 0.39703118801116943, 0.14310474693775177, 0.0, 0.0, 0.0], [0.3003872334957123, 0.22181743383407593, 0.38161516189575195, 0.09618020057678223, 0.0, 0.0], [0.18963918089866638, 0.1376371681690216, 0.20173481106758118, 0.23632165789604187, 0.23466715216636658, 0.0], [0.15410438179969788, 0.09489505738019943, 0.11902564018964767, 0.10277966409921646, 0.431721955537796, 0.09747330099344254]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36500000953674316, 0.6349999904632568, 0.0, 0.0, 0.0, 0.0], [0.24595215916633606, 0.5519201755523682, 0.202127605676651, 0.0, 0.0, 0.0], [0.2721358835697174, 0.40738624334335327, 0.25186213850975037, 0.06861571967601776, 0.0, 0.0], [0.10242554545402527, 0.16683614253997803, 0.5248050093650818, 0.054454635828733444, 0.15147866308689117, 0.0], [0.25029510259628296, 0.22198131680488586, 0.18899966776371002, 0.10677117109298706, 0.13032673299312592, 0.10162606835365295]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6990506649017334, 0.300949364900589, 0.0, 0.0, 0.0, 0.0], [0.5107942223548889, 0.2948642075061798, 0.1943414956331253, 0.0, 0.0, 0.0], [0.4604707360267639, 0.28051912784576416, 0.1917480230331421, 0.06726215034723282, 0.0, 0.0], [0.376484215259552, 0.21120665967464447, 0.20214541256427765, 0.10207021981477737, 0.10809355229139328, 0.0], [0.30138447880744934, 0.20456178486347198, 0.1825033575296402, 0.11019384860992432, 0.16291266679763794, 0.03844384476542473]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7131581902503967, 0.28684180974960327, 0.0, 0.0, 0.0, 0.0], [0.40588000416755676, 0.18063294887542725, 0.4134870171546936, 0.0, 0.0, 0.0], [0.2655460834503174, 0.16985861957073212, 0.3358592689037323, 0.22873596847057343, 0.0, 0.0], [0.31385406851768494, 0.1831669807434082, 0.14928361773490906, 0.053776707500219345, 0.29991865158081055, 0.0], [0.20466557145118713, 0.18731121718883514, 0.15959152579307556, 0.06381776928901672, 0.03642302379012108, 0.34819096326828003]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6586242914199829, 0.3413757383823395, 0.0, 0.0, 0.0, 0.0], [0.5917776823043823, 0.3160034418106079, 0.09221882373094559, 0.0, 0.0, 0.0], [0.5477152466773987, 0.23586949706077576, 0.061456020921468735, 0.1549593061208725, 0.0, 0.0], [0.4587061107158661, 0.22439992427825928, 0.07887422293424606, 0.09920340776443481, 0.13881628215312958, 0.0], [0.32743728160858154, 0.19600817561149597, 0.06805712729692459, 0.0892510786652565, 0.11618079245090485, 0.20306554436683655]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9961552023887634, 0.0038448371924459934, 0.0, 0.0, 0.0, 0.0], [0.8594854474067688, 0.06906113028526306, 0.07145344465970993, 0.0, 0.0, 0.0], [0.3800053596496582, 0.04127565026283264, 0.5496611595153809, 0.029057765379548073, 0.0, 0.0], [0.2144523561000824, 0.05088743939995766, 0.43174391984939575, 0.2586929202079773, 0.04422333091497421, 0.0], [0.11175251752138138, 0.017593061551451683, 0.027507437393069267, 0.04086765646934509, 0.7754672169685364, 0.02681213989853859]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9285966753959656, 0.07140327990055084, 0.0, 0.0, 0.0, 0.0], [0.6077286005020142, 0.3121427297592163, 0.08012863248586655, 0.0, 0.0, 0.0], [0.49429091811180115, 0.28503692150115967, 0.1184932291507721, 0.10217896103858948, 0.0, 0.0], [0.41838788986206055, 0.23117896914482117, 0.08340625464916229, 0.11365951597690582, 0.1533673107624054, 0.0], [0.4221589267253876, 0.12917141616344452, 0.08740925043821335, 0.10163748264312744, 0.21230244636535645, 0.0473204143345356]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9786477088928223, 0.021352343261241913, 0.0, 0.0, 0.0, 0.0], [0.7749121785163879, 0.0651036724448204, 0.15998412668704987, 0.0, 0.0, 0.0], [0.6484924554824829, 0.0748312845826149, 0.14751607179641724, 0.12916018068790436, 0.0, 0.0], [0.5224639773368835, 0.06921806186437607, 0.13823406398296356, 0.11106578260660172, 0.15901808440685272, 0.0], [0.39645180106163025, 0.07325819134712219, 0.12938153743743896, 0.10642421990633011, 0.14864003658294678, 0.1458442211151123]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5525904297828674, 0.4474095404148102, 0.0, 0.0, 0.0, 0.0], [0.5585009455680847, 0.2176259160041809, 0.22387316823005676, 0.0, 0.0, 0.0], [0.5143128633499146, 0.15964673459529877, 0.15491966903209686, 0.17112070322036743, 0.0, 0.0], [0.5039963126182556, 0.11401881277561188, 0.11974023282527924, 0.1255258023738861, 0.13671885430812836, 0.0], [0.5061841011047363, 0.08567393571138382, 0.0890302062034607, 0.09759815782308578, 0.10275726765394211, 0.1187562420964241]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9242545366287231, 0.07574543356895447, 0.0, 0.0, 0.0, 0.0], [0.8257424831390381, 0.07932532578706741, 0.0949321985244751, 0.0, 0.0, 0.0], [0.7306380271911621, 0.0857183039188385, 0.08043931424617767, 0.10320429503917694, 0.0, 0.0], [0.6383237838745117, 0.0788639485836029, 0.07815034687519073, 0.08758100867271423, 0.11708094924688339, 0.0], [0.5552157163619995, 0.07409123331308365, 0.06834892928600311, 0.07778594642877579, 0.09999319165945053, 0.1245650053024292]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8578914999961853, 0.1421085000038147, 0.0, 0.0, 0.0, 0.0], [0.6423038840293884, 0.1662902981042862, 0.19140584766864777, 0.0, 0.0, 0.0], [0.553097665309906, 0.10609276592731476, 0.07821261882781982, 0.26259690523147583, 0.0, 0.0], [0.40121686458587646, 0.12223610281944275, 0.19347301125526428, 0.1416463404893875, 0.141427680850029, 0.0], [0.4021257758140564, 0.18450741469860077, 0.07516802847385406, 0.05849042534828186, 0.1444634199142456, 0.13524499535560608]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791558980941772, 0.020844051614403725, 0.0, 0.0, 0.0, 0.0], [0.8829841613769531, 0.06233254820108414, 0.05468339845538139, 0.0, 0.0, 0.0], [0.8105455040931702, 0.08617085963487625, 0.07321777194738388, 0.030065858736634254, 0.0, 0.0], [0.6819812059402466, 0.049908217042684555, 0.08296556770801544, 0.08369525521993637, 0.10144972801208496, 0.0], [0.40566906332969666, 0.0733766257762909, 0.08601399511098862, 0.061709318310022354, 0.13226418197155, 0.24096690118312836]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9670192003250122, 0.032980870455503464, 0.0, 0.0, 0.0, 0.0], [0.8449063301086426, 0.0851450189948082, 0.06994856148958206, 0.0, 0.0, 0.0], [0.712357223033905, 0.07896044850349426, 0.05541076511144638, 0.15327154099941254, 0.0, 0.0], [0.6402612924575806, 0.0739755630493164, 0.044393084943294525, 0.14322125911712646, 0.09814874082803726, 0.0], [0.5073903799057007, 0.07523056864738464, 0.07754651457071304, 0.11362487822771072, 0.13947953283786774, 0.0867280513048172]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8487567901611328, 0.1512431502342224, 0.0, 0.0, 0.0, 0.0], [0.8415648937225342, 0.12107235193252563, 0.037362754344940186, 0.0, 0.0, 0.0], [0.750551700592041, 0.11348950117826462, 0.061799634248018265, 0.0741591602563858, 0.0, 0.0], [0.6614720225334167, 0.10242638736963272, 0.052934251725673676, 0.0752970427274704, 0.10787028074264526, 0.0], [0.6014200448989868, 0.1134038195014, 0.05631931126117706, 0.07096722722053528, 0.10906289517879486, 0.04882662743330002]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.944548487663269, 0.05545153468847275, 0.0, 0.0, 0.0, 0.0], [0.8874567747116089, 0.054742176085710526, 0.05780100077390671, 0.0, 0.0, 0.0], [0.8281888961791992, 0.06895003467798233, 0.05903465300798416, 0.043826356530189514, 0.0, 0.0], [0.6429892778396606, 0.0674755647778511, 0.11629696935415268, 0.05417948588728905, 0.11905863881111145, 0.0], [0.7367821931838989, 0.05611901357769966, 0.06857296824455261, 0.03421955928206444, 0.07875380665063858, 0.025552431121468544]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0002913392090704292, 0.9997085928916931, 0.0, 0.0, 0.0, 0.0], [0.0007981205708347261, 0.5288336873054504, 0.4703682065010071, 0.0, 0.0, 0.0], [0.0007648472674190998, 0.34519824385643005, 0.30852681398391724, 0.3455100953578949, 0.0, 0.0], [0.0010283150477334857, 0.24135905504226685, 0.23320144414901733, 0.2555713355541229, 0.26883992552757263, 0.0], [0.0009746805299073458, 0.17789693176746368, 0.16743157804012299, 0.18587595224380493, 0.1873445361852646, 0.28047627210617065]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8244929313659668, 0.1755070984363556, 0.0, 0.0, 0.0, 0.0], [0.123868927359581, 0.0444999635219574, 0.8316311240196228, 0.0, 0.0, 0.0], [0.079243503510952, 0.01296587847173214, 0.0015277144266292453, 0.9062629342079163, 0.0, 0.0], [0.0880640298128128, 0.02134104259312153, 0.0028886180371046066, 0.0028453818522393703, 0.8848609328269958, 0.0], [0.09983208775520325, 0.03363381698727608, 0.005499974358826876, 0.0024330471642315388, 0.0015082373283803463, 0.8570928573608398]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9646892547607422, 0.03531069681048393, 0.0, 0.0, 0.0, 0.0], [0.7529155611991882, 0.08733483403921127, 0.1597496122121811, 0.0, 0.0, 0.0], [0.42022812366485596, 0.0919511616230011, 0.23549865186214447, 0.25232207775115967, 0.0, 0.0], [0.3084891736507416, 0.059081461280584335, 0.38391315937042236, 0.15659154951572418, 0.09192463755607605, 0.0], [0.4479040205478668, 0.04329320415854454, 0.07969193160533905, 0.11081938445568085, 0.22124597430229187, 0.09704560786485672]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.991096019744873, 0.008904012851417065, 0.0, 0.0, 0.0, 0.0], [0.9697675704956055, 0.02608449012041092, 0.004147926811128855, 0.0, 0.0, 0.0], [0.9082902073860168, 0.03320598229765892, 0.009421163238584995, 0.049082621932029724, 0.0, 0.0], [0.8949132561683655, 0.055445630103349686, 0.0055776298977434635, 0.031506892293691635, 0.012556551024317741, 0.0], [0.8497739434242249, 0.028890099376440048, 0.003664793213829398, 0.037519875913858414, 0.03842782601714134, 0.04172348231077194]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9984525442123413, 0.0015474462416023016, 0.0, 0.0, 0.0, 0.0], [0.48947787284851074, 0.4812198877334595, 0.02930225431919098, 0.0, 0.0, 0.0], [0.11772128194570541, 0.1312120407819748, 0.6702316999435425, 0.08083496987819672, 0.0, 0.0], [0.13043686747550964, 0.04068691283464432, 0.2652047574520111, 0.41143539547920227, 0.1522361934185028, 0.0], [0.1266181319952011, 0.03275136649608612, 0.03567884862422943, 0.06039205193519592, 0.6021828055381775, 0.14237675070762634]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9805176854133606, 0.01948235183954239, 0.0, 0.0, 0.0, 0.0], [0.7948846220970154, 0.12061934918165207, 0.08449608087539673, 0.0, 0.0, 0.0], [0.561235249042511, 0.15743158757686615, 0.20339740812778473, 0.07793577015399933, 0.0, 0.0], [0.4258372187614441, 0.1074204370379448, 0.151236891746521, 0.08755026012659073, 0.227955162525177, 0.0], [0.24752575159072876, 0.024188309907913208, 0.03039529360830784, 0.08586953580379486, 0.5714344382286072, 0.040586717426776886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887767434120178, 0.011223225854337215, 0.0, 0.0, 0.0, 0.0], [0.7572690844535828, 0.22317378222942352, 0.01955713890492916, 0.0, 0.0, 0.0], [0.5341876745223999, 0.22107593715190887, 0.1762186586856842, 0.06851772964000702, 0.0, 0.0], [0.17095263302326202, 0.08229422569274902, 0.5760225057601929, 0.11097591370344162, 0.05975468084216118, 0.0], [0.24871118366718292, 0.08880820125341415, 0.08980222791433334, 0.0972934141755104, 0.44130849838256836, 0.03407648205757141]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.84221351146698, 0.1577865183353424, 0.0, 0.0, 0.0, 0.0], [0.46841272711753845, 0.4610536992549896, 0.07053355872631073, 0.0, 0.0, 0.0], [0.2588139772415161, 0.4635891318321228, 0.18503500521183014, 0.09256189316511154, 0.0, 0.0], [0.18399538099765778, 0.2915422320365906, 0.17031094431877136, 0.27172988653182983, 0.08242153376340866, 0.0], [0.16469836235046387, 0.24726982414722443, 0.08770570158958435, 0.22575023770332336, 0.17745378613471985, 0.09712209552526474]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9919946193695068, 0.008005395531654358, 0.0, 0.0, 0.0, 0.0], [0.9068724513053894, 0.04406510293483734, 0.04906242713332176, 0.0, 0.0, 0.0], [0.8582223057746887, 0.05534825101494789, 0.04041941091418266, 0.04601002112030983, 0.0, 0.0], [0.7855252027511597, 0.04124240577220917, 0.0836929976940155, 0.04887611046433449, 0.04066324606537819, 0.0], [0.7856316566467285, 0.05014647915959358, 0.047512687742710114, 0.027365945279598236, 0.056147508323192596, 0.03319566696882248]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9041034579277039, 0.09589657187461853, 0.0, 0.0, 0.0, 0.0], [0.5862313508987427, 0.0719982385635376, 0.3417704105377197, 0.0, 0.0, 0.0], [0.3878958523273468, 0.046608101576566696, 0.20279009640216827, 0.3627060055732727, 0.0, 0.0], [0.26652413606643677, 0.02453301101922989, 0.12211944907903671, 0.20041222870349884, 0.386411190032959, 0.0], [0.2335742861032486, 0.020537355914711952, 0.09610342979431152, 0.13062255084514618, 0.22990457713603973, 0.2892577648162842]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639912247657776, 0.036008838564157486, 0.0, 0.0, 0.0, 0.0], [0.7075549364089966, 0.25427794456481934, 0.03816715627908707, 0.0, 0.0, 0.0], [0.2566525936126709, 0.20589333772659302, 0.0166566651314497, 0.5207974314689636, 0.0, 0.0], [0.10379378497600555, 0.04639103636145592, 0.008698646910488605, 0.7866851687431335, 0.05443137139081955, 0.0], [0.22143368422985077, 0.03379754349589348, 0.02902398630976677, 0.5412925481796265, 0.15286068618297577, 0.021591559052467346]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891703724861145, 0.010829629376530647, 0.0, 0.0, 0.0, 0.0], [0.791315495967865, 0.12309640645980835, 0.08558814227581024, 0.0, 0.0, 0.0], [0.2954595983028412, 0.15808328986167908, 0.421724408864975, 0.12473269551992416, 0.0, 0.0], [0.2344098538160324, 0.09886544197797775, 0.3316018581390381, 0.19713956117630005, 0.1379833221435547, 0.0], [0.19728359580039978, 0.05741845443844795, 0.06909029930830002, 0.1646983027458191, 0.2797278165817261, 0.23178145289421082]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9359127879142761, 0.06408719718456268, 0.0, 0.0, 0.0, 0.0], [0.7888627648353577, 0.08673479408025742, 0.12440250813961029, 0.0, 0.0, 0.0], [0.6535120010375977, 0.07573550939559937, 0.09732569009065628, 0.1734268069267273, 0.0, 0.0], [0.5222766399383545, 0.05827883630990982, 0.09920477867126465, 0.17020843923091888, 0.15003135800361633, 0.0], [0.41088414192199707, 0.047306060791015625, 0.07265680283308029, 0.10560746490955353, 0.10550005733966827, 0.2580455541610718]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9683833122253418, 0.03161672502756119, 0.0, 0.0, 0.0, 0.0], [0.896539568901062, 0.03887060284614563, 0.0645897388458252, 0.0, 0.0, 0.0], [0.8264952898025513, 0.03213467076420784, 0.05196719989180565, 0.08940290659666061, 0.0, 0.0], [0.7718175053596497, 0.030402889475226402, 0.04582744464278221, 0.07118470221757889, 0.08076753467321396, 0.0], [0.7292330265045166, 0.021699870005249977, 0.033074770122766495, 0.047200947999954224, 0.06474558264017105, 0.10404574126005173]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9979567527770996, 0.002043285872787237, 0.0, 0.0, 0.0, 0.0], [0.955294132232666, 0.00802532583475113, 0.03668050840497017, 0.0, 0.0, 0.0], [0.9254710078239441, 0.002755579072982073, 0.0020629873033612967, 0.06971046328544617, 0.0, 0.0], [0.8660573363304138, 0.003888371866196394, 0.0006785969599150121, 0.0006981453043408692, 0.12867748737335205, 0.0], [0.8455931544303894, 0.0037804031744599342, 0.0002534222148824483, 6.027047857060097e-05, 0.00011820740473922342, 0.15019452571868896]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9262452721595764, 0.0737547054886818, 0.0, 0.0, 0.0, 0.0], [0.7717155814170837, 0.16241982579231262, 0.06586461514234543, 0.0, 0.0, 0.0], [0.8167634010314941, 0.07807183265686035, 0.06324050575494766, 0.04192419722676277, 0.0, 0.0], [0.6867184042930603, 0.07755175232887268, 0.10056906193494797, 0.059550799429416656, 0.07560998201370239, 0.0], [0.6421160101890564, 0.11014913767576218, 0.0768820121884346, 0.054033394902944565, 0.10333629697561264, 0.013483160175383091]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9395952820777893, 0.0604046992957592, 0.0, 0.0, 0.0, 0.0], [0.23004570603370667, 0.6617382168769836, 0.10821598768234253, 0.0, 0.0, 0.0], [0.2670212686061859, 0.36079588532447815, 0.32496336102485657, 0.04721950367093086, 0.0, 0.0], [0.595202624797821, 0.12269263714551926, 0.0630204826593399, 0.08916771411895752, 0.12991654872894287, 0.0], [0.10284564644098282, 0.02938022091984749, 0.013739144429564476, 0.045860543847084045, 0.7698503136634827, 0.03832409530878067]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9040981531143188, 0.09590183943510056, 0.0, 0.0, 0.0, 0.0], [0.3572389781475067, 0.6274600625038147, 0.015300886705517769, 0.0, 0.0, 0.0], [0.5917983055114746, 0.27640461921691895, 0.10476133972406387, 0.02703571505844593, 0.0, 0.0], [0.7254412770271301, 0.049831323325634, 0.014982974156737328, 0.1778138279914856, 0.03193071112036705, 0.0], [0.7612766623497009, 0.061589207500219345, 0.005942226853221655, 0.016426678746938705, 0.12677942216396332, 0.02798573672771454]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9947587847709656, 0.0052412403747439384, 0.0, 0.0, 0.0, 0.0], [0.963241457939148, 0.017816441133618355, 0.018942032009363174, 0.0, 0.0, 0.0], [0.9671075940132141, 0.008509601466357708, 0.008562229573726654, 0.01582048460841179, 0.0, 0.0], [0.9340997338294983, 0.011952393688261509, 0.02018018066883087, 0.026750795543193817, 0.007016893941909075, 0.0], [0.9587237238883972, 0.004657106939703226, 0.0033267769031226635, 0.006545298267155886, 0.010182461701333523, 0.01656450144946575]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9769991040229797, 0.023000916466116905, 0.0, 0.0, 0.0, 0.0], [0.7917606830596924, 0.1753322035074234, 0.03290712088346481, 0.0, 0.0, 0.0], [0.7949190735816956, 0.10531847923994064, 0.04021858796477318, 0.05954387038946152, 0.0, 0.0], [0.7097724080085754, 0.10552516579627991, 0.0659755989909172, 0.05765584483742714, 0.061070967465639114, 0.0], [0.7506605386734009, 0.026514414697885513, 0.021575985476374626, 0.03429659456014633, 0.08494436740875244, 0.08200812339782715]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983751654624939, 0.016248326748609543, 0.0, 0.0, 0.0, 0.0], [0.5615501403808594, 0.08956822007894516, 0.34888166189193726, 0.0, 0.0, 0.0], [0.3292894661426544, 0.024114856496453285, 0.5428069829940796, 0.10378868877887726, 0.0, 0.0], [0.3433028757572174, 0.013086398132145405, 0.5121980905532837, 0.11146178841590881, 0.019950786605477333, 0.0], [0.479281485080719, 0.01733359508216381, 0.11805380880832672, 0.061302732676267624, 0.20071853697299957, 0.12330985069274902]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9908847212791443, 0.009115325286984444, 0.0, 0.0, 0.0, 0.0], [0.5282702445983887, 0.32922643423080444, 0.14250332117080688, 0.0, 0.0, 0.0], [0.48788580298423767, 0.2336864322423935, 0.1757809817790985, 0.10264680534601212, 0.0, 0.0], [0.314447283744812, 0.18065206706523895, 0.16871440410614014, 0.09506572037935257, 0.24112050235271454, 0.0], [0.5168745517730713, 0.03589726984500885, 0.026188218966126442, 0.04039734974503517, 0.18791824579238892, 0.19272442162036896]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8750303387641907, 0.12496966868638992, 0.0, 0.0, 0.0, 0.0], [0.4550611078739166, 0.4900429844856262, 0.05489587038755417, 0.0, 0.0, 0.0], [0.29337161779403687, 0.5449912548065186, 0.09444315731525421, 0.06719394773244858, 0.0, 0.0], [0.48970794677734375, 0.27210018038749695, 0.06861996650695801, 0.1469479650259018, 0.022623907774686813, 0.0], [0.4729057848453522, 0.08103127777576447, 0.016052212566137314, 0.30672261118888855, 0.10120765119791031, 0.02208036370575428]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9630220532417297, 0.03697787597775459, 0.0, 0.0, 0.0, 0.0], [0.7557193040847778, 0.164363831281662, 0.0799168273806572, 0.0, 0.0, 0.0], [0.6947702169418335, 0.08409861475229263, 0.06382618844509125, 0.15730492770671844, 0.0, 0.0], [0.5821161866188049, 0.03297793120145798, 0.07936564832925797, 0.1944134384393692, 0.11112679541110992, 0.0], [0.5974540710449219, 0.04261098429560661, 0.06919704377651215, 0.1456344574689865, 0.12481749057769775, 0.020285936072468758]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9957822561264038, 0.004217816516757011, 0.0, 0.0, 0.0, 0.0], [0.9312832951545715, 0.010560247115790844, 0.05815646052360535, 0.0, 0.0, 0.0], [0.8435326218605042, 0.01569502428174019, 0.04575122147798538, 0.09502112865447998, 0.0, 0.0], [0.7724100351333618, 0.01198125071823597, 0.03504614159464836, 0.038767702877521515, 0.1417948305606842, 0.0], [0.7642909288406372, 0.009868795052170753, 0.008122756145894527, 0.013314363546669483, 0.04824389889836311, 0.15615925192832947]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9701177477836609, 0.02988227643072605, 0.0, 0.0, 0.0, 0.0], [0.656400740146637, 0.22506137192249298, 0.11853783577680588, 0.0, 0.0, 0.0], [0.6958051919937134, 0.14701884984970093, 0.0714603066444397, 0.08571569621562958, 0.0, 0.0], [0.6353278756141663, 0.13460659980773926, 0.030994264408946037, 0.05691635236144066, 0.14215490221977234, 0.0], [0.6779390573501587, 0.05365435406565666, 0.018006397411227226, 0.06284541636705399, 0.11038216948509216, 0.07717254012823105]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9822334051132202, 0.01776665635406971, 0.0, 0.0, 0.0, 0.0], [0.9037665128707886, 0.06541507691144943, 0.030818404629826546, 0.0, 0.0, 0.0], [0.8119190335273743, 0.03679019585251808, 0.06056112423539162, 0.09072960913181305, 0.0, 0.0], [0.4054649770259857, 0.10383855551481247, 0.10211297124624252, 0.35434144735336304, 0.03424210846424103, 0.0], [0.22824402153491974, 0.01727871596813202, 0.05055490508675575, 0.60157310962677, 0.09411770850419998, 0.008231508545577526]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873148202896118, 0.012685136869549751, 0.0, 0.0, 0.0, 0.0], [0.35445892810821533, 0.5317586660385132, 0.11378246545791626, 0.0, 0.0, 0.0], [0.07823362201452255, 0.7221351265907288, 0.10936681926250458, 0.09026447683572769, 0.0, 0.0], [0.21967922151088715, 0.4048427939414978, 0.12358146905899048, 0.20018842816352844, 0.0517081543803215, 0.0], [0.3608972728252411, 0.10459017753601074, 0.06983830779790878, 0.29764848947525024, 0.13869914412498474, 0.02832675352692604]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9732162356376648, 0.026783782988786697, 0.0, 0.0, 0.0, 0.0], [0.9167556166648865, 0.061452481895685196, 0.02179187908768654, 0.0, 0.0, 0.0], [0.8543080687522888, 0.08049603551626205, 0.030334968119859695, 0.034860968589782715, 0.0, 0.0], [0.8919214606285095, 0.04280785843729973, 0.022045092657208443, 0.023470696061849594, 0.019754959270358086, 0.0], [0.8116771578788757, 0.03413521125912666, 0.0356765016913414, 0.047485724091529846, 0.02539709210395813, 0.04562826454639435]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502761363983154, 0.049723830074071884, 0.0, 0.0, 0.0, 0.0], [0.7637463212013245, 0.20073527097702026, 0.035518381744623184, 0.0, 0.0, 0.0], [0.6279093027114868, 0.03768132999539375, 0.19945405423641205, 0.13495533168315887, 0.0, 0.0], [0.6397068500518799, 0.027007201686501503, 0.09082008898258209, 0.2065378874540329, 0.03592789173126221, 0.0], [0.4559430480003357, 0.02164110541343689, 0.12939560413360596, 0.2180090695619583, 0.10379841923713684, 0.07121271640062332]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.949840784072876, 0.05015929415822029, 0.0, 0.0, 0.0, 0.0], [0.8688724637031555, 0.08722192794084549, 0.04390566796064377, 0.0, 0.0, 0.0], [0.6937949657440186, 0.06359197199344635, 0.09179069846868515, 0.1508224457502365, 0.0, 0.0], [0.7266592979431152, 0.0438988097012043, 0.04683993384242058, 0.09851823002099991, 0.084083691239357, 0.0], [0.7848989963531494, 0.03714786469936371, 0.012907862663269043, 0.01053939014673233, 0.12079212069511414, 0.03371364623308182]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9891054034233093, 0.010894596576690674, 0.0, 0.0, 0.0, 0.0], [0.8929520845413208, 0.08700034022331238, 0.020047562196850777, 0.0, 0.0, 0.0], [0.7891120910644531, 0.0979725793004036, 0.08633225411176682, 0.026582974940538406, 0.0, 0.0], [0.8850637078285217, 0.036449968814849854, 0.053954605013132095, 0.012377229519188404, 0.012154524214565754, 0.0], [0.6861334443092346, 0.05720369145274162, 0.011636318638920784, 0.021660534664988518, 0.17487967014312744, 0.04848628118634224]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9396193027496338, 0.06038069725036621, 0.0, 0.0, 0.0, 0.0], [0.7851802110671997, 0.19751375913619995, 0.01730608195066452, 0.0, 0.0, 0.0], [0.7660508155822754, 0.1544468104839325, 0.03188299760222435, 0.04761935770511627, 0.0, 0.0], [0.7035229206085205, 0.0517142117023468, 0.07761009782552719, 0.1533903032541275, 0.013762438669800758, 0.0], [0.7121880650520325, 0.04994235187768936, 0.03772565349936485, 0.08649145811796188, 0.06541427969932556, 0.048238206654787064]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.974072277545929, 0.025927728042006493, 0.0, 0.0, 0.0, 0.0], [0.792539656162262, 0.011715562082827091, 0.19574476778507233, 0.0, 0.0, 0.0], [0.5106766819953918, 0.007296766620129347, 0.03961999714374542, 0.4424065053462982, 0.0, 0.0], [0.5862478017807007, 0.012099698185920715, 0.024585217237472534, 0.06737837195396423, 0.3096889853477478, 0.0], [0.3019629716873169, 0.007724009454250336, 0.011518126353621483, 0.04694725573062897, 0.22146691381931305, 0.41038069128990173]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9744554162025452, 0.025544624775648117, 0.0, 0.0, 0.0, 0.0], [0.9769196510314941, 0.015048498287796974, 0.008031906560063362, 0.0, 0.0, 0.0], [0.9060619473457336, 0.025875406339764595, 0.0259548369795084, 0.04210779070854187, 0.0, 0.0], [0.9400081038475037, 0.00555665185675025, 0.005828304681926966, 0.031757812947034836, 0.01684906892478466, 0.0], [0.9105739593505859, 0.00197521666996181, 0.008646715432405472, 0.013360830023884773, 0.03543954715132713, 0.030003638938069344]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9791666865348816, 0.020833350718021393, 0.0, 0.0, 0.0, 0.0], [0.8444867730140686, 0.1350778490304947, 0.02043532207608223, 0.0, 0.0, 0.0], [0.79030841588974, 0.145591601729393, 0.03753012418746948, 0.026569755747914314, 0.0, 0.0], [0.7298934459686279, 0.05649610608816147, 0.03273553401231766, 0.10400418937206268, 0.07687069475650787, 0.0], [0.5684201121330261, 0.0438881553709507, 0.026293382048606873, 0.08117102831602097, 0.24314747750759125, 0.0370798297226429]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9499868154525757, 0.05001312494277954, 0.0, 0.0, 0.0, 0.0], [0.9336171746253967, 0.05848865583539009, 0.007894255220890045, 0.0, 0.0, 0.0], [0.7897833585739136, 0.11071822792291641, 0.05360185354948044, 0.045896612107753754, 0.0, 0.0], [0.885930061340332, 0.05752985551953316, 0.013743252493441105, 0.0033877433743327856, 0.03940894454717636, 0.0], [0.9337607622146606, 0.026470622047781944, 0.004523388110101223, 0.006190470885485411, 0.014132914133369923, 0.014921694993972778]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.0, 1.8521260081172386e-09, 0.0, 0.0, 0.0, 0.0], [6.675903478026157e-06, 0.9999804496765137, 1.2841342140745837e-05, 0.0, 0.0, 0.0], [2.2193603399500716e-08, 2.6684225939987982e-09, 0.9999971389770508, 2.8136612399976e-06, 0.0, 0.0], [1.0145256510440959e-06, 4.46400640896627e-08, 0.0003535630239639431, 0.9993677735328674, 0.00027762516401708126, 0.0], [9.43658595708996e-10, 1.3820626067195807e-11, 5.017902204862423e-10, 2.965183876213473e-09, 0.9999971389770508, 2.8643494260904845e-06]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9948632121086121, 0.00513676879927516, 0.0, 0.0, 0.0, 0.0], [0.9274215698242188, 0.01832391880452633, 0.054254528135061264, 0.0, 0.0, 0.0], [0.9678993225097656, 0.004143425729125738, 0.004314453341066837, 0.02364284358918667, 0.0, 0.0], [0.8999071717262268, 0.0014671594835817814, 0.0002913369389716536, 0.002585020614787936, 0.09574926644563675, 0.0], [0.9386116862297058, 0.00022248283494263887, 0.0006146674859337509, 0.001549566863104701, 0.030689409002661705, 0.02831234037876129]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9999959468841553, 4.042728050990263e-06, 0.0, 0.0, 0.0, 0.0], [0.9982761144638062, 3.2613893381494563e-06, 0.0017206610646098852, 0.0, 0.0, 0.0], [0.9998809099197388, 5.328835683826583e-08, 6.376221790560521e-07, 0.00011847093992400914, 0.0, 0.0], [0.9996154308319092, 3.4731661457954033e-07, 3.892111877235038e-08, 4.4684205136036326e-07, 0.0003836941614281386, 0.0], [0.9994840621948242, 1.6550078640875654e-08, 2.8715612998553297e-08, 1.0638264029694255e-06, 0.0002126663748640567, 0.00030211807461455464]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9514135718345642, 0.04858642816543579, 0.0, 0.0, 0.0, 0.0], [0.5749937295913696, 0.39028200507164, 0.03472421318292618, 0.0, 0.0, 0.0], [0.744231641292572, 0.17524123191833496, 0.0756477639079094, 0.004879268351942301, 0.0, 0.0], [0.5232070088386536, 0.0942932739853859, 0.11381909251213074, 0.199792742729187, 0.06888788938522339, 0.0], [0.47472670674324036, 0.05636586248874664, 0.04530372843146324, 0.06967273354530334, 0.3098013997077942, 0.044129498302936554]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8734647035598755, 0.12653528153896332, 0.0, 0.0, 0.0, 0.0], [0.6097909212112427, 0.3541729152202606, 0.036036167293787, 0.0, 0.0, 0.0], [0.45984145998954773, 0.3869791030883789, 0.09960132837295532, 0.0535782128572464, 0.0, 0.0], [0.5722206234931946, 0.23636245727539062, 0.08344567567110062, 0.06921914219856262, 0.03875211626291275, 0.0], [0.5143572092056274, 0.16723047196865082, 0.0901939794421196, 0.0765446126461029, 0.1057807207107544, 0.045892927795648575]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.981228768825531, 0.018771260976791382, 0.0, 0.0, 0.0, 0.0], [0.6142943501472473, 0.3503974974155426, 0.03530814126133919, 0.0, 0.0, 0.0], [0.5770685076713562, 0.32858479022979736, 0.055082615464925766, 0.039264190942049026, 0.0, 0.0], [0.1718820184469223, 0.011042507365345955, 0.05457884445786476, 0.7326582670211792, 0.02983839437365532, 0.0], [0.3783011734485626, 0.017070064321160316, 0.021754175424575806, 0.44096899032592773, 0.06093829870223999, 0.0809672474861145]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9923112392425537, 0.007688738871365786, 0.0, 0.0, 0.0, 0.0], [0.9498787522315979, 0.01670977473258972, 0.033411506563425064, 0.0, 0.0, 0.0], [0.9961295127868652, 0.0008787282276898623, 0.0006868182099424303, 0.002304845955222845, 0.0, 0.0], [0.9935757517814636, 0.0032635012175887823, 0.0009993863059207797, 0.0002793227322399616, 0.0018820592667907476, 0.0], [0.9907532930374146, 0.00021344238484743983, 0.00045952422078698874, 0.0007905613165348768, 0.004424726124852896, 0.0033583571203052998]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.964773952960968, 0.03522602468729019, 0.0, 0.0, 0.0, 0.0], [0.8194128274917603, 0.1365438550710678, 0.04404330253601074, 0.0, 0.0, 0.0], [0.7584255337715149, 0.006878912448883057, 0.20653310418128967, 0.028162462636828423, 0.0, 0.0], [0.5298123359680176, 0.002678809454664588, 0.07857999205589294, 0.3598378598690033, 0.029091043397784233, 0.0], [0.754441499710083, 0.0003678227076306939, 0.001971352146938443, 0.0032400530762970448, 0.19423414766788483, 0.04574509337544441]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9749132394790649, 0.02508675493299961, 0.0, 0.0, 0.0, 0.0], [0.9306471943855286, 0.05705658718943596, 0.01229624543339014, 0.0, 0.0, 0.0], [0.9305250644683838, 0.05277106165885925, 0.011119479313492775, 0.005584415048360825, 0.0, 0.0], [0.8863321542739868, 0.012924151495099068, 0.017724741250276566, 0.06150190532207489, 0.02151712030172348, 0.0], [0.7916855216026306, 0.015036052092909813, 0.03174784779548645, 0.033921852707862854, 0.0370795801281929, 0.0905291959643364]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9608500599861145, 0.039149921387434006, 0.0, 0.0, 0.0, 0.0], [0.9121274352073669, 0.022576449438929558, 0.06529611349105835, 0.0, 0.0, 0.0], [0.9364107251167297, 0.015584415756165981, 0.0245449710637331, 0.0234599057585001, 0.0, 0.0], [0.9454621076583862, 0.006762259639799595, 0.022026216611266136, 0.009137730114161968, 0.016611695289611816, 0.0], [0.8346174955368042, 0.001881692442111671, 0.005609028972685337, 0.018873492255806923, 0.12449129670858383, 0.014527009800076485]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9964227080345154, 0.003577282652258873, 0.0, 0.0, 0.0, 0.0], [0.9713928699493408, 0.024453025311231613, 0.004154070280492306, 0.0, 0.0, 0.0], [0.9735792279243469, 0.01900338940322399, 0.003664416028186679, 0.0037529077380895615, 0.0, 0.0], [0.9586312174797058, 0.0071162013337016106, 0.009218445979058743, 0.02272566594183445, 0.002308481838554144, 0.0], [0.973607063293457, 0.008490566164255142, 0.003251248737797141, 0.0036064349114894867, 0.004877458792179823, 0.006167220883071423]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.97598797082901, 0.024011967703700066, 0.0, 0.0, 0.0, 0.0], [0.9460638165473938, 0.04211372509598732, 0.01182244811207056, 0.0, 0.0, 0.0], [0.8446813225746155, 0.04293111711740494, 0.05218198522925377, 0.0602056086063385, 0.0, 0.0], [0.9378372430801392, 0.03354859724640846, 0.008826459757983685, 0.002879226813092828, 0.016908442601561546, 0.0], [0.8124936819076538, 0.02696746587753296, 0.05999191105365753, 0.034457143396139145, 0.011011820286512375, 0.0550779327750206]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9001204967498779, 0.09987951070070267, 0.0, 0.0, 0.0, 0.0], [0.6271927952766418, 0.07988713681697845, 0.2929201126098633, 0.0, 0.0, 0.0], [0.7624075412750244, 0.027344312518835068, 0.03867955133318901, 0.17156852781772614, 0.0, 0.0], [0.7995960116386414, 0.014336294494569302, 0.014375682920217514, 0.02543851174414158, 0.14625348150730133, 0.0], [0.7851974964141846, 0.0420403778553009, 0.02525358647108078, 0.029083862900733948, 0.029306240379810333, 0.08911842852830887]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954467415809631, 0.004553199280053377, 0.0, 0.0, 0.0, 0.0], [0.9356003999710083, 0.04476733133196831, 0.019632287323474884, 0.0, 0.0, 0.0], [0.5605555772781372, 0.09861976653337479, 0.29983237385749817, 0.040992334485054016, 0.0, 0.0], [0.5893721580505371, 0.11000939458608627, 0.08033614605665207, 0.16753984987735748, 0.05274246260523796, 0.0], [0.22306011617183685, 0.056808121502399445, 0.05467968434095383, 0.24733951687812805, 0.31112346053123474, 0.1069890707731247]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9301451444625854, 0.06985487043857574, 0.0, 0.0, 0.0, 0.0], [0.8936480283737183, 0.08535702526569366, 0.020994946360588074, 0.0, 0.0, 0.0], [0.8404536247253418, 0.1061922013759613, 0.023636743426322937, 0.029717376455664635, 0.0, 0.0], [0.8927384614944458, 0.024784700945019722, 0.008319015614688396, 0.05165454372763634, 0.022503262385725975, 0.0], [0.8646613359451294, 0.009503137320280075, 0.0024329768493771553, 0.04796736314892769, 0.04273197054862976, 0.03270314633846283]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9859625697135925, 0.014037388376891613, 0.0, 0.0, 0.0, 0.0], [0.9702037572860718, 0.016807029023766518, 0.012989150360226631, 0.0, 0.0, 0.0], [0.9524770379066467, 0.016064437106251717, 0.013456246815621853, 0.018002305179834366, 0.0, 0.0], [0.9332926869392395, 0.018972063437104225, 0.02014695107936859, 0.01702381670475006, 0.010564573109149933, 0.0], [0.9113592505455017, 0.012528608553111553, 0.022096263244748116, 0.017518579959869385, 0.01851789280772209, 0.017979402095079422]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9681769013404846, 0.03182310611009598, 0.0, 0.0, 0.0, 0.0], [0.9096419215202332, 0.07916685938835144, 0.01119125634431839, 0.0, 0.0, 0.0], [0.8379933834075928, 0.13078252971172333, 0.012140998616814613, 0.019083015620708466, 0.0, 0.0], [0.9116523265838623, 0.054519619792699814, 0.00949938502162695, 0.007465861737728119, 0.016862777993083, 0.0], [0.851029098033905, 0.07338204979896545, 0.008022509515285492, 0.009083150885999203, 0.04260997846722603, 0.015873290598392487]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9799023866653442, 0.020097682252526283, 0.0, 0.0, 0.0, 0.0], [0.9558742642402649, 0.02906331978738308, 0.015062525868415833, 0.0, 0.0, 0.0], [0.7943134903907776, 0.06074090674519539, 0.06907660514116287, 0.07586902379989624, 0.0, 0.0], [0.5494317412376404, 0.03154715523123741, 0.054820265620946884, 0.057880859822034836, 0.3063200116157532, 0.0], [0.6453989744186401, 0.010770932771265507, 0.017528090626001358, 0.021579807624220848, 0.24958215653896332, 0.05514010041952133]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9506810307502747, 0.04931899905204773, 0.0, 0.0, 0.0, 0.0], [0.8553216457366943, 0.0925624817609787, 0.05211583897471428, 0.0, 0.0, 0.0], [0.8508524298667908, 0.047345925122499466, 0.04417736455798149, 0.057624299079179764, 0.0, 0.0], [0.7697127461433411, 0.027885807678103447, 0.031017374247312546, 0.06842515617609024, 0.10295884311199188, 0.0], [0.7931904792785645, 0.04052181541919708, 0.02924203872680664, 0.04478130862116814, 0.04894694313406944, 0.04331747815012932]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9770310521125793, 0.02296891249716282, 0.0, 0.0, 0.0, 0.0], [0.9429817199707031, 0.01732144132256508, 0.03969675302505493, 0.0, 0.0, 0.0], [0.9144347310066223, 0.00858356710523367, 0.013035789132118225, 0.06394591182470322, 0.0, 0.0], [0.9222429990768433, 0.0036440351977944374, 0.003740282729268074, 0.010410360060632229, 0.05996229872107506, 0.0], [0.9198877215385437, 0.00308226328343153, 0.0034827536437660456, 0.004206801764667034, 0.021254312247037888, 0.0480860210955143]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.977458119392395, 0.022541867569088936, 0.0, 0.0, 0.0, 0.0], [0.8929325342178345, 0.07475461065769196, 0.03231288120150566, 0.0, 0.0, 0.0], [0.8423514366149902, 0.05980268120765686, 0.03740082308650017, 0.06044512242078781, 0.0, 0.0], [0.767462968826294, 0.035363391041755676, 0.042155198752880096, 0.06658652424812317, 0.08843202888965607, 0.0], [0.6182615160942078, 0.016110582277178764, 0.020167652517557144, 0.038688965141773224, 0.23146964609622955, 0.07530171424150467]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9634855389595032, 0.03651442751288414, 0.0, 0.0, 0.0, 0.0], [0.4363935589790344, 0.5226373672485352, 0.040969084948301315, 0.0, 0.0, 0.0], [0.36086100339889526, 0.35129719972610474, 0.265510618686676, 0.022331176325678825, 0.0, 0.0], [0.39429211616516113, 0.02170465514063835, 0.07794343680143356, 0.3716889023780823, 0.13437090814113617, 0.0], [0.6310721635818481, 0.01698395051062107, 0.025942014530301094, 0.08615919947624207, 0.21831989288330078, 0.021522851660847664]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9988250136375427, 0.0011750215198844671, 0.0, 0.0, 0.0, 0.0], [0.9944871068000793, 0.000482639909023419, 0.0050302306190133095, 0.0, 0.0, 0.0], [0.9981209635734558, 2.7051579309045337e-05, 0.00011307407839922234, 0.001738940947689116, 0.0, 0.0], [0.9982239603996277, 6.83655816828832e-05, 0.00010199954704148695, 6.028387360856868e-05, 0.001545313629321754, 0.0], [0.9982888102531433, 1.0552178082434693e-06, 3.278099757153541e-05, 0.00013039002078585327, 0.000660590420011431, 0.0008863671682775021]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9936710596084595, 0.006328931078314781, 0.0, 0.0, 0.0, 0.0], [0.9727688431739807, 0.0018561385804787278, 0.02537504769861698, 0.0, 0.0, 0.0], [0.9724299907684326, 0.0019586130511015654, 0.0111924447119236, 0.014418884180486202, 0.0, 0.0], [0.9782042503356934, 0.0009589148685336113, 0.0018706441624090075, 0.006326551549136639, 0.012639685533940792, 0.0], [0.9592596888542175, 0.0024555183481425047, 0.0016124190296977758, 0.005019677337259054, 0.006687132176011801, 0.024965709075331688]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629000425338745, 0.037099964916706085, 0.0, 0.0, 0.0, 0.0], [0.3680204749107361, 0.6152247786521912, 0.016754787415266037, 0.0, 0.0, 0.0], [0.31735146045684814, 0.6140009760856628, 0.053751520812511444, 0.014896061271429062, 0.0, 0.0], [0.48987242579460144, 0.21071438491344452, 0.04693024978041649, 0.20700497925281525, 0.045477937906980515, 0.0], [0.48774248361587524, 0.17695219814777374, 0.06915215402841568, 0.09849291294813156, 0.12091444432735443, 0.04674571007490158]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9794419407844543, 0.02055801823735237, 0.0, 0.0, 0.0, 0.0], [0.6677901148796082, 0.3103237748146057, 0.021886024624109268, 0.0, 0.0, 0.0], [0.7118752002716064, 0.11108573526144028, 0.14187400043010712, 0.03516511619091034, 0.0, 0.0], [0.45014554262161255, 0.04036048427224159, 0.040458329021930695, 0.3885704278945923, 0.08046524226665497, 0.0], [0.49346134066581726, 0.013696961104869843, 0.008126801811158657, 0.1307452917098999, 0.30861467123031616, 0.04535486549139023]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846054315567017, 0.015394557267427444, 0.0, 0.0, 0.0, 0.0], [0.9806739091873169, 0.00771379517391324, 0.011612341739237309, 0.0, 0.0, 0.0], [0.932663083076477, 0.019578365609049797, 0.024103496223688126, 0.023654954507946968, 0.0, 0.0], [0.9422017931938171, 0.0009538942249491811, 0.0010898011969402432, 0.0031933740247040987, 0.052561141550540924, 0.0], [0.9352928400039673, 0.0010279340203851461, 0.00444443104788661, 0.0016371429665014148, 0.010590991005301476, 0.047006651759147644]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9985783100128174, 0.0014216711279004812, 0.0, 0.0, 0.0, 0.0], [0.9893348813056946, 0.0011178896529600024, 0.009547151625156403, 0.0, 0.0, 0.0], [0.9979978203773499, 7.997019565664232e-05, 0.00013218825915828347, 0.0017900315579026937, 0.0, 0.0], [0.9986976385116577, 4.104396066395566e-05, 3.86835108656669e-06, 2.3676237105973996e-05, 0.0012337120715528727, 0.0], [0.9971562623977661, 1.8522248865338042e-05, 1.8826665382221108e-06, 2.7900308850803412e-05, 0.0006533503765240312, 0.0021419888362288475]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9768234491348267, 0.023176616057753563, 0.0, 0.0, 0.0, 0.0], [0.9194678664207458, 0.05088184028863907, 0.02965029887855053, 0.0, 0.0, 0.0], [0.8474552631378174, 0.0610017366707325, 0.043723780661821365, 0.04781918227672577, 0.0, 0.0], [0.8011623620986938, 0.04186701774597168, 0.04375810548663139, 0.04189479723572731, 0.07131779938936234, 0.0], [0.8031870126724243, 0.024504972621798515, 0.017323583364486694, 0.047443993389606476, 0.061099253594875336, 0.04644118249416351]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9829428195953369, 0.017057159915566444, 0.0, 0.0, 0.0, 0.0], [0.8863736391067505, 0.09492656588554382, 0.01869977079331875, 0.0, 0.0, 0.0], [0.9231083989143372, 0.03696353733539581, 0.03219838812947273, 0.00772966630756855, 0.0, 0.0], [0.9068527221679688, 0.016046592965722084, 0.014310522936284542, 0.04543788731098175, 0.017352281138300896, 0.0], [0.6555968523025513, 0.05091021955013275, 0.028384927660226822, 0.1256553679704666, 0.10546855628490448, 0.03398403897881508]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9502320885658264, 0.049767933785915375, 0.0, 0.0, 0.0, 0.0], [0.882986843585968, 0.10009609907865524, 0.01691715605556965, 0.0, 0.0, 0.0], [0.8057457804679871, 0.14463543891906738, 0.030189240351319313, 0.019429462030529976, 0.0, 0.0], [0.8706230521202087, 0.03244059532880783, 0.026951614767313004, 0.04410304129123688, 0.02588159590959549, 0.0], [0.6883643269538879, 0.00968147162348032, 0.016449356451630592, 0.09871123731136322, 0.08971188217401505, 0.09708172082901001]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9792683720588684, 0.020731639117002487, 0.0, 0.0, 0.0, 0.0], [0.9523285627365112, 0.025933803990483284, 0.02173773944377899, 0.0, 0.0, 0.0], [0.9144353270530701, 0.017671240493655205, 0.022358544170856476, 0.04553484544157982, 0.0, 0.0], [0.9448292851448059, 0.006467597559094429, 0.006386075634509325, 0.03263096883893013, 0.009686199016869068, 0.0], [0.9347904920578003, 0.007862492464482784, 0.00778817106038332, 0.021432826295495033, 0.008491143584251404, 0.019634811207652092]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.983370304107666, 0.01662970893085003, 0.0, 0.0, 0.0, 0.0], [0.963111400604248, 0.009229961782693863, 0.027658678591251373, 0.0, 0.0, 0.0], [0.9706627130508423, 0.0041494122706353664, 0.006813110783696175, 0.018374666571617126, 0.0, 0.0], [0.987951934337616, 0.0021658826153725386, 0.0003490109520498663, 0.0015838148538023233, 0.007949409075081348, 0.0], [0.9457950592041016, 0.014583510346710682, 0.0003652951563708484, 0.0009569510584697127, 0.01362155843526125, 0.02467748336493969]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9878059029579163, 0.012194057926535606, 0.0, 0.0, 0.0, 0.0], [0.8710368275642395, 0.09448162466287613, 0.03448151424527168, 0.0, 0.0, 0.0], [0.6309778094291687, 0.11090415716171265, 0.19230234622955322, 0.06581573933362961, 0.0, 0.0], [0.5360508561134338, 0.04618927836418152, 0.1360524743795395, 0.26455411314964294, 0.01715322956442833, 0.0], [0.8287523984909058, 0.023732686415314674, 0.0200803205370903, 0.07245255261659622, 0.030431007966399193, 0.024550918489694595]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8995687365531921, 0.10043126344680786, 0.0, 0.0, 0.0, 0.0], [0.27034348249435425, 0.6504330039024353, 0.07922350615262985, 0.0, 0.0, 0.0], [0.20541679859161377, 0.5892513394355774, 0.18085838854312897, 0.024473492056131363, 0.0, 0.0], [0.557386577129364, 0.17741332948207855, 0.08806800842285156, 0.09881839901208878, 0.07831361889839172, 0.0], [0.592290997505188, 0.08700643479824066, 0.05643286183476448, 0.056858956813812256, 0.12181514501571655, 0.08559554815292358]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9316380620002747, 0.06836196035146713, 0.0, 0.0, 0.0, 0.0], [0.9572947025299072, 0.026243478059768677, 0.01646178960800171, 0.0, 0.0, 0.0], [0.9880544543266296, 0.004273314960300922, 0.0029545787256211042, 0.004717642907053232, 0.0, 0.0], [0.99403977394104, 0.000941342965234071, 0.00047398428432643414, 0.0001164695349871181, 0.004428449086844921, 0.0], [0.9806035161018372, 2.5468691092100926e-05, 0.0001623934949748218, 0.00014764114166609943, 0.001344241201877594, 0.017716819420456886]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.993178129196167, 0.006821834947913885, 0.0, 0.0, 0.0, 0.0], [0.9756524562835693, 0.013184119947254658, 0.011163449846208096, 0.0, 0.0, 0.0], [0.9418966770172119, 0.004721749108284712, 0.0023818123154342175, 0.050999753177165985, 0.0, 0.0], [0.9905040860176086, 0.002284808550029993, 6.19848069618456e-05, 0.0005984465242363513, 0.0065506696701049805, 0.0], [0.9697662591934204, 0.000887882721144706, 0.0002346669789403677, 0.001704077236354351, 0.004128350876271725, 0.023278873413801193]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9716231822967529, 0.028376810252666473, 0.0, 0.0, 0.0, 0.0], [0.9223620295524597, 0.028907237574458122, 0.048730701208114624, 0.0, 0.0, 0.0], [0.8426316380500793, 0.023872135207057, 0.047481343150138855, 0.08601481467485428, 0.0, 0.0], [0.8521119952201843, 0.020744245499372482, 0.04494619369506836, 0.0576501302421093, 0.024547411128878593, 0.0], [0.8800727725028992, 0.022448495030403137, 0.018235674127936363, 0.01925477385520935, 0.01585422269999981, 0.04413408041000366]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9412723779678345, 0.058727655559778214, 0.0, 0.0, 0.0, 0.0], [0.916313886642456, 0.05759201943874359, 0.026094043627381325, 0.0, 0.0, 0.0], [0.8392420411109924, 0.0576905757188797, 0.013829050585627556, 0.089238241314888, 0.0, 0.0], [0.8987160325050354, 0.013477892614901066, 0.0003456464037299156, 0.003298763185739517, 0.08416159451007843, 0.0], [0.8701689839363098, 0.002700863406062126, 0.0014349977718666196, 0.005666180979460478, 0.08874324709177017, 0.031285710632801056]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9656725525856018, 0.034327439963817596, 0.0, 0.0, 0.0, 0.0], [0.9178615212440491, 0.062257975339889526, 0.019880497828125954, 0.0, 0.0, 0.0], [0.8233147859573364, 0.06282391399145126, 0.03670433908700943, 0.07715694606304169, 0.0, 0.0], [0.850174605846405, 0.038169246166944504, 0.03196500986814499, 0.051601458340883255, 0.028089668601751328, 0.0], [0.6572404503822327, 0.058773960918188095, 0.04336008429527283, 0.09013216942548752, 0.08146587014198303, 0.06902747601270676]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9162061810493469, 0.08379381895065308, 0.0, 0.0, 0.0, 0.0], [0.9451773762702942, 0.04099279269576073, 0.013829839415848255, 0.0, 0.0, 0.0], [0.8928354978561401, 0.05368681252002716, 0.017597004771232605, 0.03588074818253517, 0.0, 0.0], [0.8337052464485168, 0.047996122390031815, 0.03351327404379845, 0.04680858924984932, 0.03797685727477074, 0.0], [0.8167197704315186, 0.06337116658687592, 0.013286247849464417, 0.020469708368182182, 0.02529226988554001, 0.06086098402738571]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9525134563446045, 0.04748653620481491, 0.0, 0.0, 0.0, 0.0], [0.30198657512664795, 0.6520941257476807, 0.04591922089457512, 0.0, 0.0, 0.0], [0.28558313846588135, 0.5569522976875305, 0.1444740742444992, 0.012990488670766354, 0.0, 0.0], [0.8438040614128113, 0.0322512723505497, 0.03954298049211502, 0.06848165392875671, 0.01592007651925087, 0.0], [0.6664938926696777, 0.06095923110842705, 0.04064349830150604, 0.06804486364126205, 0.0918637365102768, 0.0719948261976242]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9682655334472656, 0.03173447400331497, 0.0, 0.0, 0.0, 0.0], [0.7385219931602478, 0.22856836020946503, 0.03290965035557747, 0.0, 0.0, 0.0], [0.5946674346923828, 0.23033154010772705, 0.14867639541625977, 0.026324590668082237, 0.0, 0.0], [0.6339258551597595, 0.05813023820519447, 0.09654311835765839, 0.14291933178901672, 0.06848140805959702, 0.0], [0.40375664830207825, 0.08945391327142715, 0.0763508751988411, 0.2558707892894745, 0.14330387115478516, 0.03126382827758789]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9869793653488159, 0.013020600192248821, 0.0, 0.0, 0.0, 0.0], [0.8631383180618286, 0.11056677997112274, 0.02629486285150051, 0.0, 0.0, 0.0], [0.9488077759742737, 0.028615085408091545, 0.006535575725138187, 0.016041584312915802, 0.0, 0.0], [0.9672170877456665, 0.006604996509850025, 0.0004517149063758552, 0.004844421520829201, 0.020881768316030502, 0.0], [0.9354620575904846, 0.02047811448574066, 0.0011700240429490805, 0.007056952454149723, 0.01631820760667324, 0.0195146631449461]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9846673011779785, 0.015332731418311596, 0.0, 0.0, 0.0, 0.0], [0.9052743315696716, 0.08373638242483139, 0.010989279486238956, 0.0, 0.0, 0.0], [0.8145939707756042, 0.04283738136291504, 0.10568298399448395, 0.036885667592287064, 0.0, 0.0], [0.23519864678382874, 0.012018423527479172, 0.052801016718149185, 0.6516178250312805, 0.0483640655875206, 0.0], [0.31818586587905884, 0.01863238587975502, 0.03948180750012398, 0.37555408477783203, 0.2078733742237091, 0.04027256369590759]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9811733365058899, 0.018826698884367943, 0.0, 0.0, 0.0, 0.0], [0.861893892288208, 0.06479166448116302, 0.07331448048353195, 0.0, 0.0, 0.0], [0.7664541006088257, 0.0733041912317276, 0.10353526473045349, 0.05670643597841263, 0.0, 0.0], [0.8128494024276733, 0.032154932618141174, 0.05900587886571884, 0.05416533723473549, 0.041824545711278915, 0.0], [0.8687860369682312, 0.026987731456756592, 0.02046993561089039, 0.016297340393066406, 0.03218373283743858, 0.03527515381574631]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9264583587646484, 0.07354163378477097, 0.0, 0.0, 0.0, 0.0], [0.840353786945343, 0.06373763829469681, 0.09590858221054077, 0.0, 0.0, 0.0], [0.7330995202064514, 0.06451121717691422, 0.10380081832408905, 0.09858846664428711, 0.0, 0.0], [0.9143611788749695, 0.008257775567471981, 0.0073203882202506065, 0.0179662574082613, 0.052094392478466034, 0.0], [0.8971915245056152, 0.008555498905479908, 0.007019446697086096, 0.014860529452562332, 0.03399762138724327, 0.038375258445739746]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9180347919464111, 0.08196521550416946, 0.0, 0.0, 0.0, 0.0], [0.8328665494918823, 0.12199021875858307, 0.04514317587018013, 0.0, 0.0, 0.0], [0.7994157075881958, 0.08744136989116669, 0.03605782240629196, 0.07708513736724854, 0.0, 0.0], [0.8809850215911865, 0.02074962854385376, 0.020554590970277786, 0.017120812088251114, 0.06058994680643082, 0.0], [0.7453036904335022, 0.04433394968509674, 0.022549200803041458, 0.03315267711877823, 0.0335705541074276, 0.12108993530273438]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9867060780525208, 0.013293919153511524, 0.0, 0.0, 0.0, 0.0], [0.982177734375, 0.012414149008691311, 0.005408118944615126, 0.0, 0.0, 0.0], [0.96304851770401, 0.015290765091776848, 0.010345702059566975, 0.011314956471323967, 0.0, 0.0], [0.921357274055481, 0.014132414944469929, 0.01763911545276642, 0.016567610204219818, 0.03030361607670784, 0.0], [0.9373326301574707, 0.009064320474863052, 0.007548372261226177, 0.006576449144631624, 0.011827622540295124, 0.027650468051433563]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9951004385948181, 0.004899625666439533, 0.0, 0.0, 0.0, 0.0], [0.9476008415222168, 0.04140792787075043, 0.01099128182977438, 0.0, 0.0, 0.0], [0.914217472076416, 0.023523781448602676, 0.0391450896859169, 0.023113636299967766, 0.0, 0.0], [0.9534734487533569, 0.008932958357036114, 0.01527285948395729, 0.007908289320766926, 0.01441233605146408, 0.0], [0.9427102208137512, 0.008233072236180305, 0.004650996532291174, 0.004178107716143131, 0.005463524721562862, 0.034764114767313004]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9543375372886658, 0.045662399381399155, 0.0, 0.0, 0.0, 0.0], [0.9696040749549866, 0.01954764500260353, 0.010848326608538628, 0.0, 0.0, 0.0], [0.9710449576377869, 0.012425409629940987, 0.008068899624049664, 0.008460735902190208, 0.0, 0.0], [0.9726192951202393, 0.0026976661756634712, 0.0004483147931750864, 0.0013814790872856975, 0.022853214293718338, 0.0], [0.9675467610359192, 0.00961342453956604, 0.0032030234578996897, 0.004248827695846558, 0.007442236877977848, 0.007945860736072063]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9887008666992188, 0.011299116536974907, 0.0, 0.0, 0.0, 0.0], [0.9382632374763489, 0.04204237088561058, 0.019694417715072632, 0.0, 0.0, 0.0], [0.8351995348930359, 0.03487849235534668, 0.05134478211402893, 0.0785771831870079, 0.0, 0.0], [0.9042682647705078, 0.010541536845266819, 0.01642668806016445, 0.025921892374753952, 0.04284176975488663, 0.0], [0.8913140296936035, 0.00891267228871584, 0.005010711494833231, 0.008175631985068321, 0.01351472269743681, 0.07307225465774536]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8693917393684387, 0.13060827553272247, 0.0, 0.0, 0.0, 0.0], [0.3507991135120392, 0.6063516139984131, 0.042849257588386536, 0.0, 0.0, 0.0], [0.35475584864616394, 0.3502020537853241, 0.24722479283809662, 0.04781736060976982, 0.0, 0.0], [0.3537052869796753, 0.03527728095650673, 0.09567125141620636, 0.44979700446128845, 0.06554915010929108, 0.0], [0.4132605493068695, 0.09055498242378235, 0.05286572501063347, 0.1746796816587448, 0.17384834587574005, 0.09479069709777832]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9629756212234497, 0.0370243638753891, 0.0, 0.0, 0.0, 0.0], [0.9756426811218262, 0.019658580422401428, 0.00469872634857893, 0.0, 0.0, 0.0], [0.9775736331939697, 0.013286291621625423, 0.002559040440246463, 0.006581087596714497, 0.0, 0.0], [0.9870141744613647, 0.007388267666101456, 0.0009579190518707037, 0.0018318271031603217, 0.002807757118716836, 0.0], [0.9409245848655701, 0.01663369871675968, 0.0022979089990258217, 0.005890654865652323, 0.0055129146203398705, 0.028740227222442627]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.962827205657959, 0.03717280924320221, 0.0, 0.0, 0.0, 0.0], [0.9582237601280212, 0.024641839787364006, 0.01713441126048565, 0.0, 0.0, 0.0], [0.9351300001144409, 0.01533155981451273, 0.014810988679528236, 0.034727487713098526, 0.0, 0.0], [0.9225171208381653, 0.010528765618801117, 0.011010175570845604, 0.019440075382590294, 0.03650391846895218, 0.0], [0.8420167565345764, 0.043571941554546356, 0.007488266099244356, 0.01496152114123106, 0.023852868005633354, 0.06810871511697769]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9926387071609497, 0.007361340336501598, 0.0, 0.0, 0.0, 0.0], [0.9957393407821655, 0.003346986835822463, 0.0009136911830864847, 0.0, 0.0, 0.0], [0.9869900345802307, 0.0019747884944081306, 0.0015245546819642186, 0.009510713629424572, 0.0, 0.0], [0.9933527708053589, 0.0010203253477811813, 0.00034337257966399193, 0.0010291127255186439, 0.004254375584423542, 0.0], [0.9749016761779785, 0.0004348014772403985, 0.00043065508361905813, 0.0012364371214061975, 0.0015347691951319575, 0.0214616060256958]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9897475242614746, 0.010252452455461025, 0.0, 0.0, 0.0, 0.0], [0.9790639281272888, 0.016509056091308594, 0.004427103791385889, 0.0, 0.0, 0.0], [0.9521437287330627, 0.02943229302763939, 0.008943171240389347, 0.009480933658778667, 0.0, 0.0], [0.9395941495895386, 0.02151092328131199, 0.010278573259711266, 0.004555240273475647, 0.02406112663447857, 0.0], [0.9205076098442078, 0.016153624281287193, 0.010818622075021267, 0.016644427552819252, 0.014566363766789436, 0.021309377625584602]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9898501634597778, 0.010149775072932243, 0.0, 0.0, 0.0, 0.0], [0.9820908904075623, 0.006907526403665543, 0.011001539416611195, 0.0, 0.0, 0.0], [0.9684997200965881, 0.00898759812116623, 0.015342569909989834, 0.0071700941771268845, 0.0, 0.0], [0.9274121522903442, 0.009485254064202309, 0.02206612005829811, 0.03222893923521042, 0.008807620964944363, 0.0], [0.9006659388542175, 0.021623753011226654, 0.013808260671794415, 0.009843838401138783, 0.00852135755121708, 0.04553692787885666]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9954444169998169, 0.004555594641715288, 0.0, 0.0, 0.0, 0.0], [0.995254397392273, 0.002460238989442587, 0.0022854891140013933, 0.0, 0.0, 0.0], [0.9862446188926697, 0.0015168144600465894, 0.004072294104844332, 0.0081663578748703, 0.0, 0.0], [0.9889963865280151, 0.0012260436778888106, 0.000799637520685792, 0.0006774249486625195, 0.008300581946969032, 0.0], [0.9865202903747559, 0.0003942708426620811, 0.0009571776608936489, 0.0004954370087943971, 0.0009604979422874749, 0.010672301054000854]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9821295142173767, 0.017870450392365456, 0.0, 0.0, 0.0, 0.0], [0.7489441633224487, 0.2200266420841217, 0.03102918341755867, 0.0, 0.0, 0.0], [0.2854781150817871, 0.2112564593553543, 0.47871625423431396, 0.024549271911382675, 0.0, 0.0], [0.8056638836860657, 0.026974665001034737, 0.04302823543548584, 0.06993737071752548, 0.054395824670791626, 0.0], [0.33072203397750854, 0.022326543927192688, 0.016627110540866852, 0.08019448071718216, 0.41574740409851074, 0.13438241183757782]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9697746634483337, 0.030225304886698723, 0.0, 0.0, 0.0, 0.0], [0.9800565838813782, 0.01501889992505312, 0.004924531560391188, 0.0, 0.0, 0.0], [0.9237860441207886, 0.052764855325222015, 0.0063024042174220085, 0.017146749421954155, 0.0, 0.0], [0.9451844096183777, 0.036180444061756134, 0.0019892072305083275, 0.003958722576498985, 0.012687275186181068, 0.0], [0.9633328318595886, 0.018662936985492706, 0.0030418310780078173, 0.007070897612720728, 0.0050094048492610455, 0.0028820550069212914]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9873244762420654, 0.01267546508461237, 0.0, 0.0, 0.0, 0.0], [0.9904569983482361, 0.005541936494410038, 0.004001116845756769, 0.0, 0.0, 0.0], [0.9814971685409546, 0.00465345149859786, 0.00372528238222003, 0.010124064981937408, 0.0, 0.0], [0.9744364619255066, 0.004632250871509314, 0.0023799948394298553, 0.006518092937767506, 0.012033039703965187, 0.0], [0.9624499678611755, 0.003374351654201746, 0.0013198566157370806, 0.0017274974379688501, 0.002944669686257839, 0.02818365767598152]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9807674288749695, 0.019232602789998055, 0.0, 0.0, 0.0, 0.0], [0.9664247035980225, 0.0154139194637537, 0.01816144958138466, 0.0, 0.0, 0.0], [0.9632682204246521, 0.004538117907941341, 0.0029253941029310226, 0.02926820144057274, 0.0, 0.0], [0.9562349319458008, 0.0012223614612594247, 0.0005304082878865302, 0.008671483024954796, 0.033340904861688614, 0.0], [0.9657101035118103, 0.0009808274917304516, 0.0016686276067048311, 0.002634831238538027, 0.005866364110261202, 0.02313927561044693]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639714956283569, 0.03602852299809456, 0.0, 0.0, 0.0, 0.0], [0.9562799334526062, 0.03373318165540695, 0.009986845776438713, 0.0, 0.0, 0.0], [0.853999674320221, 0.08073031902313232, 0.03334449231624603, 0.031925544142723083, 0.0, 0.0], [0.9547491073608398, 0.009605043567717075, 0.004146157298237085, 0.002013318007811904, 0.029486333951354027, 0.0], [0.933113694190979, 0.02869970165193081, 0.005477478262037039, 0.006368077825754881, 0.012613045983016491, 0.013728044927120209]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9392993450164795, 0.06070062145590782, 0.0, 0.0, 0.0, 0.0], [0.929839015007019, 0.061895474791526794, 0.00826549157500267, 0.0, 0.0, 0.0], [0.8471820950508118, 0.09035061299800873, 0.017636112868785858, 0.044831179082393646, 0.0, 0.0], [0.885770320892334, 0.03918180614709854, 0.007867700420320034, 0.02276584692299366, 0.04441431537270546, 0.0], [0.8563282489776611, 0.10088985413312912, 0.0065314252860844135, 0.008485888130962849, 0.0073684146627783775, 0.020396165549755096]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8353267908096313, 0.16467322409152985, 0.0, 0.0, 0.0, 0.0], [0.6160862445831299, 0.3137644827365875, 0.0701492428779602, 0.0, 0.0, 0.0], [0.3431633710861206, 0.2758488953113556, 0.11966050416231155, 0.26132717728614807, 0.0, 0.0], [0.590817391872406, 0.050290681421756744, 0.041665878146886826, 0.21994929015636444, 0.09727674722671509, 0.0], [0.8481413125991821, 0.0631808266043663, 0.014733714051544666, 0.055267464369535446, 0.00901501253247261, 0.009661633521318436]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9627320766448975, 0.03726797550916672, 0.0, 0.0, 0.0, 0.0], [0.7757524847984314, 0.17996257543563843, 0.04428499937057495, 0.0, 0.0, 0.0], [0.6317061185836792, 0.2438071072101593, 0.1092565506696701, 0.015230262652039528, 0.0, 0.0], [0.9539909958839417, 0.01818224973976612, 0.011601795442402363, 0.012299071066081524, 0.00392577052116394, 0.0], [0.40356963872909546, 0.14237530529499054, 0.05661213770508766, 0.19757381081581116, 0.09299228340387344, 0.10687696188688278]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9802619218826294, 0.019738124683499336, 0.0, 0.0, 0.0, 0.0], [0.98739093542099, 0.007800445891916752, 0.0048086862079799175, 0.0, 0.0, 0.0], [0.9283919334411621, 0.008301216177642345, 0.01330563984811306, 0.05000118911266327, 0.0, 0.0], [0.8981055021286011, 0.015591299161314964, 0.01017758622765541, 0.039987027645111084, 0.036138664931058884, 0.0], [0.975350022315979, 0.00035432918230071664, 0.000586602371186018, 0.0011877480428665876, 0.0010750865330919623, 0.021446339786052704]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9295330047607422, 0.07046696543693542, 0.0, 0.0, 0.0, 0.0], [0.9361506104469299, 0.04116684943437576, 0.022682495415210724, 0.0, 0.0, 0.0], [0.848682165145874, 0.05802804231643677, 0.02485615573823452, 0.06843367964029312, 0.0, 0.0], [0.8661179542541504, 0.022324690595269203, 0.010369129478931427, 0.026001954451203346, 0.07518625259399414, 0.0], [0.8074424862861633, 0.04438251629471779, 0.018497074022889137, 0.03357783704996109, 0.018561221659183502, 0.07753884047269821]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9680535197257996, 0.03194639831781387, 0.0, 0.0, 0.0, 0.0], [0.9693688750267029, 0.02568497136235237, 0.0049460818991065025, 0.0, 0.0, 0.0], [0.9620568156242371, 0.02255242131650448, 0.0054713222198188305, 0.009919441305100918, 0.0, 0.0], [0.9727528095245361, 0.010137123987078667, 0.0007573263137601316, 0.002882888540625572, 0.013469807803630829, 0.0], [0.9624636769294739, 0.0031108937691897154, 0.001000758376903832, 0.0019475924782454967, 0.00826621986925602, 0.02321087382733822]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8542504906654358, 0.14574958384037018, 0.0, 0.0, 0.0, 0.0], [0.9725967645645142, 0.014116308651864529, 0.013286862522363663, 0.0, 0.0, 0.0], [0.9257621765136719, 0.03257258981466293, 0.014612091705203056, 0.02705303207039833, 0.0, 0.0], [0.7923433780670166, 0.02730492874979973, 0.018806710839271545, 0.13854092359542847, 0.023004023358225822, 0.0], [0.6152045130729675, 0.026655228808522224, 0.029353102669119835, 0.05590905621647835, 0.11611326038837433, 0.15676474571228027]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9804654121398926, 0.019534548744559288, 0.0, 0.0, 0.0, 0.0], [0.9882452487945557, 0.007509480696171522, 0.004245338030159473, 0.0, 0.0, 0.0], [0.9584206342697144, 0.010963553562760353, 0.010456074960529804, 0.02015972137451172, 0.0, 0.0], [0.9604811668395996, 0.007182620465755463, 0.003072339342907071, 0.006898906547576189, 0.02236505039036274, 0.0], [0.966888964176178, 0.0032812796998769045, 0.005500525701791048, 0.004234071355313063, 0.005038019735366106, 0.015057139098644257]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9498194456100464, 0.05018055811524391, 0.0, 0.0, 0.0, 0.0], [0.9781363606452942, 0.016430053859949112, 0.00543356966227293, 0.0, 0.0, 0.0], [0.8618696928024292, 0.036093570291996, 0.07555556297302246, 0.02648119255900383, 0.0, 0.0], [0.5449843406677246, 0.015411121770739555, 0.02351648546755314, 0.2574354410171509, 0.15865254402160645, 0.0], [0.9571872353553772, 0.0030803862027823925, 0.001444687251932919, 0.006861583329737186, 0.014818801544606686, 0.01660725846886635]]], [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6156562566757202, 0.3843437135219574, 0.0, 0.0, 0.0, 0.0], [0.3676063120365143, 0.42816364765167236, 0.20423007011413574, 0.0, 0.0, 0.0], [0.1647152304649353, 0.413679301738739, 0.25092387199401855, 0.1706816405057907, 0.0, 0.0], [0.41844576597213745, 0.1524762064218521, 0.10305406898260117, 0.11071507632732391, 0.21530888974666595, 0.0], [0.19686941802501678, 0.20146216452121735, 0.12827251851558685, 0.09203242510557175, 0.09167557209730148, 0.2896879017353058]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9027364253997803, 0.09726356714963913, 0.0, 0.0, 0.0, 0.0], [0.9736634492874146, 0.014004302211105824, 0.01233230996876955, 0.0, 0.0, 0.0], [0.8504457473754883, 0.05690572038292885, 0.0320608913898468, 0.06058766320347786, 0.0, 0.0], [0.7661209106445312, 0.03530395030975342, 0.03433046489953995, 0.09675205498933792, 0.0674925372004509, 0.0], [0.8650377988815308, 0.02008521929383278, 0.011498049832880497, 0.018558336421847343, 0.018430253490805626, 0.06639043241739273]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9653082489967346, 0.034691739827394485, 0.0, 0.0, 0.0, 0.0], [0.9816323518753052, 0.014176078140735626, 0.004191520158201456, 0.0, 0.0, 0.0], [0.9275256395339966, 0.04737217351794243, 0.01152826938778162, 0.013573980890214443, 0.0, 0.0], [0.9293117523193359, 0.025833290070295334, 0.0072271134704351425, 0.014300605282187462, 0.023327283561229706, 0.0], [0.8895065188407898, 0.04689610004425049, 0.00471709668636322, 0.0062865810468792915, 0.006090124603360891, 0.04650355875492096]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8938026428222656, 0.10619732737541199, 0.0, 0.0, 0.0, 0.0], [0.8221707344055176, 0.06304483860731125, 0.11478452384471893, 0.0, 0.0, 0.0], [0.5047376751899719, 0.15375745296478271, 0.22770409286022186, 0.11380089074373245, 0.0, 0.0], [0.4082075357437134, 0.09066350013017654, 0.11696871370077133, 0.2455318123102188, 0.13862836360931396, 0.0], [0.7291043996810913, 0.06638871133327484, 0.023112772032618523, 0.031103022396564484, 0.05714310333132744, 0.09314798563718796]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9247532486915588, 0.07524675130844116, 0.0, 0.0, 0.0, 0.0], [0.8957376480102539, 0.06989560276269913, 0.034366827458143234, 0.0, 0.0, 0.0], [0.7924937605857849, 0.09601148217916489, 0.05509118735790253, 0.0564035139977932, 0.0, 0.0], [0.7891505360603333, 0.07880303263664246, 0.03840159252285957, 0.05396983399987221, 0.03967498242855072, 0.0], [0.7807857990264893, 0.07993530482053757, 0.042531732469797134, 0.032342106103897095, 0.0178169347345829, 0.046588048338890076]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9480886459350586, 0.05191132426261902, 0.0, 0.0, 0.0, 0.0], [0.8636947870254517, 0.047562118619680405, 0.08874309808015823, 0.0, 0.0, 0.0], [0.9341371059417725, 0.02222410961985588, 0.02262447215616703, 0.021014327183365822, 0.0, 0.0], [0.9588143229484558, 0.008020920678973198, 0.004490080755203962, 0.005862290970981121, 0.02281239815056324, 0.0], [0.9385918378829956, 0.021227702498435974, 0.004872457589954138, 0.01094016246497631, 0.009524572640657425, 0.01484342198818922]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9763734340667725, 0.02362659201025963, 0.0, 0.0, 0.0, 0.0], [0.9884802103042603, 0.005189403425902128, 0.006330382544547319, 0.0, 0.0, 0.0], [0.9477092027664185, 0.01798516884446144, 0.010156619362533092, 0.024149026721715927, 0.0, 0.0], [0.967192530632019, 0.006552826147526503, 0.0033227908425033092, 0.005563332699239254, 0.01736840419471264, 0.0], [0.9584562182426453, 0.007502953987568617, 0.005136328749358654, 0.008071633987128735, 0.005997116211801767, 0.014835822395980358]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8840709328651428, 0.11592909693717957, 0.0, 0.0, 0.0, 0.0], [0.9931254386901855, 0.005070808809250593, 0.001803802908398211, 0.0, 0.0, 0.0], [0.9534159302711487, 0.023829061537981033, 0.007748984266072512, 0.01500609703361988, 0.0, 0.0], [0.9151289463043213, 0.010873105376958847, 0.013190969824790955, 0.011050427332520485, 0.04975659400224686, 0.0], [0.8769674301147461, 0.03385210409760475, 0.008486478589475155, 0.009969150647521019, 0.03468582406640053, 0.036039091646671295]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0003709525044541806, 0.999629020690918, 0.0, 0.0, 0.0, 0.0], [6.525040225824341e-05, 0.37378236651420593, 0.6261524558067322, 0.0, 0.0, 0.0], [4.6060264139669016e-05, 0.21050874888896942, 0.41159680485725403, 0.377848356962204, 0.0, 0.0], [4.753069515572861e-05, 0.11616948246955872, 0.23264294862747192, 0.3985331058502197, 0.25260692834854126, 0.0], [1.2476385791160283e-06, 0.14819687604904175, 0.15813174843788147, 0.3007437586784363, 0.11939030885696411, 0.2735360264778137]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.971555769443512, 0.028444180265069008, 0.0, 0.0, 0.0, 0.0], [0.9529063701629639, 0.03233079984784126, 0.014762787148356438, 0.0, 0.0, 0.0], [0.9343128204345703, 0.02351296693086624, 0.020498057827353477, 0.021676253527402878, 0.0, 0.0], [0.9529678225517273, 0.00855141133069992, 0.0043593235313892365, 0.008064544759690762, 0.02605690062046051, 0.0], [0.9653594493865967, 0.008487643674015999, 0.0034992804285138845, 0.0027215764857828617, 0.0032828792463988066, 0.016649337485432625]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8630780577659607, 0.1369219273328781, 0.0, 0.0, 0.0, 0.0], [0.7696154117584229, 0.08513347804546356, 0.14525112509727478, 0.0, 0.0, 0.0], [0.7133336663246155, 0.10170901566743851, 0.11931274831295013, 0.06564459204673767, 0.0, 0.0], [0.7186222672462463, 0.05444291979074478, 0.013868155889213085, 0.07808026671409607, 0.13498631119728088, 0.0], [0.7990154027938843, 0.0580558106303215, 0.009446999058127403, 0.01777041330933571, 0.021138500422239304, 0.09457293897867203]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9518988728523254, 0.04810110479593277, 0.0, 0.0, 0.0, 0.0], [0.8580653071403503, 0.02944575622677803, 0.11248888075351715, 0.0, 0.0, 0.0], [0.6577736139297485, 0.08513452857732773, 0.12613102793693542, 0.1309608370065689, 0.0, 0.0], [0.8087372183799744, 0.03230157867074013, 0.018418142572045326, 0.06856127083301544, 0.07198181748390198, 0.0], [0.6683297157287598, 0.13281385600566864, 0.021880634129047394, 0.02787742204964161, 0.049234047532081604, 0.09986431896686554]]]], \"left_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"], \"right_text\": [\"No\", \",\", \" I\", \" am\", \" your\", \" father\"]}], \"default_filter\": \"0\", \"display_mode\": \"dark\", \"root_div_id\": \"bertviz-43e94066d0a34bdbbbf570b94f4258a7\", \"include_layers\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"include_heads\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], \"total_heads\": 12} is a template marker that is replaced by actual params.\n        const config = {};\n\n        const MIN_X = 0;\n        const MIN_Y = 0;\n        const DIV_WIDTH = 970;\n        const THUMBNAIL_PADDING = 5;\n        const DETAIL_WIDTH = 300;\n        const DETAIL_ATTENTION_WIDTH = 140;\n        const DETAIL_BOX_WIDTH = 80;\n        const DETAIL_BOX_HEIGHT = 18;\n        const DETAIL_PADDING = 15;\n        const ATTN_PADDING = 0;\n        const DETAIL_HEADING_HEIGHT = 25;\n        const HEADING_TEXT_SIZE = 15;\n        const HEADING_PADDING = 5;\n        const TEXT_SIZE = 13;\n        const TEXT_PADDING = 5;\n        const LAYER_COLORS = d3.schemeCategory10;\n        const PALETTE = {\n            'light': {\n                'text': 'black',\n                'background': 'white',\n                'highlight': '#F5F5F5'\n            },\n            'dark': {\n                'text': '#ccc',\n                'background': 'black',\n                'highlight': '#222'\n            }\n        }\n\n        function render() {\n\n            // Set global state variables\n\n            var attData = config.attention[config.filter];\n            config.leftText = attData.left_text;\n            config.rightText = attData.right_text;\n            config.attn = attData.attn;\n            config.numLayers = config.attn.length;\n            config.numHeads = config.attn[0].length;\n            config.thumbnailBoxHeight = 7 * (12 / config.totalHeads);\n            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n            config.thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n            config.thumbnailWidth = (DIV_WIDTH - axisSize) / config.totalHeads;\n            config.detailHeight = Math.max(config.leftText.length, config.rightText.length) * DETAIL_BOX_HEIGHT + 2 * DETAIL_PADDING + DETAIL_HEADING_HEIGHT;\n            config.divHeight = Math.max(config.numLayers * config.thumbnailHeight + axisSize, config.detailHeight);\n\n            const vis = $(`#${config.rootDivId} #vis`)\n            vis.empty();\n            vis.attr(\"height\", config.divHeight);\n            config.svg = d3.select(`#${config.rootDivId} #vis`)\n                .append('svg')\n                .attr(\"width\", DIV_WIDTH)\n                .attr(\"height\", config.divHeight)\n                .attr(\"fill\", getBackgroundColor());\n\n            renderAxisLabels();\n\n            var i;\n            var j;\n            for (i = 0; i < config.numLayers; i++) {\n                for (j = 0; j < config.numHeads; j++) {\n                    renderThumbnail(i, j);\n                }\n            }\n        }\n\n        function renderAxisLabels() {\n            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n            const tableWidth = config.thumbnailWidth * config.heads.length;\n            config.svg.append(\"text\")\n                .text(\"Heads\")\n                .attr(\"fill\", \"black\")\n                .attr(\"font-weight\", \"bold\")\n                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n                .attr(\"x\", axisSize + tableWidth / 2)\n                .attr(\"text-anchor\", \"middle\")\n                .attr(\"y\", 0)\n                .attr(\"dy\", HEADING_TEXT_SIZE);\n            for (let i = 0; i < config.numHeads; i++) {\n                config.svg.append(\"text\")\n                    .text(config.heads[i])\n                    .attr(\"fill\", \"black\")\n                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n                    .attr(\"x\", axisSize + (i + .5) * config.thumbnailWidth)\n                    .attr(\"text-anchor\", \"middle\")\n                    .attr(\"y\", HEADING_TEXT_SIZE + HEADING_PADDING)\n                    .attr(\"dy\", TEXT_SIZE);\n            }\n            let x = 0;\n            let y = axisSize + config.thumbnailHeight * config.layers.length / 2;\n            console.log(\"x\", x, y)\n            config.svg.append(\"text\")\n                .text(\"Layers\")\n                .attr(\"fill\", \"black\")\n                .attr(\"font-weight\", \"bold\")\n                .attr(\"transform\", \"rotate(270, \" + x  + \", \" + y + \")\")\n                .attr(\"font-size\", HEADING_TEXT_SIZE + \"px\")\n                .attr(\"x\", x)\n                .attr(\"text-anchor\", \"middle\")\n                .attr(\"y\", y)\n                .attr(\"dy\", HEADING_TEXT_SIZE);\n            for (let i = 0; i < config.numLayers; i++) {\n                x = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE; // HACK\n                y = axisSize + (i + .5) * config.thumbnailHeight;\n                config.svg.append(\"text\")\n                    .text(config.layers[i])\n                    .attr(\"fill\", \"black\")\n                    .attr(\"font-size\", TEXT_SIZE + \"px\")\n                    .attr(\"x\", x)\n                    .attr(\"text-anchor\", \"end\")\n                    .attr(\"y\", y)\n                    .attr(\"dy\", TEXT_SIZE / 2);\n            }\n        }\n\n\n        function renderThumbnail(layerIndex, headIndex) {\n            const axisSize = HEADING_TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING\n            const x = headIndex * config.thumbnailWidth + axisSize;\n            const y = layerIndex * config.thumbnailHeight + axisSize;\n            renderThumbnailAttn(x, y, config.attn[layerIndex][headIndex], layerIndex, headIndex);\n        }\n\n        function renderDetail(att, layerIndex, headIndex) {\n            const axisSize = TEXT_SIZE + HEADING_PADDING + TEXT_SIZE + TEXT_PADDING;\n            var xOffset = .8 * config.thumbnailWidth;\n            var maxX = DIV_WIDTH;\n            var maxY = config.divHeight - 3;\n            var leftPos = axisSize + headIndex * config.thumbnailWidth;\n            var x = leftPos + THUMBNAIL_PADDING + xOffset;\n            if (x < MIN_X) {\n                x = MIN_X;\n            } else if (x + DETAIL_WIDTH > maxX) {\n                x = leftPos + THUMBNAIL_PADDING - DETAIL_WIDTH + 8;\n            }\n            var posLeftText = x;\n            var posAttention = posLeftText + DETAIL_BOX_WIDTH;\n            var posRightText = posAttention + DETAIL_ATTENTION_WIDTH;\n            var thumbnailHeight = Math.max(config.leftText.length, config.rightText.length) * config.thumbnailBoxHeight + 2 * THUMBNAIL_PADDING;\n            var yOffset = 20;\n            var y = layerIndex * thumbnailHeight + THUMBNAIL_PADDING + yOffset;\n            if (y < MIN_Y) {\n                y = MIN_Y;\n            } else if (y + config.detailHeight > maxY) {\n                y = maxY - config.detailHeight;\n            }\n            renderDetailFrame(x, y, layerIndex);\n            y = y + DETAIL_PADDING;\n            renderDetailHeading(x, y, layerIndex, headIndex);\n            y = y + DETAIL_HEADING_HEIGHT;\n            renderDetailText(config.leftText, \"leftText\", posLeftText, y , layerIndex);\n            renderDetailAttn(posAttention, y, att, layerIndex, headIndex);\n            renderDetailText(config.rightText, \"rightText\", posRightText, y, layerIndex);\n        }\n\n        function renderDetailHeading(x, y, layerIndex, headIndex) {\n            var fillColor = getTextColor();\n            config.svg.append(\"text\")\n                .classed(\"detail\", true)\n                .text('Layer ' + config.layers[layerIndex] + \", Head \" + config.heads[headIndex])\n                .attr(\"font-size\", TEXT_SIZE + \"px\")\n                .attr(\"font-weight\", \"bold\")\n                .style(\"cursor\", \"default\")\n                .style(\"-webkit-user-select\", \"none\")\n                .attr(\"fill\", fillColor)\n                .attr(\"x\", x + DETAIL_WIDTH / 2)\n                .attr(\"text-anchor\", \"middle\")\n                .attr(\"y\", y)\n                .attr(\"height\", DETAIL_HEADING_HEIGHT)\n                .attr(\"width\", DETAIL_WIDTH)\n                .attr(\"dy\", HEADING_TEXT_SIZE);\n        }\n\n        function renderDetailText(text, id, x, y, layerIndex) {\n            var tokenContainer = config.svg.append(\"svg:g\")\n                .classed(\"detail\", true)\n                .selectAll(\"g\")\n                .data(text)\n                .enter()\n                .append(\"g\");\n\n            var fillColor = getTextColor();\n\n            tokenContainer.append(\"rect\")\n                .classed(\"highlight\", true)\n                .attr(\"fill\", fillColor)\n                .style(\"opacity\", 0.0)\n                .attr(\"height\", DETAIL_BOX_HEIGHT)\n                .attr(\"width\", DETAIL_BOX_WIDTH)\n                .attr(\"x\", x)\n                .attr(\"y\", function (d, i) {\n                    return y + i * DETAIL_BOX_HEIGHT;\n                });\n\n            var textContainer = tokenContainer.append(\"text\")\n                .classed(\"token\", true)\n                .text(function (d) {\n                    return d;\n                })\n                .attr(\"font-size\", TEXT_SIZE + \"px\")\n                .style(\"cursor\", \"default\")\n                .style(\"-webkit-user-select\", \"none\")\n                .attr(\"fill\", fillColor)\n                .attr(\"x\", x)\n                .attr(\"y\", function (d, i) {\n                    return i * DETAIL_BOX_HEIGHT + y;\n                })\n                .attr(\"height\", DETAIL_BOX_HEIGHT)\n                .attr(\"width\", DETAIL_BOX_WIDTH)\n                .attr(\"dy\", TEXT_SIZE);\n\n            if (id == \"leftText\") {\n                textContainer.style(\"text-anchor\", \"end\")\n                    .attr(\"dx\", DETAIL_BOX_WIDTH - 2);\n                tokenContainer.on(\"mouseover\", function (d, index) {\n                    highlightSelection(index);\n                });\n                tokenContainer.on(\"mouseleave\", function () {\n                    unhighlightSelection();\n                });\n            }\n        }\n\n        function highlightSelection(index) {\n            config.svg.select(\"#leftText\")\n                .selectAll(\".highlight\")\n                .style(\"opacity\", function (d, i) {\n                    return i == index ? 1.0 : 0.0;\n                });\n            config.svg.selectAll(\".attn-line-group\")\n                .style(\"opacity\", function (d, i) {\n                    return i == index ? 1.0 : 0.0;\n                });\n        }\n\n        function unhighlightSelection() {\n            config.svg.select(\"#leftText\")\n                .selectAll(\".highlight\")\n                .style(\"opacity\", 0.0);\n            config.svg.selectAll(\".attn-line-group\")\n                .style(\"opacity\", 1);\n        }\n\n        function renderThumbnailAttn(x, y, att, layerIndex, headIndex) {\n\n            var attnContainer = config.svg.append(\"svg:g\");\n\n            var attnBackground = attnContainer.append(\"rect\")\n                .attr(\"id\", 'attn_background_' + layerIndex + \"_\" + headIndex)\n                .classed(\"attn_background\", true)\n                .attr(\"x\", x)\n                .attr(\"y\", y)\n                .attr(\"height\", config.thumbnailHeight)\n                .attr(\"width\", config.thumbnailWidth)\n                .attr(\"stroke-width\", 2)\n                .attr(\"stroke\", getLayerColor(layerIndex))\n                .attr(\"stroke-opacity\", 0)\n                .attr(\"fill\", getBackgroundColor());\n            var x1 = x + THUMBNAIL_PADDING;\n            var x2 = x1 + config.thumbnailWidth - 14;\n            var y1 = y + THUMBNAIL_PADDING;\n\n            attnContainer.selectAll(\"g\")\n                .data(att)\n                .enter()\n                .append(\"g\") // Add group for each source token\n                .attr(\"source-index\", function (d, i) { // Save index of source token\n                    return i;\n                })\n                .selectAll(\"line\")\n                .data(function (d) { // Loop over all target tokens\n                    return d;\n                })\n                .enter() // When entering\n                .append(\"line\")\n                .attr(\"x1\", x1)\n                .attr(\"y1\", function (d) {\n                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n                    return y1 + (sourceIndex + .5) * config.thumbnailBoxHeight;\n                })\n                .attr(\"x2\", x2)\n                .attr(\"y2\", function (d, targetIndex) {\n                    return y1 + (targetIndex + .5) * config.thumbnailBoxHeight;\n                })\n                .attr(\"stroke-width\", 2.2)\n                .attr(\"stroke\", getLayerColor(layerIndex))\n                .attr(\"stroke-opacity\", function (d) {\n                    return d;\n                });\n\n            var clickRegion = attnContainer.append(\"rect\")\n                .attr(\"x\", x)\n                .attr(\"y\", y)\n                .attr(\"height\", config.thumbnailHeight)\n                .attr(\"width\", config.thumbnailWidth)\n                .style(\"opacity\", 0);\n\n            clickRegion.on(\"click\", function (d, index) {\n                var attnBackgroundOther = config.svg.selectAll(\".attn_background\");\n                attnBackgroundOther.attr(\"fill\", getBackgroundColor());\n                attnBackgroundOther.attr(\"stroke-opacity\", 0);\n\n                config.svg.selectAll(\".detail\").remove();\n                if (config.detail_layer != layerIndex || config.detail_head != headIndex) {\n                    renderDetail(att, layerIndex, headIndex);\n                    config.detail_layer = layerIndex;\n                    config.detail_head = headIndex;\n                    attnBackground.attr(\"fill\", getHighlightColor());\n                    attnBackground.attr(\"stroke-opacity\", .8);\n                } else {\n                    config.detail_layer = null;\n                    config.detail_head = null;\n                    attnBackground.attr(\"fill\", getBackgroundColor());\n                    attnBackground.attr(\"stroke-opacity\", 0);\n                }\n            });\n\n            clickRegion.on(\"mouseover\", function (d) {\n                d3.select(this).style(\"cursor\", \"pointer\");\n            });\n        }\n\n        function renderDetailFrame(x, y, layerIndex) {\n            var detailFrame = config.svg.append(\"rect\")\n                .classed(\"detail\", true)\n                .attr(\"x\", x)\n                .attr(\"y\", y)\n                .attr(\"height\", config.detailHeight)\n                .attr(\"width\", DETAIL_WIDTH)\n                .style(\"opacity\", 1)\n                .attr(\"stroke-width\", 1.5)\n                .attr(\"stroke-opacity\", 0.7)\n                .attr(\"stroke\", getLayerColor(layerIndex));\n        }\n\n        function renderDetailAttn(x, y, att, layerIndex) {\n            var attnContainer = config.svg.append(\"svg:g\")\n                .classed(\"detail\", true)\n                .attr(\"pointer-events\", \"none\");\n            attnContainer.selectAll(\"g\")\n                .data(att)\n                .enter()\n                .append(\"g\") // Add group for each source token\n                .classed('attn-line-group', true)\n                .attr(\"source-index\", function (d, i) { // Save index of source token\n                    return i;\n                })\n                .selectAll(\"line\")\n                .data(function (d) { // Loop over all target tokens\n                    return d;\n                })\n                .enter()\n                .append(\"line\")\n                .attr(\"x1\", x + ATTN_PADDING)\n                .attr(\"y1\", function (d) {\n                    var sourceIndex = +this.parentNode.getAttribute(\"source-index\");\n                    return y + (sourceIndex + .5) * DETAIL_BOX_HEIGHT;\n                })\n                .attr(\"x2\", x + DETAIL_ATTENTION_WIDTH - ATTN_PADDING)\n                .attr(\"y2\", function (d, targetIndex) {\n                    return y + (targetIndex + .5) * DETAIL_BOX_HEIGHT;\n                })\n                .attr(\"stroke-width\", 2.2)\n                .attr(\"stroke\", getLayerColor(layerIndex))\n                .attr(\"stroke-opacity\", function (d) {\n                    return d;\n                });\n        }\n\n        function getLayerColor(layer) {\n          return LAYER_COLORS[config.layers[layer] % 10];\n        }\n\n        function getTextColor() {\n            return PALETTE[config.mode]['text']\n        }\n\n        function getBackgroundColor() {\n           return PALETTE[config.mode]['background']\n        }\n\n        function getHighlightColor() {\n           return PALETTE[config.mode]['highlight']\n        }\n\n        function initialize() {\n            config.attention = params['attention'];\n            config.filter = params['default_filter'];\n            config.mode = params['display_mode'];\n            config.layers = params['include_layers']\n            config.heads = params['include_heads']\n            config.totalHeads = params['total_heads']\n            config.rootDivId = params['root_div_id'];\n            $(`#${config.rootDivId} #filter`).on('change', function (e) {\n                config.filter = e.currentTarget.value;\n                render();\n            });\n        }\n\n        initialize();\n        render();\n\n    });",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel, utils, AutoModelForCausalLM\n",
    "\n",
    "from bertviz import model_view\n",
    "utils.logging.set_verbosity_error()  # Suppress standard warnings\n",
    "\n",
    "model_name = 'openai-community/gpt2'\n",
    "input_text = \"No, I am your father\"  \n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')  # Tokenize input text\n",
    "outputs = model(inputs)  # Run model\n",
    "attention = outputs[-1]  # Retrieve attention from model outputs\n",
    "tokens = tokenizer.convert_ids_to_tokens(inputs[0])  # Convert input ids to token strings\n",
    "model_view(attention, tokens)  # Display model view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFq78-kjbrWp"
   },
   "source": [
    "Last week, Carlo discussed token embedding, which is when words are encoded into a vocabulary. Now, we just discussed attention mechanisms which account for context between words. Another question we should ask is how do we account for the order of words in an input sentence\n",
    "\n",
    "Consider the following two sentences to see why this is important:\n",
    "\n",
    "``The man ate the sandwich.``\n",
    "\n",
    "``The sandwich ate the man.``\n",
    "\n",
    "Clearly, these are two vastly different situations even though they have the same words. The Transformer can \n",
    "\n",
    "Transformers differentiate between these situations by adding a **Positional encoding** vector to each input embedding. These vectors follow a specific pattern that the model learns, which helps it determine the position of each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/positional_encoding.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "Image credit: https://medium.com/@xuer.chen.human/llm-study-notes-positional-encoding-0639a1002ec0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up positional encoding similarly as token embedding using the ``nn.Embedding`` tool. We use a simple embedding here but there are more complex positional encodings used such as sinusoidal. \n",
    "\n",
    "For an explanation of different positional encodings, refer to this post: https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 65\n",
    "n_embd = 64\n",
    "\n",
    "token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "position_embedding_table = nn.Embedding(block_size, n_embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice the positional encoding size is `(block_size, n_embed)` because it encodes for the postion of a token within the sequence of size `block_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the position embedding used is simply added to the token embedding to apply positional embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at token embedding alone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.7221, -0.9629, -2.0578,  1.9740,  0.7434,  1.1139,  0.6926,  0.0296,\n",
      "         0.6405, -1.6464,  0.4935,  0.7485,  0.9238, -0.4940,  0.4814, -0.3859,\n",
      "        -0.3094,  1.1066, -0.2891,  0.1891,  2.0440, -0.7945, -0.4331,  0.3007,\n",
      "         1.4317,  0.2881, -0.4343,  0.4280,  1.2469,  1.4047, -0.3404, -2.2190,\n",
      "         0.4893,  0.0398, -0.2717, -2.2400, -0.0029, -1.4251,  0.7330,  0.3551,\n",
      "         0.1472, -1.1895, -0.8407,  0.3134, -0.6709, -0.8176,  0.6929, -0.6374,\n",
      "         0.3174,  0.4837, -0.0073, -1.5924,  1.8606, -1.2910, -0.1594,  0.3111,\n",
      "        -0.1536, -0.3414, -0.0170, -0.1633,  0.2794,  0.6755,  0.7066, -1.6665],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x = token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And token + positional embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.4326, -1.6287, -0.8684,  3.0704,  0.3646,  1.9826,  0.7582, -0.1918,\n",
      "         1.0491, -2.2562, -0.4931, -0.7808,  1.7206, -1.0297,  2.0798, -1.3427,\n",
      "        -0.7896, -0.1746,  0.0926,  0.0543,  2.3831, -0.6208,  0.3902,  0.1097,\n",
      "         1.0455, -1.4557,  0.3402,  2.6717,  1.8380,  1.2628, -0.4831, -4.6023,\n",
      "         0.6959,  1.0347,  0.5903, -0.7541,  0.4682, -0.3895,  2.1526,  0.6272,\n",
      "        -0.8558, -0.8434,  0.1311, -1.0272, -2.0580,  0.0584,  0.3442, -0.3464,\n",
      "        -0.3444,  2.3134, -1.1142, -1.4629,  3.3503, -2.0594,  1.4105,  0.4558,\n",
      "        -1.3366,  1.9283,  1.5187,  0.3906,  1.1448, -0.8422,  2.2692, -0.7949],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,3,15,4,7,1,4,9])\n",
    "x= position_embedding_table(x) + token_embedding_table(x)\n",
    "print(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a clear offset between these two embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the training process, these embeddings will be learned to best encode the token and positional embeddings of the sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iF1HzH9xNJ7S"
   },
   "source": [
    "## Output layers\n",
    "\n",
    "At the end of our Transformer model, we are left with a vector, so how do we turn this into a word?\n",
    "\n",
    "<img src=\"images/transformer-decoder-intro.png\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "Using a final Linear layer and a Softmax Layer.\n",
    "The Linear layer projects the vector produced by the stack of decoders, into a larger vector called a logits vector.\n",
    "\n",
    "If our model knows 10,000 unique English words learned from its training dataset the logits vector is 10,000 cells wide ‚Äì each cell corresponds to the score of a unique word.\n",
    "\n",
    "The softmax layer turns those scores into probabilities. The cell with the highest probability is chosen, and the word associated with it is produced as the output for this time step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/transformer_decoder_output_softmax.png\" alt=\"Drawing\" style=\"width: 450px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XK8q67P03yr4"
   },
   "source": [
    "## Training\n",
    "\n",
    "How does an LLM improve over time?\n",
    "We want to compare the probabilitiy distribution for each token generated by our model to the ground truths. \n",
    "Our model produces a probability distribution for each token. We want to compare these probability distributions to the ground truths. \n",
    "For example, when translating the sentence: ‚Äúje suis √©tudiant‚Äù into ‚Äúi am a student‚Äù as can be seen in the example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/output_target_probability_distributions.png\" alt=\"Drawing\" style=\"width: 500px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HS6r-z8dN_RV"
   },
   "source": [
    "Image credit: https://jalammar.github.io/illustrated-transformer/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model can calculate the loss between the vector it generates and the ground truth vector seen in this example. A commonly used loss function is cross entropy loss:\n",
    "\n",
    "$CE = -\\sum_{x \\in X} p(x) log q(x)$\n",
    "\n",
    "where p(x) represents the true distribution and q(x) represents the predicted distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9119)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "logits = torch.tensor([0.5, 0.1, 0.3])\n",
    "targets = torch.tensor([1.0, 0.0, 0.0])\n",
    "loss = F.cross_entropy(logits, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important metric commonly used in LLMs is **perplexity**.\n",
    "\n",
    "Intuitively, perplexity means to be surprised. We measure how much the model is surprised by seeing new data. The lower the perplexity, the better the training is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mathematically, perplexity is just the exponent of the negative cross entropy loss:\n",
    "\n",
    "$\\text{perplexity} = exp(\\text{CE})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4891)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are using cross entropy loss."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's train a mini-LLM from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "batch_size = 16 # how many independent sequences will we process in parallel?\n",
    "block_size = 32 # what is the maximum context length for predictions?\n",
    "max_iters = 5000\n",
    "eval_interval = 10\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "dropout = 0.0\n",
    "# ------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in data and create train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to be using the tiny Shakespeare dataset. \n",
    "Data is tokenized according to a simple character based tokenizer.\n",
    "Data is split into a train and test set so we have something to test after performing training (9:1 split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset/input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string\n",
    "\n",
    "# Train and test splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "n = int(0.9*len(data)) # first 90% will be train, rest val\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]\n",
    "\n",
    "# data loading\n",
    "def get_batch(split):\n",
    "    # generate a small batch of data of inputs x and targets y\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the components of the Decoder block: \n",
    "* MultiHeadAttention\n",
    "* FeedForward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" one head of self-attention \"\"\"\n",
    "\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)   # (B,T,C) 16,32,16\n",
    "        q = self.query(x) # (B,T,C)\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n",
    "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
    "        wei = self.dropout(wei)\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x) # (B,T,C)\n",
    "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(n_embd, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd), # Projection layer going back into the residual pathway\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine components into the Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, n_head):\n",
    "        # n_embd: embedding dimension, n_head: the number of heads we'd like\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size)\n",
    "        self.ffwd = FeedFoward(n_embd)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))    # Communication\n",
    "        x = x + self.ffwd(self.ln2(x))  # Computation\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the full Transformer model \n",
    "This is a combination of the Token embeddings, Positional embeddings, a stack of Transformer blocks and an output block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# super simple language model\n",
    "class LanguageModel(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # each token directly reads off the logits for the next token from a lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        B, T = idx.shape\n",
    "\n",
    "        # idx and targets are both (B,T) tensor of integers\n",
    "        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n",
    "        x = tok_emb + pos_emb # (B,T,C)\n",
    "        x = self.blocks(x) # (B,T,C)\n",
    "        x = self.ln_f(x) # (B,T,C)\n",
    "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        # idx is (B, T) array of indices in the current context\n",
    "        for _ in range(max_new_tokens):\n",
    "            # crop idx to the last block_size tokens\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            # get the predictions\n",
    "            logits, loss = self(idx_cond)\n",
    "            # focus only on the last time step\n",
    "            logits = logits[:, -1, :] # becomes (B, C)\n",
    "            # apply softmax to get probabilities\n",
    "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
    "            # sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
    "            # append sampled index to the running sequence\n",
    "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
    "        return idx\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be training a larger LLM on distributed resources in session 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. In this notebook, we learned the various components of an LLM. \n",
    "    Your homework this week is to take the mini LLM we created from scratch and run your own training loop. Show how the training and validation perplexity change over the steps.\n",
    "      \n",
    "    Hint: this function might be useful for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train perplexity: 76.5399169921875 | val perplexity: 76.59461212158203\n",
      "train perplexity: 62.26118087768555 | val perplexity: 62.92958450317383\n",
      "train perplexity: 52.31807327270508 | val perplexity: 53.230552673339844\n",
      "train perplexity: 45.90920639038086 | val perplexity: 46.5277214050293\n",
      "train perplexity: 41.363929748535156 | val perplexity: 42.34206008911133\n",
      "train perplexity: 38.50232696533203 | val perplexity: 39.48176574707031\n",
      "train perplexity: 36.18961715698242 | val perplexity: 36.88169479370117\n",
      "train perplexity: 34.7253303527832 | val perplexity: 35.4586181640625\n",
      "train perplexity: 32.90141677856445 | val perplexity: 34.07029724121094\n",
      "train perplexity: 31.71086311340332 | val perplexity: 32.611351013183594\n",
      "train perplexity: 30.96308708190918 | val perplexity: 31.893321990966797\n",
      "train perplexity: 30.2747802734375 | val perplexity: 31.30768585205078\n",
      "train perplexity: 29.565139770507812 | val perplexity: 30.472490310668945\n",
      "train perplexity: 28.62732696533203 | val perplexity: 29.90613555908203\n",
      "train perplexity: 28.266374588012695 | val perplexity: 29.213102340698242\n",
      "train perplexity: 27.982797622680664 | val perplexity: 28.860151290893555\n",
      "train perplexity: 27.553003311157227 | val perplexity: 28.524349212646484\n",
      "train perplexity: 26.927955627441406 | val perplexity: 28.185800552368164\n",
      "train perplexity: 26.597164154052734 | val perplexity: 27.854297637939453\n",
      "train perplexity: 26.61815643310547 | val perplexity: 27.597558975219727\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "steps = 20\n",
    "for j in range(steps):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    x, y = get_batch('train')\n",
    "    \n",
    "    logits, loss = model(x, y)\n",
    "\n",
    "    out = estimate_loss()\n",
    "\n",
    "    print(f\"train perplexity: {torch.exp(out['train'])} | val perplexity: {torch.exp(out['val'])}\")\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run the same training loop but modify one of the hyperparameters from this list: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train perplexity: 75.37800598144531 | val perplexity: 75.04232788085938\n",
      "train perplexity: 63.1735954284668 | val perplexity: 63.42974090576172\n",
      "train perplexity: 54.56033706665039 | val perplexity: 55.04841232299805\n",
      "train perplexity: 47.92430114746094 | val perplexity: 49.028053283691406\n",
      "train perplexity: 43.84872817993164 | val perplexity: 44.498085021972656\n",
      "train perplexity: 40.77113723754883 | val perplexity: 41.362548828125\n",
      "train perplexity: 37.763954162597656 | val perplexity: 38.902587890625\n",
      "train perplexity: 36.08360290527344 | val perplexity: 36.71930694580078\n",
      "train perplexity: 34.389793395996094 | val perplexity: 35.44292068481445\n",
      "train perplexity: 33.2720947265625 | val perplexity: 34.03470230102539\n",
      "train perplexity: 32.1295051574707 | val perplexity: 33.08979415893555\n",
      "train perplexity: 31.486074447631836 | val perplexity: 32.3765869140625\n",
      "train perplexity: 30.5065975189209 | val perplexity: 31.692768096923828\n",
      "train perplexity: 29.934276580810547 | val perplexity: 31.168882369995117\n",
      "train perplexity: 29.105247497558594 | val perplexity: 30.01166343688965\n",
      "train perplexity: 28.670961380004883 | val perplexity: 29.633140563964844\n",
      "train perplexity: 28.09019660949707 | val perplexity: 28.747478485107422\n",
      "train perplexity: 27.76854133605957 | val perplexity: 28.38214111328125\n",
      "train perplexity: 27.261390686035156 | val perplexity: 28.22529411315918\n",
      "train perplexity: 26.69843101501465 | val perplexity: 27.626405715942383\n",
      "train perplexity: 86.77953338623047 | val perplexity: 86.93364715576172\n",
      "train perplexity: 69.57394409179688 | val perplexity: 69.9320297241211\n",
      "train perplexity: 58.116294860839844 | val perplexity: 58.568199157714844\n",
      "train perplexity: 50.55642318725586 | val perplexity: 50.95973205566406\n",
      "train perplexity: 45.10198974609375 | val perplexity: 45.865257263183594\n",
      "train perplexity: 41.77096939086914 | val perplexity: 42.62112808227539\n",
      "train perplexity: 38.95597457885742 | val perplexity: 39.897830963134766\n",
      "train perplexity: 36.78813171386719 | val perplexity: 37.737213134765625\n",
      "train perplexity: 35.098175048828125 | val perplexity: 36.05278396606445\n",
      "train perplexity: 33.29016876220703 | val perplexity: 34.390228271484375\n",
      "train perplexity: 32.4202766418457 | val perplexity: 33.28239822387695\n",
      "train perplexity: 31.310089111328125 | val perplexity: 32.12285614013672\n",
      "train perplexity: 30.54647445678711 | val perplexity: 31.318614959716797\n",
      "train perplexity: 29.865840911865234 | val perplexity: 30.76019859313965\n",
      "train perplexity: 28.952743530273438 | val perplexity: 29.71538734436035\n",
      "train perplexity: 28.45107650756836 | val perplexity: 29.24416160583496\n",
      "train perplexity: 27.825477600097656 | val perplexity: 28.692974090576172\n",
      "train perplexity: 27.608366012573242 | val perplexity: 28.072521209716797\n",
      "train perplexity: 27.120019912719727 | val perplexity: 27.7698917388916\n",
      "train perplexity: 26.667659759521484 | val perplexity: 27.479259490966797\n",
      "train perplexity: 81.83921813964844 | val perplexity: 81.72398376464844\n",
      "train perplexity: 67.12997436523438 | val perplexity: 67.37202453613281\n",
      "train perplexity: 56.439823150634766 | val perplexity: 57.02402877807617\n",
      "train perplexity: 49.26207733154297 | val perplexity: 49.71143341064453\n",
      "train perplexity: 44.07963562011719 | val perplexity: 44.98675537109375\n",
      "train perplexity: 40.94817352294922 | val perplexity: 41.450382232666016\n",
      "train perplexity: 38.221805572509766 | val perplexity: 38.921756744384766\n",
      "train perplexity: 36.22071075439453 | val perplexity: 37.13518524169922\n",
      "train perplexity: 34.73210144042969 | val perplexity: 35.687015533447266\n",
      "train perplexity: 33.30826950073242 | val perplexity: 34.279788970947266\n",
      "train perplexity: 32.3897819519043 | val perplexity: 33.14836120605469\n",
      "train perplexity: 31.391136169433594 | val perplexity: 32.10250473022461\n",
      "train perplexity: 30.50908660888672 | val perplexity: 31.637340545654297\n",
      "train perplexity: 29.929054260253906 | val perplexity: 30.740455627441406\n",
      "train perplexity: 29.052461624145508 | val perplexity: 30.209203720092773\n",
      "train perplexity: 28.64825439453125 | val perplexity: 29.610116958618164\n",
      "train perplexity: 28.28040885925293 | val perplexity: 29.101806640625\n",
      "train perplexity: 27.53736686706543 | val perplexity: 28.785701751708984\n",
      "train perplexity: 27.36361312866211 | val perplexity: 28.37567901611328\n",
      "train perplexity: 27.15235710144043 | val perplexity: 28.361841201782227\n",
      "train perplexity: 75.94558715820312 | val perplexity: 75.76155090332031\n",
      "train perplexity: 64.18290710449219 | val perplexity: 64.39667510986328\n",
      "train perplexity: 55.33933639526367 | val perplexity: 55.812931060791016\n",
      "train perplexity: 49.02224349975586 | val perplexity: 49.940147399902344\n",
      "train perplexity: 44.29230880737305 | val perplexity: 45.100311279296875\n",
      "train perplexity: 40.59950256347656 | val perplexity: 41.663570404052734\n",
      "train perplexity: 38.182376861572266 | val perplexity: 39.0510139465332\n",
      "train perplexity: 36.11381149291992 | val perplexity: 37.05693054199219\n",
      "train perplexity: 34.710594177246094 | val perplexity: 35.32864761352539\n",
      "train perplexity: 33.275394439697266 | val perplexity: 34.247291564941406\n",
      "train perplexity: 32.09687042236328 | val perplexity: 32.8550910949707\n",
      "train perplexity: 30.98988914489746 | val perplexity: 31.8541316986084\n",
      "train perplexity: 30.2883243560791 | val perplexity: 31.250837326049805\n",
      "train perplexity: 29.381763458251953 | val perplexity: 30.53323745727539\n",
      "train perplexity: 28.837852478027344 | val perplexity: 30.299419403076172\n",
      "train perplexity: 28.620012283325195 | val perplexity: 29.400514602661133\n",
      "train perplexity: 28.06320571899414 | val perplexity: 29.0820255279541\n",
      "train perplexity: 27.344999313354492 | val perplexity: 28.64447784423828\n",
      "train perplexity: 27.373720169067383 | val perplexity: 28.206384658813477\n",
      "train perplexity: 26.723854064941406 | val perplexity: 27.88905143737793\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "n_embd = 64\n",
    "n_head = 4 ## so head_size = 16\n",
    "n_layer = 4\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n_head in [1, 2, 4, 8]:\n",
    "    results[n_head] = dict()\n",
    "    results[n_head]['train'] = []\n",
    "    results[n_head]['val'] = []\n",
    "\n",
    "    model = LanguageModel().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    steps = 20\n",
    "    for j in range(steps):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y = get_batch('train')\n",
    "\n",
    "        logits, loss = model(x, y)\n",
    "\n",
    "        out = estimate_loss()\n",
    "\n",
    "        train_perplexity = torch.exp(out['train'])\n",
    "        val_perplexity = torch.exp(out['val'])\n",
    "\n",
    "        print(f\"train perplexity: {train_perplexity} | val perplexity: {val_perplexity}\")\n",
    "\n",
    "        results[n_head]['train'].append(train_perplexity)\n",
    "        results[n_head]['val'].append(val_perplexity)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Training steps')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "n_step = 20\n",
    "steps = list(range(n_step))\n",
    "\n",
    "for i, n_head in enumerate(results):\n",
    "    # plt.plot(steps, results[n_head]['train'], label=f'{n_head} heads', color=f\"C{i}\")\n",
    "    plt.plot(steps, results[n_head]['val'], \"--\", color=f\"C{i}\", label=f'{n_head} heads')\n",
    "\n",
    "plt.legend()\n",
    "plt.ylabel('Val perplexity')\n",
    "plt.xlabel('Training steps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this at least 4 times with a different value and plot each perplexity over training step. Write a sentence on how the perplexity changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 1: output some generated text from each model you trained. Did the output make more sense with some hyperparameters than others? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bonus 2: We saw a cool visualization of attention mechanisms with BertViz. Take a more complicated model than GPT2 such as \"meta-llama/Llama-2-7b-chat-hf\" and see how the attention mechanisms are different "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nDXLTusqxXHf"
   },
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some recommendations for further reading and additional code for review.\n",
    "\n",
    "* \"The Illustrated Transformer\" by Jay Alammar\n",
    "* \"Visualizing A Neural Machine Translation Model (Mechanics of Seq2seq Models With Attention)\"\n",
    "* \"The Illustrated GPT-2 (Visualizing Transformer Language Models)\"\n",
    "* \"A gentle introduction to positional encoding\"\n",
    "* \"LLM Tutorial Workshop (Argonne National Laboratory)\"\n",
    "* \"LLM Tutorial Workshop Part 2 (Argonne National Laboratory)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
